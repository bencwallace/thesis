% Parts are the largest structural units, but are optional.
%\part{Thesis}

% Chapters are the next main unit.
\chapter{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Statistical mechanics}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Entropy}

Let $(\Omega, \lambda)$ be a measure space. The state of knowledge of a system on $\Omega$ can be expressed by a probability measure $\mu$ on $\Omega$. Let
$\Mcal_\lambda(\Omega)$ denote the set of probability measures on $\Omega$ absolutely continuous with respect to $\lambda$. For
$\mu \in \Mcal_\lambda(\Omega)$, we denote the Radon-Nikodym derivative of
$\mu$ with respect to $\lambda$ by $d\mu/d\lambda$ and define the
\emph{entropy} of $\mu$ with respect to $\lambda$ by
\begin{equation}
h(\mu) = h_\lambda(\mu) = -\int_\Omega \log\frac{d\mu}{d\lambda} \; d\mu.
\end{equation}
In many cases, specific information about the system under consideration is available, so that we may restrict our attention to a subspace $M \subset \Mcal_\lambda(\Omega)$.
% for example in the form of statements such as
% \begin{equation}
% \int f \; d\mu \in S_f
% \end{equation}
% with $f$ running over some collection of $\mu$-integrable functions
% that represent \emph{observable} quantities of the system, and $S_f$ a Borel
% subsets of $\R$ for each $f$.
The \emph{principle of maximum entropy} \cite{Jaynes57} asserts that, in this
case, the measure best expressing the state of knowledge of the system is given by
\begin{equation}
\hat\mu = \argmax(h_\lambda(\mu) : \mu \in M),
\end{equation}
assuming such a measure exists and is unique.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Microcanonical ensemble}

Consider an \emph{isolated} physical system on $\Omega$, that is, one that cannot exchange energy with its surroundings. Such a system can be determined by a choice of function $H : \Omega \to \R$, called the \emph{Hamiltonian}. The value $H(\omega)$ represents the total energy of the system in state
$\omega\in\Omega$.

\begin{example}
Let $\Omega = U^n \times \R^{3n}$, where $U \subset \R^3$, and denote a generic element of $\Omega$ by $(q, p)$, where $q \in U^n$ and $p \in \R^{3n}$. Then $\Omega$ is the state space of a system of $n$ point particles
$i = 1, \ldots, n$ with positions $q_i \in U$ and momenta $p_i \in \R^3$. Given a $C^1$ Hamiltonian $H : \Omega \to \R$, the dynamics of such a system is determined by \emph{Hamilton's equations}
\begin{align}
\dd{q}{t}   &= \nabla_q H(q(t), p(t)) \\
-\dd{p}{t}  &= \nabla_p H(q(t), p(t)).
\end{align}
An immediate consequence of these equations and the chain rule is the \emph{principle of conservation of energy}:
\begin{equation}
\dd{H}{t}(q(t), p(t)) = 0.
\end{equation}
Thus, a Hamiltonian system with initial configuration $(q(0), p(0))$ of energy
$E = H(q(0), p(0))$ will evolve on the constant energy shell $S_E = H^{-1}(E)$.

% Let us assume that $H$ has compact level sets so that the solutions to Hamilton's
% equations can be extended globally in time. In general, especially when $n$ is large,
% a Hamiltonian system is likely to be too complicated to understand in a precise way.
% The basic idea of statistical mechanics is to leverage this complexity by assuming
% (or in some cases proving) that, as $t\to\infty$, such a system will settle into a
% state of equilibrium in which all possible states are ``equiprobable''.
\end{example}

% Although one can make sense of the notion of an equiprobable probability distribution
% on $S_E$ in the above example, it is simpler (and more relevant to this thesis) to
% consider the case when $S_E$ is finite.
If $S_E = H^{-1}(E)$ is finite\footnote{We can view such a system as an approximation to a traditional continuous system with $S_E$ uncountable.}, then one can easily determine that the maximum entropy measure on $S_E$ is simply the uniform measure. For a system with finite state space $\Omega$ and Hamiltonian $H$, we define the \emph{microcanonical distribution} with energy $E$ to be the uniform measure on $S_E$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Canonical ensemble}

In practice, most systems of interest are not truly isolated: they may exchange
energy with their environments. Everyday experience, however, suggests that
a physical system that is left undisturbed for a sufficiently long time will achieve \emph{thermal equilibrium}, in which the system's temperature is constant and equal to that of its surroundings. We define the \emph{canonical ensemble} for a system with state space $\Omega$ and Hamiltonian $H$ on
$\Omega$ to be the maximum entropy distribution subject to the fixed average energy constraint
\begin{equation}
\int H \; d\mu = E.
\end{equation}
It can be shown by the method of Lagrange multipliers that the canonical ensemble is given by the \emph{Gibbs measure}
\begin{equation}
d\mu_\beta = \frac{1}{Z_\beta} e^{-\beta H} d\lambda,
\end{equation}
where
\begin{equation}
Z_\beta = \int e^{-\beta H} \; d\lambda
\end{equation}
is the normalizing constant, known as the \emph{canonical partition function}.
The quantity $\beta = \beta(E)$, which arises as a Lagrange multiplier, is known as the \emph{inverse temperature}.

The \emph{free energy} of this system is defined by
\begin{equation}
F_\beta = -\frac{1}{\beta} \log Z_\beta.
\end{equation}
This definition may seem obscure at first, but is elucidated by a computation of the entropy $h_\lambda(\mu_\beta)$ with $\beta = \beta(E)$, which implies that
\begin{equation}
F_\beta = E - \frac{1}{\beta} h_\lambda(\mu_\beta).
\end{equation}
This is the famous thermodynamic relation between free energy, internal energy $E$, temperature $1/\beta$, and entropy.


In the context of spin systems, there is a natural mathematical reason for studying measures of the above form. This is the Hammersley-Clifford theorem, which states that any Markov random field (a spatial generalization of a Markov chain) on a graph has a representation as a Gibbs measure whose Hamiltonian is a sum of ``local'' interactions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% COMMENTED OUT: Canonical measure as marginal of microcanonical %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% This situation can be modeled as follows: call the system of interest system $A$ and
% its surroundings system $B$. We assume that $B$ behaves as a \emph{thermal reservoir},
% meaning that it is so large that its temperature may be assumed to be effectively
% constant, even if system $A$ is at a different temperature.
% It is then reasonable to assume that the total system $A \times B$ is isolated.

% \begin{example}
% Let $\Omega_1$ and $\Omega_2$ be the state spaces of systems $A$ and
% $B$ and let $H_i : \Omega_i \to \R$ be their respective Hamiltonians.
% The system $A \times B$ then has state space $\Omega_1 \times \Omega_2$.
% If we assume that the contribution to the energy due to interactions between systems $A$
% and $B$ is negligible, then the Hamiltonian of $A \times B$ is the function $H : \Omega \to \R$
% defined by $H(\omega_1, \omega_2) = H_1(\omega_1) + H_2(\omega_2)$.

% Let us assume that the 
% Let $S^i_{E_i} = H_i^{-1}(E_i)$ and $S_E = H^{-1}(S_E)$ and assume that $|S^i_{E_i}| < \infty$
% for any $E_i$. Then
% \begin{equation}
% S_E = \bigcup_{E_1=0}^E S^1_{E_1} \times S^2_{E-E_2}
% \end{equation}
% is finite for all $E$.
% % Suppose that $S_E$ is compact so that the microcanonical ensemble $\mu_E$ on $S_E$ is well-defined.

% For any $E_2 \in \R$, let $S^2_{E_2} = H_2^{-1}(E_2)$. Then the marginal distribution $\mu^1_E$
% of $\mu$ on $\Omega_1$ is given by
% \begin{equation}
% \mu^1_E(\omega_1)
%   =
% \sum_{\omega_2:\omega\in S_E} \mu_E(\omega)
%   =
% \frac{\# S^2_{E-H_1(\omega_1)}}{\# S_E}
%   \propto
% e^{h^2_{E-H_1(\omega_1)}},
% \end{equation}
% where
% \begin{equation}
% h^2_{E_2} = \log |S^2_{E_2}|
% \end{equation}
% is the \emph{entropy} of the microcanonical ensemble on $S^2_{E_2}$.

% If $E_2 \mapsto h^2_{E_2}$ is $C^1$, then we have the first-order expansion
% \begin{equation}
% h^2_{E - H_1(\omega_1)}
%   =
% h^2_E - \dd{h^2_E}{E} H_1(\omega_1) + O(H_1(\omega_1)^2).
% \end{equation}
% Thus,
% \begin{equation}
% e^{-h^2_{E-H_1(\omega_1)}}
%   \approx
% C e^{-\beta H_1(\omega_1)},
% \end{equation}
% where $\beta = \dd{h^2_E}{E}$ and $C$ is a constant independent of $\omega_1$.
% The assumption that system $B$ is a ``heat bath'' then amounts to saying that
% $E - H_1(\omega_1)$ is such a negligible perturbation of $E$ that the first-order
% approximation above accurately represents the marginal density of $\mu^1_E$.
% \end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Grand canonical ensemble}

Consider a physical system that is free to exchange both energy and particles with its environment. We suppose the ``number of particles'' of this system takes values in a measurable set $\interval \subset \R$. For
$T \in \interval$, let $\Omega_T$ be a space of $T$-particle configurations and let $H_T : \Omega_T \to \R$ be the Hamiltonian on $\Omega_T$. The state space for the full system is then given by
$\Omega = \bigsqcup_{T \in \interval} \Omega_T$, where $\sqcup$ denotes the disjoint union. For $\omega\in\Omega$, let $|\omega|$ be the unique value of
$T$ such that $\omega \in \Omega_T$. We define $H : \Omega \to \R$ by
$H(\omega) = H_{|\omega|}(\omega)$.

The \emph{grand canonical ensemble} for this system is defined to be the maximum entropy measure subject to the constraints of fixed average energy and fixed average number of particles. It can be shown that the grand canonical ensemble is given by a measure
\begin{equation}
d\mu_{\beta,\nu}
  =
\frac{1}{Z_{\beta,\nu}} e^{-\beta H(\omega) - \nu |\omega|},
\end{equation}
where $Z_{\beta,\nu}$ is the normalizing constant, known as the \emph{grand canonical partition function}. We call $\nu$ the \emph{fugacity}. Since the
$\nu |\omega|$ term can be absorbed into the Hamiltonian, the measure $\mu_{\beta,\nu}$ is really just an ordinary Gibbs measure as defined in the previous section. For this reason, the distinction between canonical and grand canonical ensembles is an informal one.

\begin{rk}
Note that the grand canonical partition function is given by
\begin{equation}
Z_{\beta,\nu}
  =
\int_\interval e^{-\nu T} Z_\beta^{(T)} \; dT,
\end{equation}
where $Z^{(T)}_\beta$ is the canonical partition function of $H_T$. Thus,
$Z_{\beta,\nu}$ is the Laplace transform of the canonical partition function
viewed as a function of $T$.
\end{rk}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Graphs}

Most systems of interest do not have a finite (or even countable) state space. Nevertheless, finite systems serve as natural approximations of real systems. For instance, a natural way to approximate spatially-extended systems is by defining models on graphs.

An \emph{undirected graph} is a pair $\graph = (\vertices, \edges)$, where $\vertices$ is a set of \emph{vertices} and $\edges$ is a set of
\emph{edges} $\{ x, y \}$ with $x, y \in \vertices$; we will write $x \sim y$ if $\{ x, y \} \in \edges$. We will assume that $\vertices$ is countable and that there are no \emph{self-loops} $\{ x \} \in \edges$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Functions on graphs}

Let $\varphi \in (\R^n)^\vertices$. We denote the components of $\varphi$ by
$\varphi^i_x \in \R$ for $x \in \vertices$ and $i = 1, \ldots, n$. The Euclidean inner product on $(\R^n)^\vertices$ is defined by
\begin{equation}
\varphi\cdot\tilde\varphi
  =
\sum_{x\in\vertices} \varphi_x \cdot \tilde\varphi_y
  =
\sum_{i=1}^n \sum_{x\in\vertices} \varphi^i_x \tilde\varphi^i_x
\end{equation}
and the Euclidean norm $|\cdot|$ is defined by
\begin{equation}
|\varphi|^2 = \varphi \cdot \varphi.
\end{equation}
A $\vertices\times\vertices$ matrix $M$ acts on $\varphi$ via
\begin{equation}
(M \varphi)_x = \sum_{y\in\vertices} M_{xy} \varphi_y.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The graph Laplacian}

Let $\jay$ be a $\vertices\times\vertices$ matrix with $\jay_{xy} \ge 0$ for all $x, y$ with equality if and only if $\{ x, y \} \notin \edges$. The pair
$(\graph, \jay)$, which we will usually abbreivate as $\graph$ with $\jay$ implicit, is an example of a \emph{weighted} graph.

Define the diagonal $\vertices\times\vertices$ matrix $\diag$ by
\begin{equation}
\diag_{xx} = d_x = \sum_{y \sim x} J_{xy}.
\end{equation}
We will say that $\graph$ is $d_0$-regular if $d_x = d_0$ for all $x$.

The \emph{(massless) graph Laplacian} on $\graph$ is defined by
\begin{equation}
-\lap = \diag - \jay.
\end{equation}
We also define the \emph{massive Laplacian} with squared \emph{mass} $m^2 > 0$
by
\begin{equation}
-\lap + m^2.
\end{equation}
Note that
\begin{equation}
\varphi \cdot (-\lap \varphi)
  =
\frac{1}{2} \sum_{x,y\in\vertices} J_{xy} |\varphi_x - \varphi_y|^2
  \ge
0,
\end{equation}
so $-\lap$ is positive-semidefinite.

\begin{example}
An important case is when $\jay$ has $\{0, 1 \}$-valued entries. In this case, $d_x$ is the \emph{degree} of $x$ in $\graph$ and we denote $\lap$ by
$\Delta$, which has entries given by
\begin{equation}
-\Delta_{xy} = d_x \1_{x=y} - \1_{x \sim y}.
\end{equation}
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Green function}

If $m^2 > 0$, then $-\lap + m^2$ is positive-definite, hence invertible with inverse
\begin{equation}
(-\lap + m^2)^{-1} = (m^2 + D)^{-1} \sum_{n=0}^\infty Z^n P^n,
\end{equation}
where
\begin{align}
Z = (m^2 + D)^{-1} D,
  \quad
P = D^{-1} J.
\end{align}
Let $z_x$ denote the diagonal elements of $Z$. The \emph{Green function} for
$-\lap + m^2$ is the kernel of $(-\lap + m^2)^{-1}$, given by
\begin{equation}
C(x, y)
  =
(m^2 + d_x)^{-1} \sum_{n=0}^\infty z_x^n P^n_{xy}.
\end{equation}

% Let $\jay$ be a $\vertices \times \vertices$
% matrix with $J_{xx} = 0$ and $J_{xy} \ge 0$ for all $x, y \in \vertices$ and suppose
% that $\jay$ has summable rows: $\sum_{y\in\vertices} J_{xy} < \infty$. Let $\diag$ be
% the diagonal matrix with entries $D_{xx} = \sum_{y\in\vertices} J_{xy}$, and let $A = \diag - \jay$.

% \todo{The $Q$ matrix will be $Q = -A$, the matrix $\jay$ will be the (ferromagnetic) Ising interaction,
% and $A$ will be the interaction for the $|\varphi|^4$ model.
% E.g.\ $A = -\Delta + m^2$ has positive diagonal entries. Recall that
% $\Delta_{xy} = \1_{x \sim y} - 2 d \1_{x=y}$.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Spin systems}

An $n$-component \emph{field} or \emph{spin configuration} on $\vertices$
with spins in $S \subset \R^n$ is an element of $\Omega = S^\vertices$.
% A \emph{spin system} is a probability measure $d\mu$ on $\Omega$.
Suppose that $S$ is endowed with a measure $d\lambda^0$ and define the product measure
\begin{equation}
d\lambda(\varphi) = \prod_{x\in\vertices} d\lambda^0(\varphi_x)
\end{equation}
on $\Omega$.
Given a (measurable) Hamiltonian function $H : \Omega \to \R$, we wish to define the measure
\begin{equation}
d\mu_\beta(\varphi)
  =
\frac{1}{Z_\beta} e^{-\beta H(\varphi)} d\lambda(\varphi)
\end{equation}
on $\Omega$.

However, there are some problems with this definition when $\vertices$ is infinite. For one, $d\lambda$ may not be well-defined (for instance if
$S = \R$ and $d\lambda^0$ is Lebesgue measure). Another issue is that it may be difficult to define a reasonable choice of $H$ on the infinite product space
$\Omega$. For this reason, we temporarily restrict our attention to finite graphs, and define spin systems on such graphs as above. In many cases, the Hamiltonian will depend on one or more parameters; in this case, adjusting $\beta$ is equivalent to rescaling these parameters and so we will usually drop $\beta$
(or set $\beta = 1$).

Let us fix\footnote{In general, some quantities we define will depend on the choice of vertex. However, we will ultimately be interested in the transitive graph $\graph = \Zd$ for which this choice is irrelevant.} a vertex
$0 \in \vertices$. The \emph{two-point function} for a spin system $\mu_\beta$ is defined by
\begin{equation}
G_x(\mu_\beta)
  =
\frac{1}{n}
(\mu_\beta(\varphi_0 \cdot \varphi_x)
  -
\mu_\beta(\varphi_0) \cdot \mu_\beta(\varphi_x)).
\end{equation}
The \emph{magnetization} of $\mu_\beta$ is the normalized expected value
\begin{equation}
\frac{1}{n} \mu_\beta(\varphi_0).
\end{equation}
Let $h \in (\R^n)^\vertices$ be an \emph{external field} and consider the spin system with Hamiltonian $H(\varphi) + h \cdot \varphi$;
the \emph{(magnetic) susceptibility} is defined as the directional derivative of the magnetization of such a system in the constant direction. \todo{Then for translation-invariant spin systems (on transitive graphs), we can show that}
\begin{equation}
\chi(\mu_\beta) = \sum_{x\in\vertices} G_x(\mu_\beta).
\end{equation}

We will mainly be concerned with \emph{ferromagnetic} spin systems, for which the Hamiltonian has the form
\begin{equation}
H(\varphi) = \sum_{x, y \in \vertices} \varphi_x \cdot J_{xy} \varphi_y,
\end{equation}
where (recall) $J_{xy} \ge 0$. Thus, $H(\varphi)$ is smaller (and $d\mu_\beta(\varphi)$ larger) when the spins align (when $\varphi_x = \varphi_y$ for $x \sim y$).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Gaussian measures and the free field}

Let $S = \R^n$ and let $C$ be a positive-definite symmetric $\vertices\times\vertices$ matrix. The $n$-component \emph{Gaussian measure} $d\mu_C$ on
$\Omega$ with mean $0$ and \emph{covariance} $C$ is defined by the Hamiltonian
\begin{equation}
H_C(\varphi) = \frac{1}{2} \varphi \cdot C^{-1} \varphi.
\end{equation}
This is essentially the simplest choice of non-constant
Hamiltonian\footnote{Note that $e^{-\beta H}$ is not integrable if $H$ is linear. Also, by completing the square, there is no additional generality gained by adding a linear term to $H_C$.}.
% is the unique measure $\mu$ on $(\R^n)^\vertices$ with characteristic function
% \begin{equation}
% \hat\mu(\xi)
%   \coloneqq
% \int_{(\R^n)^\vertices} \mu(d\varphi) \; e^{i \varphi \cdot \xi}
%   =
% e^{-\frac{1}{2} \xi \cdot C \xi}.
% \end{equation}
% If $\vertices$ is finite, then the Lebesgue measure $d\varphi$ on $(\R^n)^\vertices$
% is well-defined and
The partition function can be computed explicitly, giving\footnote{Here, we have employed our convention of setting $\beta = 1$ when the Hamiltonian depends on a parameter ($C$ in this case).}
\begin{equation}
d\mu_C(\varphi)
  =
\frac{1}{\sqrt{\det(2\pi C)}} e^{-\frac{1}{2} \varphi\cdot C^{-1}\varphi} d\varphi.
\end{equation}
By \emph{Wick's theorem}, the magnetization is $0$ and the two-point function is the covariance:
\begin{equation}
\int \varphi_a \cdot \varphi_b \; d\mu(\varphi) = C_{ab}.
\end{equation}

An important case is the \emph{massive Gaussian free field} on $\graph$, for which the covariance is equal to the massive Green function:
$C = (-\lap + m^2)^{-1}$. The Gaussian free field is an example of a ferromagnetic spin system since $J$ has nonnegative entries.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The \texorpdfstring{$|\varphi|^4$}{phi4} spin model}

Let $S = \R^n$. The $|\varphi|^4$ spin model on $\graph$ is defined by the quartic Hamiltonian
\begin{equation}
H_{g,\nu}(\varphi)
  =
\sum_{x\in\vertices}
\left(
  \frac{1}{4} g |\varphi_x|^4
    +
  \frac{1}{2} \nu |\varphi_x|^2
    +
  \frac{1}{2} \varphi_x \cdot (-\lap \varphi)_x
\right),
\end{equation}
where $g > 0$ and $\nu\in\R$. This is another example of a ferromagnetic spin system. Note that when $\nu > 0$, we have
$H_{g,\nu} = g |\varphi|^4 + H_C$, where $C = (\nu - \lap)^{-1}$ is the covariance of the Gaussian free field with mass $\nu$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The \texorpdfstring{$O(n)$}{O(n)} spin model}

Let $S = S^{n-1} \subset \R^n$ be the unit $(n-1)$-sphere equipped with the surface measure $d\lambda^0$ (in particular, $S^0 = \{ \pm 1 \}$, which is equipped with the counting measure). The $O(n)$ model is defined by the Hamiltonian
\begin{equation}
H_J(\sigma) = -\frac{1}{2} \sigma \cdot J \sigma,
\end{equation}
which is clearly ferromagnetic.

The corresponding Gibbs measure arises naturally as a limiting case of the
$|\varphi|^4$ measure $d\mu_{g,\nu}$ on a $d_0$-regular graph. Indeed, in this case the $|\varphi|^4$ Hamiltonian can be written as
\begin{equation}
H_{g,\nu}(\varphi)
  =
\sum_{x\in\vertices}
\left(
  \frac{1}{4} g |\varphi_x|^4
    +
  \frac{1}{2} (\nu + d_0) |\varphi_x|^2
\right)
  -
\frac{1}{2} \varphi \cdot \jay \varphi
\end{equation}
Thus, $d\mu_{g,\nu} \Rightarrow d\mu_J$ if we take the limit $g\to\infty$ with $\nu = -(d_0 + g / 2)$.

The case $n = 1$ is the celebrated \emph{Ising model}. When $n = 2, 3$, we get the \emph{XY model} and the \emph{classical Heisenberg model}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The infinite-volume limit}

The presence of a phase transition in a physical system is signalled by an abrupt (i.e.\ non-analytic) change in an observable quantity as a parameter is varied. In fact, a $p$-th order phase transition is usually said to occur when the free energy has a discontinuous derivative of order $p$ with respect to an external field (but continuous derivatives of order less than $p$). However, the spin systems we have defined above all have smooth free energy (since the Hamiltonians are smooth functions). Ultimately, the reason we cannot detect phase transitions in these systems is that we have defined them on finite graphs. Thus, we are forced to face the problem of defining spin systems on an infinite graph.

A natural approach to defining such systems is via a procedure known as the
\emph{infinite-volume limit}, which we describe here. For any
finite subgraph $\Lambda \subset \graph$, let $H_\Lambda$ be the Hamiltonian
of one of the above spin systems on $\Lambda$ and let $\mu_\Lambda$ be the
corresponding Gibbs measure (which we can view as a measure on the full state
space $\Omega$).

Let $\Lambda_N \subset \graph$ be a sequence of subgraphs that exhaust
$\graph$, i.e.\ $\Lambda_N \uparrow \graph$. If the limits
\begin{equation}
\lim_{N\to\infty} \int f \; d\mu_{\Lambda_N}
\end{equation}
exist for a sufficiently rich class of functions $f$ (such as all bounded continuous functions), then they define a measure $\mu$ on $\Omega$ (with $\mu(f)$ the above limit), which we call a \emph{Gibbs state} or
\emph{infinite-volume Gibbs measure} on $\Omega$.

We remark that there is a more general approach to the study of spin systems in infinite volume developed by Dobrushin, Lanford, and Ruelle. We do not detail their approach here, but merely mention that, for the examples above, this approach involves defining a Gibbs measure for the collection
$H = (H_\Lambda)$ of Hamiltonians directly as a measure on $\Omega$ satisfying a system of constraints on its conditionals measures. This is somewhat in the spirit of Kolmogorov's consistency conditions with the importance difference that the resulting collection $\gibbs_\beta(H)$ of Gibbs states at inverse temperature
$\beta$ need not consist of only a single element. This is significant due to the interpretation of distinct elements of $\gibbs(H)$ as corresponding to different phases of the system under consideration.

For many models, including the $O(n)$ and $n$-component $|\varphi|^4$ models on $\Zd$ with $d > 2$, it is known that there exists a critical inverse temperature $\beta_c < \infty$ such that
$|\gibbs_\beta(H)| = 1$ if and only if $\beta \le \beta_c$ (\REF). In this thesis, our main concern is with the behaviour at $\beta_c$ and as
$\beta \uparrow \beta_c$. Thus, we need not concern ourselves with the precise nature of the infinite-volume limit.

\begin{rk}
Our interest will be in translation-invariant systems on $\Zd$, for which a particular approach to the infinite-volume limit will be convenient. Namely, for $L > 1$ we will let $\Lambda_N = \Zd/L^N\Zd$ be the discrete torus, which we view as a subset of $\Zd$. This allows us to preserve
translation-invariance of these models in finite volume. Strictly speaking, $\Lambda_N$ is not a subgraph of $\Zd$; nevertheless, it can be shown that the infinite-volume limit (if it exists) is a Gibbs measure in the usual sense; see \cite[Example 4.20]{Georgii11} for details.
\end{rk}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% COMMENTED OUT: Phase transitions in infinite volume %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \subsection{Phase transitions in infinite volume}

% The presence of a phase transition in a physical system is signalled by an abrupt (i.e.\ non-analytic) change in an observable quantity as a parameter is varied. In fact, a $p$-th order phase transition is usually said to occur when the free energy has a discontinuous $p$-th derivative (but continuous derivatives of order less than $p$). However, the spin systems we have defined above all have smooth free energy (since the Hamiltonians are smooth functions). Ultimately, the reason we cannot detect phase transitions in these systems is that we have defined them on finite graphs. Thus, we are forced to face the problem of defining spin systems on an infinite volume $\graph$. Here we briefly outline the solution to this problem according to the theory of Dobrushin, Lanford, and Ruelle.

% We wish to define a measure corresponding to an ``infinite-volume Hamiltonian''
% \begin{equation}
% H^\Phi(\varphi) = \sum \Phi_A(\varphi),
%   \quad
% \varphi \in \Omega
% \end{equation}
% where the sum is over all finite subsets $A \subset \vertices$ and the $\Phi_A$
% depend only on the values of $\varphi$ in $A$. Although $H^\Phi$ is typically a fictional object, the $\Phi_A$ are well-defined. Thus, given a finite subset $\Lambda\subset\vertices$ and a choice of \emph{boundary condition}
% $\xi\in\Omega$, we can define the \emph{finite-volume} Hamiltonian
% $H^\xi_\Lambda : \Omega \to \R$ on $\Lambda$ by
% \begin{equation}
% H^\xi_\Lambda(\varphi) = \sum \Phi_A(\varphi_{\Lambda} \xi_{\Lambda^c}),
% \end{equation}
% where the sum is over all finite sets $A$ intersecting $\Lambda$,
% $\varphi_{\Lambda} \in S^{\Lambda}$ is the restriction of $\varphi$ to
% $\Lambda$, and $\varphi_{\Lambda} \xi_{\Lambda^c} \in \Omega$ is the concatenation of $\varphi_{\Lambda}$ and $\xi_{\Lambda^c}$. We then say that
% $\mu$ is a \emph{Gibbs measure} if for $\mu$-almost every choice of boundary condition $\xi$, the conditional distribution $\mu(d\varphi \mid \varphi_{\Lambda^c} = \xi_{\Lambda^c})$ is given by the finite-volume Gibbs measure
% \begin{equation}
% \mu^\Phi_\Lambda(\varphi \mid \xi)
%   :=
% \frac{1}{Z^\Phi_\Lambda(\xi)}
% e^{-H^\Phi_\Lambda(\varphi_\Lambda \xi_{\Lambda^c})}
% d\lambda^\Lambda(\varphi),
% \end{equation}
% where $d\lambda^\Lambda(\varphi) = \prod_{x\in\Lambda} d\lambda^0(\varphi_x)$.
% We denote the collection of all such Gibbs measures by $\gibbs(\Phi)$.

% \subsubsection{The infinite-volume limit}

% It can be checked that any finite-volume Gibbs measure (seen as a measure on $\Omega$) is a Gibbs measure in the above sense. More general Gibbs measures can be constructed by an explicit procedure known as the infinite-volume limit: generally speaking, one begins with a sequence $\Lambda_N \subset \vertices$ of finite subsets with $\Lambda_N\uparrow\vertices$. Letting $H_N$ be a Hamiltonian that only depends on the spins in $\Lambda_N$, one proceeds by taking the weak limit of the Gibbs measures $\mu_N$ corresponding to $H_N$. If the sequence $(\Lambda_N, H_N)$ is appropriately chosen, then the weak limit will exist and be an element of $\gibbs(\Phi)$.

% \subsubsection{Periodic boundary conditions}

% When $\graph = \Zd$ and the $\Phi$ are translation-invariant\footnote{That is, $\Phi_A = \Phi_{A+i}$ for any $i\in\Zd$.}, there is a particularly convenient approach to taking the infinite-volume limit. Suppose that $\Phi$ has finite range\footnote{This is a mere convenience. This construction extends to potentials with infinite range.}, i.e.\ $\Phi_A = 0$ whenever $|A| > R$ for some $R$. We let $\Lambda_N = \Zd/L^N\Zd$ be the discrete torus of side $L^N$ (for $L > 1$) and identify the $\Lambda_N$ with an increasing sequence of subsets of $\Zd$ (since $\Phi$ is translation-invariant, it is not important how this identification is made). Then any subset $A \subset \Zd$ of side
% $|A| \le R$ can be identified with a subset of $\Lambda_N$ for $N$ sufficiently large. For such $N$, we let
% \begin{equation}
% H_N(\varphi) = \sum \Phi_A(\varphi),
% \end{equation}
% where the sum is over subsets of $\Lambda_N$ of size at most $R$. \todo{I don't think this is right.} It is shown in \cite[Example 4.20]{Georgii11} that, if $\mu_N$ converges weakly to a measure $\mu$, then
% $\mu \in \gibbs(\Phi)$. The measure $\mu$ is said to have \emph{periodic} boundary conditions.

% \begin{example}
% Let $\graph = \Zd$ and let $\Lambda_N = \Zd/L^N\Zd$ for $L > 1$.
% Let $G_{N,x}$ denote the two-point function of a spin system on $\Lambda_N$.
% We define the two-point function on $\Zd$ by the limit
% \begin{equation}
% G_x = \lim_{N\to\infty} G_{x,N}.
% \end{equation}
% By the previous example, if the limit $\mu$ of the $\mu_N$ exists, then
% \begin{equation}
% G_x = \frac{1}{n} \int d\mu(\varphi) \varphi_0 \cdot \varphi_x.
% \end{equation}
% \end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Models of walks}

For simplicity, we take $\graph$ to be a $d_0$-regular vertex-transitive graph and fix a designated vertex $0 \in \vertices$.
% We let $\interval_T$ denote either of the following choices for all $T \ge 0$:
% \begin{equation}
% \interval_T
%   =
% \begin{cases}
% \{ 0, \ldots, \lfloor T \rfloor \} \\
% [0, T]
% \end{cases}.
% \end{equation}
For any right-continuous function $\omega : [0, T] \to \vertices$, we define
$\tau_n = \tau_n(\omega)$ inductively by setting $\tau_0 = 0$ and
\begin{equation}
\tau_{n+1} = \inf(t > \tau_n : \omega_t \ne \omega_{\tau_n}).
\end{equation}
We call $\omega$ a \emph{walk} of length $T$ if
$\{ \tau_n : n \in \Z_+ \}$ does not have any cluster points and
$\omega_{\tau_n} \sim \omega_{\tau_{n+1}}$ for all $n$; thus, $\omega$
only jumps between neighbouring vertices.
% A \emph{discrete-time} (respectively,
% \emph{continuous-time}) walk of length $T$ is a walk indexed by
% $\{ 0, \ldots, \lfloor T \rfloor \}$ (respectively, $[0, T]$).
A \emph{discrete-time} walk is one for which $\tau_n = n$ for all $n$.
Let $\Wcal_T$ denote the set of walks of length $T$ with $\omega_0 = 0$ and set $\Wcal := \bigcup_{T \geq 0} \Wcal_T$.

A model of walks is determined by a choice of finite measure $d\mu_T$ on
$\Wcal_T$ for each $T$. All models we consider will be given by canonical Gibbs measures
\begin{equation}
d\mu_T(\omega) = \frac{1}{c_T} e^{-H_T(\omega)} \; d\lambda_T(\omega),
\end{equation}
with respect to some measure $\lambda_T$ on $\Wcal_T$ (we have denoted the partition function by $c_T$).
% We will assume that models of discrete-time walks satisfy $\mu_T = \mu_{\lfloor T \rfloor}$ for all $T$
% (note that both are measures on $\Wcal_{\lfloor T \rfloor}$ in this case).
Given such a model, the corresponding grand canonical ensemble is given by
\begin{equation}
d\mu(\omega)
  =
\frac{1}{\chi(\nu)}
e^{-\nu |\omega| - H_{|\omega|}(\omega)}
d\lambda_{|\omega|}(\omega)
\end{equation}
and the grand canonical partition function, denoted $\chi(\nu)$, is known as the \emph{susceptibility}. In this setting, the fugacity $\nu$ is usually referred to as the \emph{killing rate}.
% The grand canonical partition function, denoted $\chi$, is known as the \emph{susceptibility}.
Note that
\begin{equation}
\mu(\cdot \mid \Wcal_T) = \mu_T.
\end{equation}

Let $\Wcal_T(x) \subset \Wcal_T$ denote the set of walks in $\Wcal_T$ from $0$ to $x$ and let $\Wcal(x) = \bigcup_{T \ge 0} \Wcal_T(x)$. We define the
\emph{two-point function}
\begin{equation}
G_x(\nu) = \mu(\Wcal(x)) \int_0^\infty e^{-\nu T} c_T(x) \; dT,
\end{equation}
where
\begin{equation}
c_T(x) = \int_{\Wcal_T(x)} e^{-H_T} \; d\lambda_T.
\end{equation}
% For $x \in \vertices$, let $\Wcal_T(x) \subset \Wcal_T$ denote the collection of walks $\omega \in \Wcal_T$ with $\omega_0 = a$ and $\omega_T = x$. The conditional measure $\mu^x_T = \mu_T(\cdot \mid \Wcal_T(x))$ is given by
% \begin{equation}
% \mu^x_T(d\omega) = \frac{\mu_T(d\omega) \1_{\Wcal_T(x)}(\omega)}{c_T(x)},
% \end{equation}
Note that
\begin{equation}
\chi(\nu) = \sum_{x\in\vertices} G_x(\nu),
\end{equation}
which is consistent with the analogous relation for spin systems. Later we will discuss the relationship between the two-point function for walks and spin systems.

The \emph{critical point} $\nu_c$ for a model of walks is defined
\begin{equation}
\nu_c = \inf (\nu : \chi(\nu) < \infty).
\end{equation}

% \todo{We really should not be defining terms for discrete- and continuous-time
% walks separately as (for example) $c_n$ in discrete-time is not the same as in
% continuous time. We should define discrete-time objects as the skeletons of
% continuous-time ones.}

% \begin{rk}
% In the discrete-time case, we let $z = e^{-\nu}$ and write
% \begin{equation}
% \mu(\omega)
%   =
% \frac{1 - e^{-\nu}}{\nu} z^{|\omega|} \mu_{|\omega|}(\omega)
% % \mu(f)
%   % =
% % \frac{1 - e^{-\nu}}{\nu} \sum_{n=0}^\infty z^n \int_{\Wcal_n} d\mu_n(\omega) \; f(\omega).
% \end{equation}
% with
% \begin{equation}
% \chi(\nu) = \frac{1 - e^{-\nu}}{\nu} \sum_{n=0}^\infty c_n z^n.
% \end{equation}
% Similarly,
% \begin{align}
% G_x(z) = \frac{1 - e^{-\nu}}{\nu} \sum_{n=0}^\infty c_n(x) z^n.
% \end{align}
% \end{rk}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Simple random walk}

% \todo{Restrict to $d_0$-regular graph (otherwise, generating function has $z_x$ instead of $z$).
% Work towards showing that generating function (for unkilled SRW) is inverse of:
% \begin{equation}
% 1 - z P = 1 - (z / d_0) J = (z / d_0) (m^2 + d_0 - J)
% \end{equation}
% with $m^2 = d_0 (1 - z) / z$.}

% The \emph{simple random walk} on $\graph$ is the Markov chain $X_n$ with transition matrix $P = d_0^{-1} J$. This induces the measure $\lambda_n$ on $\Wcal_n$ defined by
% \begin{equation}
% \lambda_n(\omega) = \Pr(X_k = \omega_k, \, k \le n \mid X_0 = 0).
% \end{equation}
% Then
% \begin{equation}
% c_n(0, x) = \Pr(X_n = x \mid X_0 = 0) = P^n_{0x}
% \end{equation}
% and
% \begin{equation}
% G_x = \sum_{n=0}^\infty (z P)^n_{0x} = (1 - z P)^{-1}_{0x},
% \end{equation}
% which converges for $|z| < 1$. Letting $m^2 = d_0 (1 - z) / z > 0$, we see that
% \begin{equation}
% 1 - z P = (z / d_0) (m^2 + L),
% \end{equation}
% so the two-point function is just the Green function for the massive Laplacian.

Let $\generator = -\lap$
Then $\generator$ is the generator of the $\vertices$-valued Markov process
$X = (X_t)_{t \ge 0}$ with transition probabilities
\begin{equation}
\Pr(X_t = y \mid X_0 = x) = (e^{-t \lap})_{xy},
\end{equation}
called the \emph{continuous-time simple random walk} on $\graph$.
We define the measure $\lambda_T$ on $\Wcal_T$ by
\begin{equation}
\lambda_T(d\omega) = \Pr(X_t = d\omega_t, \, t \le T \mid X_0 = 0).
\end{equation}
For the corresponding Gibbs measures (with $H_T \equiv 0$), we have
\begin{equation}
c_T(x) = (e^{-t \lap})_{0x},
  \quad
G_x = (\nu - \lap)^{-1}_{0x}
\end{equation}
for $\nu > 0$. Thus, the two-point function is the Green function for the
massive Laplacian.

\begin{example}
The discrete-time simple random walk is the Markov chain given by
$X_n = X_{\tau_n}$. Consider the discrete-time simple random walk on $\Zd$, for which $X_n = X_0 + \sum_{i=1}^n Y_i$, where $Y_i$ are iid random variables in $\{ e \in \Zd : |e| = 1 \}$ with $\Ex Y_i = 0$. Thus, $\Ex |X_n|^2 = n$ and the central limit theorem implies that
$X_n / \sqrt n \Rightarrow \Ncal(0, 1)$. More generally, Donsker's invariance principle states that a rescsaled version of $X$ converges to Brownian motion on $\Rd$.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Self-avoiding walk}

A \emph{self-avoiding walk} of length $n$ on $\graph$ is a discrete walk $\omega\in\Wcal_n$ that has no self intersections, i.e.\ $\omega_x = \omega_y$ if and only if $x = y$. We equip the collection of all self-avoiding walks of length $n$ with the uniform measure $\mu_n$.

These measures do not form a consistent family due to the possibility of ``traps''. That is, the equality
\begin{equation}
\mu_{|\omega|}(\omega) = \sum_{\tilde\omega \supset \omega} \mu_{|\tilde\omega|}(\tilde\omega)
\end{equation}
does not hold for all $\omega\in\Wcal$ (the sum here is over all self-avoiding walks extending $\omega$).
% \begin{wrapfigure}{R}{0.4\textwidth}
% \vspace{-0.5cm}
% \begin{center}
%   \includegraphics[width=0.3\textwidth]{figures/trapped}
%   \caption{A trapped self-avoiding walk}
%   \label{fig:trap}
% \end{center}
% \vspace{-0.5cm}
% \end{wrapfigure}
For instance, consider the self-avoiding walk $\omega\in\Wcal_7$ on $\Zd$ in
Figure~\ref{fig:trap}. This walk has positive probability under $\mu_7$ but,
since there are no self-avoiding walks extending $\omega$, the sum on the right-hand side above is $0$.

As a result, the methods of stochastic processes cannot be directly used to study the self-avoiding walk. The existence of traps also contributes to the combinatorial difficulty of studying self-avoiding walk; for instance, it is not clear how to express $c_{n+1}$ (the number of $(n+1)$-step self-avoiding walks) in terms of $c_n$.

% \begin{figure}[!htb]
% \centering
% \caption{A trapped self-avoiding walk}
% \includegraphics{figures/trapped}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Weakly self-avoiding walk with self-attraction}

Define the \emph{local time} up to time $T$ of $\omega \in \Wcal$ at
$x \in \Zd$ by
\begin{equation}
\lt^x_T(\omega) = \int_0^T \1_{\omega(S)=x} \; dS.
\end{equation}
In the discrete-time case, $\lt^x_n$ is the number of times $\omega$ visits $x$
and is bounded by $n$. In the continuous-time case, $\lt^x_T$ is almost surely
finite for the continuous-time simple random walk.

We define the \emph{intersection local time}
\begin{equation}
\label{e:ITdef}
I_T(\omega) = \sum_{x\in\vertices} (\lt^x_T)^2
  =
\int_0^T \!\! \int_0^T \1_{\omega(S_1)=\omega(S_2)} \; dS_1 dS_2
\end{equation}
and the \emph{contact self-attraction}
\begin{equation}
\label{e:CTdef}
C_T(\omega) =
  \sum_{x \in \vertices} \sum_{y \sim x} \lt_T^x(\omega) \lt_T^y(\omega)
  = \int_0^T ds \int_0^T dt \; \1_{\omega_{s} \sim \omega_{t}}
\end{equation}
up to time $T$.
% Recall that we have set the inverse temperature equal to $1$.
Given a parameter $\gcc > 0$,
and $\gamma \in \R$, we define
\begin{equation}
\label{e:Udef-neg}
U_{\gcc,\gamma}(f)
=
\gcc \sum_{x\in\vertices} f_x^2
- \frac{\gamma}{2d}
\sum_{x\in\vertices} \sum_{y \sim x} f_x f_y
\end{equation}
for $f : \vertices \to \R$.
The \emph{weakly self-avoiding walk with self-attraction} (WSAW-SA) is defined via the Hamiltonian
\begin{equation}
H_T(\omega) = U_{\gcc,\gamma}(L_T(\omega)).
\end{equation}
We denote the canonical partition function by
\begin{equation}
c_T = c_T(\gcc, \gamma) = E_0 \left( e^{-\gcc I(T) + \gamma C(T)} \right),
\end{equation}
where $0 \in \vertices$ is fixed, and the susceptibility by
\begin{equation}
\chi(\gcc, \gamma, \nu) = \int_0^\infty c_T e^{-\nu T} \; dT.
\end{equation}

In the case $\gamma = 0$, the discrete-time version of this model is known as
the \emph{Domb-Joyce model}. In continuous-time, it is the
\emph{continuous-time weakly self-avoiding walk} (WSAW).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Critical behaviour and universality}

Many systems exhibit \emph{critical behaviour} at or near a particular parameter value. For concreteness, in the setting of the models discussed above, we denote this parameter value here by $\beta_c$ and suppose that it is defined as the small valuest of $\beta$ for which the susceptibility diverges. For spin systems, this is typically the same value that separates the uniqueness regime in which $|\gibbs_\beta| = 1$ from the non-uniqueness regime in which
$|\gibbs_\beta| > 1$.

The critical point is characterized by long-range correlations. Namely, for
$\beta \ne \beta_c$, the two-point function $G_x$ decays exponentially in $x$. Clearly, this cannot be the case at $\beta_c$ if the susceptibility is to diverge and it is expected that $G_x$ scales according to a power there 
(possibly with logarithmic corrections).

A fundamental quantity in the study of critical behaviour is the
\emph{correlation length} $\xi$. On $\Zd$, this is defined to be one over the exponential rate of decay of the two-point function; that is,
\begin{equation}
\xi(\mu) = \limsup_{k\to\infty} \frac{-k}{\log G_{ke}(\mu)},
\end{equation}
where $e \in \Zd$ is a unit vector, whose choice is irrelevant for models for which the two-point function is invariant under lattice rotations.
A related quantity is the \emph{correlation length of order $p$}, defined by
\begin{equation}
\xi_p(\mu) = \left(\frac{\sum_{x\in\Zd} |x|^p G_x(\mu)}{\chi(\mu)}\right)^{1/p}.
\end{equation}
\todo{Heuristic relation bewteen $\xi$ and $\xi_p$.}

We define the \emph{critical exponents} $\eta$, $\gamma$, and $\bar\nu$ by
\begin{align}
G_x       &\sim C_1 |x|^{-(d - 2 + \eta)}, \\
\chi(\nu) &\sim C_2 (\nu - \nu_c)^{-\gamma}, \\
\xi       &\sim C_3 (\nu - \nu_c)^{-\nubar}, \\
\xi_p     &\sim C_4 (\nu - \nu_c)^{-\nubar}
\end{align}
when these relations hold. For walks, it is expected that
\begin{align}
c_T                       &\sim C_5 e^{-\nu_c T} T^{-\gamma}, \\
\langle |X_T|^2 \rangle   &\sim C_6 T^{-\nubar}.
\end{align}
\todo{Motivate the above with an example somewhere.}

\begin{example}
The two-point function is just the massive Green function
$(-\Delta + m^2)^{-1}$ which, on $\Zd$, has the well-known Ornstein-Uhlenbeck decay \todo{(show this; use random walks?)}. Moreover,
\begin{equation}
\chi
  =
\sum_{x\in\vertices} (-\Delta + m^2)^{-1}_{0x}
  =
\sum_{x\in\vertices} \sum_{n=0}^\infty z^n P^n_{0x}
  =
\sum_{n=0}^\infty z^n
  =
(1 - z)^{-1}.
\end{equation}
Thus, there is a critical point at $m^2 = 0$ ($z = 1$).

\todo{See candidacy report or preliminary version of it. For the Green function, see Theorem 1.5.4 in Lawler--Intersections of Random Walks}
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Universality}

It is generally expected that critical exponents depend only on the very coarse structure of a model such as symmetry and ``tail properties'' (e.g.\ global geometry of the underlying graph). For instance, consider a ferromagnetic spin system on $\Zd$ and suppose that the single-spin measure
$d\lambda^0$ is invariant under Euclidean symmetries and whose interaction matrix $J$ is invariant under lattice symmetries ($J_{xy} = J_{Rx,Ry}$ for $R$ a rotation or reflection of $\Zd$) and is of finite-range ($J_{xy} = 0$ for $|x - y|$ sufficiently large). The exponents for such a system are expected only to depend on the dimensions $d$ of the underlying lattice and $n$ of the space of spins.

\todo{Discuss scaling limits}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The upper-critical dimension}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The renormalisation group}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Main results}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Relations between models}

There are a number of close relationships between models of walks and ferromagnetic spin
systems given by a Gibbs measure.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The SRW and DGFF}

\todo{See candidacy report or preliminary version of it. See also misc notes}

For the discrete-time simple random walk, the canonical partition function $c_n$,
which is the number of such walks, is just $(2 d)^n$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Kac-Siegert representation}

\todo{See notes on this}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Self-avoiding walk representations}

\todo{High-temperature expansion of spin system (can be used later to motivate polymer
expansion) to get loop models, De Gennes $n\downarrow0$ limit, McKane/Parisi-Sourlas
and supersymmetry, Grassmann integration and BIS representation (sufficiently general
for WSAW-SA)}