% Parts are the largest structural units, but are optional.
%\part{Thesis}

% Chapters are the next main unit.
\chapter{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Statistical mechanics}

\todo{Restructure this: just introduce Gibbs measure, don't make hard distinction
between canonical and grand canonical. Only mention GCE when discussing walks
later}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Entropy}

Let $(\Omega, \lambda)$ be a measure space. The state of knowledge of a system on
$\Omega$ can be expressed by a probability measure $\mu$ on $\Omega$. Let
$\Mcal_\lambda(\Omega)$ denote the set of probability measures on $\Omega$ absolutely
continuous with respect to $\lambda$. For
$\mu \in \Mcal_\lambda(\Omega)$, we denote the Radon-Nikodym derivative of
$\mu$ with respect to $\lambda$ by $d\mu/d\lambda$ and define the
\emph{entropy} of $\mu$ with respect to $\lambda$ by
\begin{equation}
h(\mu) = h_\lambda(\mu) = -\int_\Omega \log\frac{d\mu}{d\lambda} \; d\mu.
\end{equation}
In many cases, specific information about the system under consideration is available,
so that we may restrict our attention to a subspace $M \subset \Mcal_\lambda(\Omega)$.
The \emph{principle of maximum entropy} \cite{Jaynes57} asserts that, in this
case, the measure best expressing the state of knowledge of the system is given by
\begin{equation}
\hat\mu = \argmax(h_\lambda(\mu) : \mu \in M),
\end{equation}
assuming such a measure exists and is unique.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Microcanonical ensemble}

Consider an \emph{isolated} physical system on $\Omega$, that is, one that cannot
exchange energy with its surroundings. Such a system can be determined by a choice
of function $H : \Omega \to \R$, called the \emph{Hamiltonian}. The value $H(\omega)$
represents the total energy of the system in state
$\omega\in\Omega$.

\begin{example}
Let $\Omega = U^n \times \R^{3n}$, where $U \subset \R^3$, and denote a generic
element of $\Omega$ by $(q, p)$, where $q \in U^n$ and $p \in \R^{3n}$. Then
$\Omega$ is the state space of a system of $n$ point particles
$i = 1, \ldots, n$ with positions $q_i \in U$ and momenta $p_i \in \R^3$. Given
a $C^1$ Hamiltonian $H : \Omega \to \R$, the dynamics of such a system is determined
by \emph{Hamilton's equations}
\begin{align}
\dd{q}{t}   &= \nabla_q H(q(t), p(t)) \\
-\dd{p}{t}  &= \nabla_p H(q(t), p(t)).
\end{align}
An immediate consequence of these equations and the chain rule is the \emph{principle of conservation of energy}:
\begin{equation}
\dd{H}{t}(q(t), p(t)) = 0.
\end{equation}
Thus, a Hamiltonian system with initial configuration $(q(0), p(0))$ of energy
$E = H(q(0), p(0))$ will evolve on the constant energy shell $S_E = H^{-1}(E)$.
\end{example}

If $S_E = H^{-1}(E)$ is finite\footnote{We can view such a system as an approximation to a traditional continuous system with $S_E$ uncountable.}, then one can easily determine that the maximum entropy measure on $S_E$ is simply the uniform measure. For a system with finite state space $\Omega$ and Hamiltonian $H$, we define the \emph{microcanonical distribution} with energy $E$ to be the uniform measure on $S_E$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Canonical ensemble}

In practice, most systems of interest are not truly isolated: they may exchange
energy with their environments. Everyday experience, however, suggests that
a physical system that is left undisturbed for a sufficiently long time will achieve \emph{thermal equilibrium}, in which the system's temperature is constant and equal to that of its surroundings. We define the \emph{canonical ensemble} for a system with state space $\Omega$ and Hamiltonian $H$
(assumed to be integrable) on
$\Omega$ to be the maximum entropy distribution subject to the fixed average energy constraint
\begin{equation}
\int H \; d\mu = E.
\end{equation}
It can be shown by the method of Lagrange multipliers that the canonical ensemble is given by the \emph{Gibbs measure}
\begin{equation}
d\mu_\beta = \frac{1}{Z_\beta} e^{-\beta H} d\lambda,
\end{equation}
where
\begin{equation}
Z_\beta = \int e^{-\beta H} \; d\lambda
\end{equation}
is the normalizing constant, known as the \emph{canonical partition function}.
The quantity $\beta = \beta(E)$, which arises as a Lagrange multiplier, is known as the \emph{inverse temperature}.

The \emph{free energy} of this system is defined by
\begin{equation}
F_\beta = -\frac{1}{\beta} \log Z_\beta.
\end{equation}
This definition may seem obscure at first, but is elucidated by a computation of the entropy $h_\lambda(\mu_\beta)$ with $\beta = \beta(E)$, which implies that
\begin{equation}
F_\beta = E - \frac{1}{\beta} h_\lambda(\mu_\beta).
\end{equation}
This is the famous thermodynamic relation between free energy, internal energy $E$, temperature $1/\beta$, and entropy.


In the context of spin systems, there is a natural mathematical reason for studying measures of the above form. This is the Hammersley-Clifford theorem, which states that any Markov random field (a spatial generalization of a Markov chain) on a graph has a representation as a Gibbs measure whose Hamiltonian is a sum of ``local'' interactions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Graphs}

Most systems of interest do not have a finite (or even countable) state space.
Nevertheless, large finite systems may be used as approximations of real systems.
A natural approach to approximating spatially-extended systems is by studying
models on graphs.

An \emph{undirected graph} or simply a \emph{graph} is a pair $\graph = (\vertices, \edges)$,
where $\vertices$
is a set of \emph{vertices} and $\edges$ is a set of
\emph{edges} $\{ x, y \}$ with $x, y \in \vertices$; we will write $x \sim y$ if
$\{ x, y \} \in \edges$.
For simplicity, we will assume that $\vertices$ is countable annd that there are no
\emph{self-loops} $\{ x \} \in \edges$.
We will also assume that $\graph$ is \emph{(vertex-)transitive}: that is, for all pairs
of distinct
vertices $a, b \in \vertices$, there exists a mapping $f : \vertices \to \vertices$
such that $x \sim y$ if and only if $f(x) \sim f(y)$.
We fix a vertex $0\in\vertices$; the assumption of transitivity implies
that the particular choice of $0$ is immaterial.

\begin{example}\mbox{}\\
\smallskip\noindent
(i) We view any set $X \subset \Zd$ as a graph with $\vertices = X$ and
$x\sim y$ if $|x - y| = 1$. In particular, $X = \Zd$ is transitive.

\smallskip\noindent
(ii) Let $L > 1$ be an integer. For $N \ge 0$, let
\begin{equation}
\Lambda_N = \Zd/L^N\Zd.
\end{equation}
We call $\Lambda_N$ the \emph{discrete $d$-dimensional torus} of side $L^N$.
We view $\Lambda_N$ as a graph with $\vertices = \Lambda_N$ and $x \sim y$
if $|x - y| = 1$ modulo $L^N$.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Functions on graphs}

Let us denote the components of a function $\varphi : \vertices \to \R^n$ by
$\varphi^i_x \in \R$ for $x \in \vertices$ and $i = 1, \ldots, n$.
The Euclidean inner product and norm on the space $(\R^n)^\vertices$ of such functions
are defined by
\begin{align}
\varphi\cdot\tilde\varphi
	&= \sum_{x\in\vertices} \varphi_x \cdot \tilde\varphi_y
  		= \sum_{i=1}^n \sum_{x\in\vertices} \varphi^i_x \tilde\varphi^i_x \\
	&=|\varphi|^2 = \varphi \cdot \varphi.
\end{align}
A $\vertices\times\vertices$ matrix $M = (M_{xy})_{x,y\in\vertices}$ acts on $\varphi$ via
\begin{equation}
(M \varphi)_x = \sum_{y\in\vertices} M_{xy} \varphi_y.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The graph Laplacian}

Let us say that a $\vertices\times\vertices$ matrix $M$ is \emph{indexed by} $\edges$
if $M_{xy} = 0$ if and only if $x \not\sim y$.
Let $\jay$ be a matrix indexed by $\edges$.
Throughout this thesis, we will assume that the $\jay$ has nonnegative entries;
thus, $\jay_{xy} \ge 0$ with equality if and only if $x\not\sim y$.
The pair $(\graph, \jay)$ is an example of a \emph{weighted} graph.
We will usually denote this weighted graph simply as $\graph$, with $\jay$
implicit.

Let $\diag$ be a diagonal $\vertices\times\vertices$ matrix with diagonal entries
\begin{equation}
d_x = \diag_{xx} = \sum_{y \sim x} J_{xy}.
\end{equation}
We say that $\graph$ is $d_0$-regular if $d_x = d_y$ for all $x, y$.

The \emph{(massless) graph Laplacian} on $\graph$ is defined by
\begin{equation}
-\lap = \diag - \jay.
\end{equation}
We also define the \emph{massive Laplacian} with squared \emph{mass} $m^2 > 0$
by
\begin{equation}
-\lap + m^2.
\end{equation}
Note that
\begin{equation}
\varphi \cdot (-\lap \varphi)
  =
\frac{1}{2} \sum_{x,y\in\vertices} J_{xy} |\varphi_x - \varphi_y|^2
  \ge
0,
\end{equation}
so $-\lap$ is positive-semidefinite.

\begin{example}
An important case is when $\jay$ has $\{0, 1 \}$-valued entries.
In this case, $d_x$ is the \emph{degree} of $x$ in $\graph$ and we denote $\lap$ by
$\Delta$, which has entries given by
\begin{equation}
-\Delta_{xy} = d_x \1_{x=y} - \1_{x \sim y}.
\end{equation}
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Green function}

If $m^2 > 0$, then $-\lap + m^2$ is positive-definite, hence invertible with inverse
\begin{equation}
(-\lap + m^2)^{-1} = (m^2 + D)^{-1} \sum_{n=0}^\infty Z^n P^n,
\end{equation}
where
\begin{align}
Z = (m^2 + D)^{-1} D,
  \quad
P = D^{-1} J.
\end{align}
Let $z_x$ denote the diagonal elements of $Z$. The \emph{Green function} for
$-\lap + m^2$ is the kernel of $(-\lap + m^2)^{-1}$, given by
\begin{equation}
C(x, y)
  =
(m^2 + d_x)^{-1} \sum_{n=0}^\infty z_x^n P^n_{xy}.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Spin systems}

\subsection{The Ising model}

Suppose that $|\vertices| < \infty$.
The \emph{Ising model} on $\graph$ is defined by the Gibbs measure on $\Omega = \{ \pm 1 \}^\vertices$
with Hamiltonian
\begin{equation}
H_h(\sigma)
	=
-\frac{1}{2} \sum_{x \sim y} \sigma_x \sigma_y - h \sum_{x\in\vertices} \sigma_x,
\end{equation}
where $h \in \R$ is known as the \emph{external field}.
The first term encourages spins to \emph{align}: an edge $\{ x, y \}$ makes
a negative contribution to the total energy (so a positive contribution to
the probability of a configuration) when $\sigma_x = \sigma_y$.
For a similar reason, the second term encourages spins to adopt the same sign as $h$.

Let $\langle\cdot\rangle_{\beta,h}$ denote the expectation with respect to
this Gibbs measure and let $Z_{\beta,h}$ be the partition function.
The \emph{magnetization} is defined by
\begin{equation}
\langle \sigma_0 \rangle_{\beta,h} = \frac{1}{Z_\beta} \sum_{\sigma\in\Omega} \sigma_0 e^{-\beta H(\sigma)}.
\end{equation}
When $\beta > 0$, it is reasonable to expect that the magnetization has the
same sign as $h$.

To see this, define the \emph{magnetic susceptibility} by
\begin{equation}
\chi(\beta, h)
	=
\frac{1}{\beta} \dd{}{h} \langle \sigma_0 \rangle_{\beta,h}.
\end{equation}
A computation shows that
\begin{equation}
\chi(\beta, h) = \sum_{x\in\vertices} G_x(\beta, h),
\end{equation}
where
\begin{equation}
G_x(\beta, h)
	=
\Big(
	\langle \sigma_0 \sigma_x \rangle_{\beta,h}
		-
	\langle \sigma_0 \rangle_{\beta,h} \langle \sigma_x \rangle_{\beta,h}
\Big)
\end{equation}
is the \emph{two-point function}.
Thus, the susceptibility is positive and so the magnetization is increasing
in $h$. When $h = 0$, the Gibbs measure is invariant under the spin flip
$\sigma \mapsto -\sigma$, and so the magnetization is $0$. It follows that
$\langle \sigma_0 \rangle_{\beta,h} > 0$ if and only if $h > 0$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Spin systems on finite graphs}

We continue to assume that $|\vertices| < \infty$.
An $n$-component \emph{field} or \emph{spin configuration} on $\vertices$
with spins in $S \subset \R^n$ is an element of $\Omega = S^\vertices$.
% A \emph{spin system} is a probability measure $d\mu$ on $\Omega$.
Suppose that $S$ is equipped with a measure $d\lambda^0$.
Given a Hamiltonian $H : \Omega \to \R$, we wish to define the measure
\begin{equation}
d\mu_\beta(\varphi)
  =
\frac{1}{Z_\beta} e^{-\beta H(\varphi)} d\lambda(\varphi)
\end{equation}
on $\Omega$, where
\begin{equation}
d\lambda(\varphi) = \prod_{x\in\vertices} d\lambda^0(\varphi_x).
\end{equation}
We denote the expectation with respect to this measure by $\langle\cdot\rangle_\beta$.
% However, there are some problems with this definition when $\vertices$ is infinite.
% For one, $d\lambda$ may not be well-defined (for instance if
% $S = \R$ and $d\lambda^0$ is Lebesgue measure). Another issue is that it may be
% difficult to define a reasonable choice of $H$ on the infinite product space
% $\Omega$.
% 
% For this reason, we temporarily restrict our attention to finite graphs:
% \begin{equation}
% |\vertices| < \infty.
% \end{equation}
% Then the Gibbs measure $\mu = \mu_\beta$ is well-defined and we will denote the
% expectation with respect to this measure by $\langle \cdot \rangle_\mu$.

Following our discussion of the Ising model, we define the two-point function
and susceptibility by
\begin{equation}
G_x(\beta)
  =
\frac{1}{n}
\big(\langle \varphi_0 \cdot \varphi_x \rangle_\beta
  -
\langle \varphi_0 \rangle_\beta \cdot \langle \varphi_x \rangle_\beta\big)
\end{equation}
and
\begin{equation}
\chi(\beta) = \sum_x G_x(\beta).
\end{equation}

We will mainly be concerned with \emph{ferromagnetic} spin systems, for which the
Hamiltonian has the form
\begin{equation}
H(\varphi) = -\varphi \cdot M\varphi,
\end{equation}
where $M_{xy} \ge 0$.
% Thus, $H(\varphi)$ is smaller (and $d\mu_\beta(\varphi)$ larger) when the spins align
% (when $\varphi_x = \varphi_y$ for $x \sim y$).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{The \texorpdfstring{$O(n)$}{O(n)} spin model}

\begin{example}[The $O(n)$ model]
Let $S = S^{n-1} \subset \R^n$ be the unit $(n-1)$-sphere equipped with the normalized sphere measure
$d\lambda^0$ (in particular, $S^0 = \{ \pm 1 \}$).
The \emph{$O(n)$ spin model} or \emph{$n$-vector model} is the
ferromagnetic spin system with Hamiltonian
\begin{equation}
H_J(\sigma) = -\frac{1}{2} \sigma \cdot J \sigma,
\end{equation}
which is clearly ferromagnetic.
When $n = 1$ we recover the Ising model. When $n = 2, 3$, we get the \emph{XY model} and the \emph{classical Heisenberg model}.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{The \texorpdfstring{$|\varphi|^4$}{phi4} spin model}

\begin{example}[The $|\varphi|^4$ model]
Let $S = \R^n$. The $|\varphi|^4$ spin model on $\graph$ is the ferromagnetic spin system
defined by the quartic Hamiltonian
\begin{equation}
\label{e:phi4-Ham}
H_{\gcc,\nu}(\varphi)
  =
\sum_{x\in\vertices}
\left(
  \frac{1}{4} \gcc |\varphi_x|^4
    +
  \frac{1}{2} \nu |\varphi_x|^2
    +
  \frac{1}{2} \varphi_x \cdot (-\lap \varphi)_x
\right),
\end{equation}
where $\gcc > 0$ and $\nu\in\R$. Adjusting $\beta$ is equivalent to  rescaling
$\gcc$ and $\nu$, so we set $\beta = 1$ without loss of generality.
% This is a natural generalization of the $O(n)$ model
% in which spins are merely concentrated near a sphere.
When $\graph$ is $d_0$-regular, we can write
\begin{equation}
H_{\gcc,\nu}(\varphi)
  =
\sum_{x\in\vertices} U_{\gcc,\nu}(\varphi_x) - \frac{1}{2} \varphi \cdot \jay \varphi,
\end{equation}
where the \emph{single-spin potential} $U_{\gcc,\nu}$ is defined by
\begin{equation}
U_{\gcc,\nu}(t)
	=
\frac{1}{4} \gcc |t|^4
	+
\frac{1}{2} (\nu + d_0) |t|^2,
	\quad
t \in \R^n.
\end{equation}
\todo{Attach graph.}
When $\nu + d_0 < 0$, the potential has roots at $0$ and $\pm\sqrt{-2 (\nu + d_0) / \gcc}$.
It follows that the Gibbs measure for $|\varphi|^4$ model converges weakly to the
Gibbs measure for the $O(n)$ model in the limit $\gcc\to\infty$
with $\nu = -(d_0 + \gcc / 2)$.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{Gaussian measures and the free field}

\begin{example}[The Gaussian free field]
Let $S = \R^n$ and let $C$ be a positive-definite symmetric $\vertices\times\vertices$
matrix. The $n$-component \emph{Gaussian measure} $d\mu_C$ on
$\Omega$ with mean $0$ and \emph{covariance} $C$ is defined by the Hamiltonian
\begin{equation}
H_C(\varphi) = \frac{1}{2} \varphi \cdot C^{-1} \varphi.
\end{equation}
Setting $\beta = 1$ again, the partition function $Z_C$ can be computed explicitly,
giving
\begin{equation}
Z_C
  =
\frac{1}{\sqrt{\det(2\pi C)}}.
\end{equation}
The correlations can also be computed explictly (this is sometimes known as
\emph{Wick's theorem}). In particular, the two-point function is the covariance:
\begin{equation}
\int \varphi_a \cdot \varphi_b \; d\mu(\varphi) = C_{ab}.
\end{equation}

An important case is the \emph{massive Gaussian free field} on $\graph$,
which is the $\gcc = 0$ case of the $|\varphi|^4$ model (with $\nu$ necessarily positive).
Thus, the the covariance is equal to the massive Green function $C = (-\lap + \nu)^{-1}$.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The infinite-volume limit}

\todo{Briefly discuss the need for infinite-volume in terms of vanishing magnetization
and analytic free energy (stress the latter). Define infinite-volume quantities we will
need on $\Zd$. Mention relation to theory of Gibbs measure.}

The presence of a phase transition in a physical system is signalled by an abrupt
(i.e.\ non-analytic) change in an observable quantity (usually the free energy) as a
parameter (usually an external field) is varied. We make a broad distinction between
\emph{first-order} phase transitions in which the free energy has discontinuous first
derivative (with respect to an external field $h$) and \emph{continuous} phase transitions,
in which the free energy is differentiable but non-analytic.

The spin systems we have defined above all
have smooth free energy since the Hamiltonians are smooth functions. The reason we cannot
detect a phase transition in these systems is that they have been defined on finite volumes.
Thus, in order to study phase transitionns, we are forced to face the problem of defining
spin systems on an infinite graph.

A natural approach to defining such systems is via a procedure known as the
\emph{infinite-volume limit}, which we describe here. For any
finite subgraph $\Lambda \subset \graph$, let $H_\Lambda$ be the Hamiltonian
of one of the above spin systems on $\Lambda$ and let $\mu_\Lambda$ be the
corresponding Gibbs measure (which we can view as a measure on the full state
space $\Omega$).

Let $\Lambda_N \subset \graph$ be a sequence of subgraphs that exhaust
$\graph$, i.e.\ $\Lambda_N \uparrow \graph$. If the limits
\begin{equation}
\lim_{N\to\infty} \int f \; d\mu_{\Lambda_N}
\end{equation}
exist for a sufficiently rich class of functions $f$ (such as all bounded continuous functions), then they define a measure $\mu$ on $\Omega$ (with $\mu(f)$ the above limit), which we call a \emph{Gibbs state} or
\emph{infinite-volume Gibbs measure} on $\Omega$.

We remark that there is a more general approach to the study of spin systems in infinite volume developed by Dobrushin, Lanford, and Ruelle. We do not detail their approach here, but merely mention that, for the examples above, this approach involves defining a Gibbs measure for the collection
$H = (H_\Lambda)$ of Hamiltonians directly as a measure on $\Omega$ satisfying a system of constraints on its conditionals measures. This is somewhat in the spirit of Kolmogorov's consistency conditions with the importance difference that the resulting collection $\gibbs_\beta(H)$ of Gibbs states at inverse temperature
$\beta$ need not consist of only a single element. This is significant due to the interpretation of distinct elements of $\gibbs(H)$ as corresponding to different phases of the system under consideration.

For many models, including the $O(n)$ and $n$-component $|\varphi|^4$ models on $\Zd$ with $d > 2$, it is known that there exists a critical inverse temperature $\beta_c < \infty$ such that
$|\gibbs_\beta(H)| = 1$ if and only if $\beta \le \beta_c$ (\REF). In this thesis, our main concern is with the behaviour at $\beta_c$ and as
$\beta \uparrow \beta_c$. Thus, we need not concern ourselves with the precise nature of the infinite-volume limit.

\subsubsection{Translation-invariant systems}

Our interest will be in translation-invariant systems on $\Zd$, for which a particular approach to the infinite-volume limit will be convenient. Namely, for $L > 1$ we will let $\Lambda_N = \Zd/L^N\Zd$ be the discrete torus, which we view as a subset of $\Zd$. This allows us to preserve
translation-invariance of these models in finite volume. Strictly speaking, $\Lambda_N$ is not a subgraph of $\Zd$; nevertheless, it can be shown that the infinite-volume limit (if it exists) is a Gibbs measure in the usual sense; see \cite[Example 4.20]{Georgii11} for details.


We study a generalization of the $|\varphi|^4$ model defined by the Hamiltonian
\begin{equation}
\label{e:Vdef1}
V_{\gcc,\gamma,\nu,N}(\varphi)
	=
\sum_{x\in\Lambda_N}
\Big(
	\tfrac{1}{4} (\gcc - \gamma) |\varphi_x|^4
		+
	\tfrac{1}{2} \nu |\varphi_x|^2
		+
	\tfrac{1}{2} \varphi_x \cdot (-\Delta \varphi)_x
		+
	\tfrac{1}{4 d} \gamma (\nabla |\phi_x|^2)^2
\Big),
\end{equation}
where
\begin{equation}
(\nabla |\phi_x|^2)^2
	=
\sum_{|e|=1} (\nabla^e |\phi_x|^2)^2.
\end{equation}
Note that we recover \eqref{e:phi4-Ham} when $\gamma = 0$.
The expectation with respect to the corresponding Gibbs measure will
be denoted $\langle\cdot\rangle_{\gcc,\gamma,\nu,N}$.
We define the two-point function
\begin{equation}
\label{e:two-point-function-phi4}
G_{x, N}(g,\gamma,\nu; n)
	=
\frac{1}{n} \pair{\varphi_0 \cdot \varphi_x}_{g,\gamma,\nu,N},
	\quad
G_x(g,\gamma,\nu; n)
	=
\lim_{N \to \infty} G_{x, N}(g,\gamma,\nu; n).
\end{equation}
In the above limit, we identify a point $x \in \Zd$ with $x \in \Lambda_N$
for large $N$, by embedding the vertices of $\Lambda_N$ as an approximately
centred cube in $\Z^d$ (say as $[-\frac12 L^N+1,\frac12 L^N]^d \cap \Z^d$ if $L^N$ is even
and as $[-\frac12 (L^N-1), \frac12 (L^N-1)]^d \cap \Z^d$ if $L^N$ is odd).

The susceptibility and correlation length of order $p$ are defined by
\begin{equation}
\label{e:susceptibility-def}
\chi(\gcc, \gamma, \nu; n)
	=
\lim_{N\to\infty} \sum_{x\in\Lambda_N} G_{x,N}(\gcc, \gamma, \nu; n)
\end{equation}
and
\begin{equation}
\xi_p(\gcc, \gamma, \nu; n)
	=
\left(
\frac{\sum_{x\in\Zd} |x|^p G_x(\gcc, \gamma, \nu; n)}{\chi(\gcc, \gamma, \nu; n)}
\right)^{\tfrac{1}{p}}.
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Critical behaviour and universality}

For this discussion, let us restrict our attention to the graph $\graph = \Zd$
with $d > 1$ and with $J_{xy} \in \{ 0, 1 \}$. Thus, $\lap = \Delta$.

\subsection{The critical point}

Many systems exhibit \emph{critical behaviour} at or near a particular parameter value.
For concreteness, let us discuss the $|\varphi|^4$ model. For convenience, we will
actually discuss a generalization of the $|\varphi|^4$ model. \todo{Define it and
the susceptibility, etc.}

Let
\begin{equation}
\nu_c = \nu_c(\gcc, \gamma, n) = \inf \{ \nu : \chi(g, \gamma, \nu; n) < \infty \}.
\end{equation}
Since the susceptibility can be written as the second derivative of the free energy
with respect to an external field, there is a second-order phase transition at $\nu_c$.
By the expression for the susceptibility in terms of the two-point function, it is
reasonable to expect rapid (i.e.\ summable) decay of $G_x(g, \gamma, \nu; n)$ in $|x|$ for
$\nu > \nu_c$ and much slower decay at $\nu = \nu_c$. In fact, the two-point function
is expected to decay exponentially above $\nu_c$ and sub-exponentially at $\nu_c$.
The \emph{correlation length} $\xi$ is defined to be the reciprocal of the exponential
rate of decay of the two-point function; concretely, we let
\begin{equation}
\xi(g, \gamma, \nu; n) = \limsup_{k\to\infty} \frac{-k}{\log G_{ke}(g, \gamma, \nu; n)},
\end{equation}
where $e \in \Zd$ is a unit vector. Roughly speaking, the correlation length acts as
a ``macroscopic length scale'' of the model; it is a measure of the largest scale at
which spins are strongly correlated.
Based on the above discussion, we expect $\xi$
to diverge as $\nu\downarrow\nu_c$. This divergence is usually seen as one of the
key features of critical behaviour and is indicative of strong correlations at all
scales. A related quantity is the \emph{correlation length of order $p$}, defined by
\begin{equation}
\xi_p(g, \gamma, \nu; n)
	=
\left(\frac{\sum_{x\in\Zd} |x|^p G_x(g, \gamma, \nu; n)}{\chi(g, \gamma, \nu; n)}\right)^{1/p}.
\end{equation}

\begin{rk}
There is a simple heuristic relationship between $\xi$ and $\xi_p$: Let us suppose that
the two-point function decays exponentially at rate $1/\xi$, possibly with some
sub-exponential multiplicative correction; for instance, suppose that
\begin{equation}
G_x(g, \gamma, \nu; n) \approx C |x|^{-\alpha} e^{-|x|/\xi(g, \gamma, \nu; n)},
\end{equation}
in some sense, where $\alpha$ and $C$ are positive constants independent of $\nu$.
Then the main contributions to the sum in the numerator in the definition of
$\xi_p$ should come from $|x| \le \xi = \xi(g, \gamma, \nu; n)$. For such $|x|$,
$G_x(g, \gamma, \nu; n) \approx C |x|^{-\alpha}$ and so
\begin{equation}
\sum_{x\in\Zd} |x|^p G_x(g, \gamma, \nu; n)
	\approx
C \sum_{|x| \le \xi} |x|^{-(\alpha-p)}
	\approx
C \xi(g, \gamma, \nu; n)^{-(\alpha-p)}.
\end{equation}
By definition, it follows that
\begin{equation}
\xi^p_p(g, \gamma, \nu; n) \approx \xi^p(g, \gamma, \nu; n).
\end{equation}
\end{rk}

\subsection{Critical exponents}

For simplicity, let us drop $\gcc$, $\gamma$, and $n$ from the notation.
It is predicted that there exist constants $\eta$, $\gammabar$, and $\nubar$,
known as \emph{critical exponents}, such that
\begin{align}
G_x(\nu_c)
	&\sim
C_1 |x|^{-(d - 2 + \eta)},
	\qquad
|x|\to\infty \\
\chi(\nu)
	&\sim
C_2 (\nu - \nu_c)^{-\gammabar},
	\qquad
\nu\downarrow\nu_c \\
\xi(\nu)
	&\sim
C_3 (\nu - \nu_c)^{-\nubar},
	\qquad
\nu\downarrow\nu_c \\
\xi_p(\nu)
	&\sim
C_4 (\nu - \nu_c)^{-\nubar},
	\qquad
\nu\downarrow\nu_c.
\end{align}
where $a \sim b$ means that $\lim (a/b) = 1$ and $C_i$ for $i = 1,2,3,4$
are constants that may depend on $g$ and $n$ (and $p$ when $i = 4$).
The critical exponents are expected to be \emph{universal} in the sense that they
only depend on ``large-scale properties'' of the model such as the global geometry
of the underlying graph and the symmetries of the Gibbs measure. In particular,
for the $n$-component $|\varphi|^4$ model on $\Zd$, these exponents should only
depend on $n$ and $d$ and independent of $g$ and $\gamma$ when $g > 0$ and $\gamma$
is sufficiently small (depending on $g$). In fact,
analogous relations are expected to hold for the $O(n)$ spin model, with the
\emph{same} critical exponents.

These and other relations are all believed to be manifestations of the existence of
a universal \emph{scaling limit} for the $|\varphi|^4$ model and other models in its
\emph{universality class}. That is, any spin system in this class, when appropriately
rescaled, is expected to converge in distribution to a unique continuum random field.
In this sense, the study of critical behaviour involves a set of far-reaching
generalizations of the central limit theorem.

\begin{example}[The Gaussian free field]
\todo{Needs work}

We have
\begin{equation}
-\Delta = 2 d (1 - P),
\end{equation}
where $P = (2 d)^{-1} J$ is the transition matrix for the simple random walk $X$ on $\Zd$.
For $d > 2$, the simple random walk is transient. Thus, letting $E_0$ denote the expectation
of $X$ conditioned so that $X_0 = 0$,
\begin{equation}
(1 - P)^{-1}_{0x} = \sum_{n=0}^\infty P^n_{0x} = E_0 \sum_{n=0}^\infty \1_{X_n=x} < \infty
\end{equation}
and we can define the \emph{massless} Gaussian free field on $\Zd$ to be the Gaussian
measure with covariance $(-\Delta)^{-1} = (2 d)^{-1} (1 - P)^{-1}$.

The two-point function is just the massive Green function
$(-\Delta + m^2)^{-1}$ which, on $\Zd$, has the well-known Ornstein-Uhlenbeck decay \todo{(show this; use random walks?)}. Moreover,
\begin{equation}
\chi
  =
\sum_{x\in\vertices} (-\Delta + m^2)^{-1}_{0x}
  =
\sum_{x\in\vertices} \sum_{n=0}^\infty z^n P^n_{0x}
  =
\sum_{n=0}^\infty z^n
  =
(1 - z)^{-1}.
\end{equation}
Thus, there is a critical point at $m^2 = 0$ ($z = 1$).

\todo{See candidacy report or preliminary version of it. For the Green function, see Theorem 1.5.4 in Lawler--Intersections of Random Walks}
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The upper-critical dimension}

The critical exponents are conjectured to take on the following values:
\begin{equation}
\eta =
	\begin{cases}
	\frac{5 + n}{24},		& d = 2, \, n = 1 \\
	\approx 0.03,			& d = 3, \\
	0,						& d \ge 4
	\end{cases}
\qquad
\gamma =
	\begin{cases}
	\frac{43 + 13 n}{32},	& d = 2, \, n = 1 \\
	\approx 1,				& d = 3 \\
	1,						& d \ge 4
	\end{cases}
\end{equation}
and
\begin{equation}
\nubar =
	\begin{cases}
	\frac{3 + n}{4},		& d = 2, \, n = 1 \\
	\approx 0.6,			& d = 3 \\
	\frac{1}{2},			& d \ge 4
	\end{cases}
\end{equation}
with logarithmic corrections in $d = 4$.
Thus, it is expected that, when $d > 4$, the critical exponents cease to depend
on the dimension and $n$. In fact, they are expected to equal the exponents of
the corresponding non-interacting model, the Gaussian free field.

This phenomenon is known as \emph{mean-field behaviour} and dimension $4$ is
called the \emph{upper-critical dimension} for this class of models. The behaviour
of models is generally better understood above than below their upper-critical
dimension.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The renormalisation group}

\todo{General idea; Kadanoff decimation; fixed points and stable manifolds;
dependence on dimension}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Walks}

\subsection{Discrete-time walks}

For simplicity, suppose that $J_{xy} \in \{ 0, 1 \}$ and that $\graph$ is
$d_0$-regular.

Let $[n] = \{ 0, \ldots, n \}$.
An $n$-step \emph{walk} is a function $\omega : [n] \to \vertices$ with
$\omega_i \sim \omega_{i+1}$ for all $i \in [n]$. Let $\dwalks_n$ denote the collection
of $n$-step walks $\omega$ with $\omega_0 = 0$ and let $\dwalks = \bigcup_n \dwalks_n$.
Given $\omega\in\dwalks_n$, we write $|\omega| = n$.
A model of discrete-time walks is defined by a weight function $w : \dwalks \to \R$.

The \emph{generating function} of a sequence $c_n$ is the function defined by
the power series
\begin{equation}
\sum_n c_n z^n.
\end{equation}
Let $\dwalks_n(x)$ denote the collection of walks $\omega\in\dwalks_n$ with $\omega_n = x$
and set $\dwalks(x) = \bigcup_n \dwalks_n(x)$.
The two-point function $G_x$ for walks with weight function $w$ is the generating
function of the sequence
\begin{equation}
c_n(x) = \sum_{\omega\in\dwalks_n(x)} w(\omega).
\end{equation}
That is,
\begin{equation}
G_x = \sum_n z^n c_n(x)
	= \sum_{\omega\in\dwalks(x)} w(\omega) z^{|\omega|}.
\end{equation}
The susceptibility is the generating function for $c_n = \sum_x c_n(x)$:
\begin{equation}
\chi = \sum_n c_n z^n = \sum_x G_x.
\end{equation}

We define a probability measure $\mu_n$ on $\dwalks_n$ by $\mu(\omega) = w(\omega) / c_n$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{example}[Simple random walk]
The (discrete-time) simple random walk $X_n$ is the Markov chain on $\graph$ with
transition matrix $P = d_0^{-1} J$. This is a model of walks in the sense above
with $w(\omega) = 1$ for all $\omega$.

There is a close relationship between the
simple random walk and the Gaussian free field. Since $P$ is a stochastic matrix,
the two-point function converges for $|z| < 1$. For $0 < z < 1$, we can write
$z = d_0 / (d_0 + m^2)$ with $m^2 > 0$ to get
\begin{equation}
G_x = \sum_n P^n_{0x} z^n = (2 d + m^2) (-\Delta + m^2)^{-1}_{0x}.
\end{equation}
In other words, the two-point function for simple random walk is the two-point
function for the Gaussian free field.

When $z = 1$, the power series above is the expected number of visits $X$ makes
to $x$ when started at $0$. Thus, $G_x$ converges at $z = 1$ when $X$ is transient.
% Since $\sum_x P^n_{0x} = 1$
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \subsection{Self-avoiding walk}

\begin{example}[Self-avoiding walk]
A walk $\omega$ is said to be \emph{self-avoiding} if $\omega_i \ne \omega_j$
for all $i \ne j$. Let $\Scal_n \subset \dwalks_n$ denote the set of $n$-step
self-avoiding walks starting at $0$. We define the weights $w(\omega) = \1_{\omega\in\Scal_n}$.
Then $c_n(x)$ is the number of $n$-step self-avoiding walks from $0$ to $x$
and $c_n = |\Scal_n|$.

Note that the sequence $c_n$ is sub-multiplicative: $c_{m+n} \le c_m c_n$.
Thus, Fekete's lemma implies that the existence of the \emph{connective constant}
$c(\graph)$ of $\graph$, defined by
\begin{equation}
c(\graph) = \lim_{n\to\infty} n^{-1} \log c_n.
\end{equation}
Note that, by the trivial bounds $1 \le c_n \le d_0^n$ for $n \ge 1$, $c(\graph) \in [0, d_0]$.
% Roughly speaking, this means that $c_n \approx c(\graph)^n$ for large $n$.
By definition, the susceptibility has radius of convergence $c(\graph)^{-1}$.
Since $c_n \ge 0$ for all $n$, the susceptibility diverges at $c(\graph)^{-1}$.

The measure $\mu_n$ on $\dwalks_n$ is the uniform measure.
These measures do not form a consistent family due to the possibility of ``traps''. That is, the equality
\begin{equation}
\mu_{|\omega|}(\omega) = \sum_{\tilde\omega \supset \omega} \mu_{|\tilde\omega|}(\tilde\omega)
\end{equation}
does not hold for all $\omega\in\dwalks$ (the sum here is over all self-avoiding walks extending $\omega$).
% \begin{wrapfigure}{R}{0.4\textwidth}
% \vspace{-0.5cm}
% \begin{center}
%   \includegraphics[width=0.3\textwidth]{trapped}
%   \caption{A trapped self-avoiding walk}
%   \label{fig:trap}
% \end{center}
% \vspace{-0.5cm}
% \end{wrapfigure}
For instance, consider the self-avoiding walk $\omega\in\dwalks_7$ on $\Zd$ in
Figure~\ref{fig:trap}. This walk has positive probability under $\mu_7$ but,
since there are no self-avoiding walks extending $\omega$, the sum on the 
right-hand side above is $0$.

As a result, the methods of stochastic processes cannot be directly used to
study the self-avoiding walk. The existence of traps also contributes to the
combinatorial difficulty of studying self-avoiding walk; for instance, it is
not clear how to express $c_{n+1}$ (the number of $(n+1)$-step self-avoiding walks)
in terms of $c_n$.

% \begin{figure}[!htb]
% \centering
% \caption{A trapped self-avoiding walk}
% \includegraphics{trapped}
% \end{figure}
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Gibbs measures on walks}

For any right-continuous function $\omega : [0, T] \to \vertices$, we define
$\tau_n = \tau_n(\omega)$ inductively by setting $\tau_0 = 0$ and
\begin{equation}
\tau_{n+1} = \inf(t > \tau_n : \omega_t \ne \omega_{\tau_n}).
\end{equation}
We call $\omega$ a \emph{walk} of length $T$ if
$\{ \tau_n : n \in \Z_+ \}$ does not have any cluster points and
$\omega_{\tau_n} \sim \omega_{\tau_{n+1}}$ for all $n$; thus, $\omega$
only jumps between neighbouring vertices.

A model of walks is determined by a choice of finite measure $d\mu_T$ on
$\cwalks_T$ for each $T$. Our focus will be on canonical Gibbs measures of the form
\begin{equation}
\int f \; d\mu_T = \frac{1}{c_T} E_0 (f e^{-H_T}),
\end{equation}
where $E_0$ is the expectation for a random walk on $\graph$ (in discrete or continuous time), $H_T : \cwalks_T \to \R$, and we have denoted the canonical partition function by $c_T$.
% \begin{equation}
% d\mu_T(\omega) = \frac{1}{c_T} e^{-H_T(\omega)} \; d\lambda_T(\omega),
% \end{equation}
% with respect to some measure $\lambda_T$ on $\cwalks_T$ (we have denoted the partition function by $c_T$).
% We will assume that models of discrete-time walks satisfy $\mu_T = \mu_{\lfloor T \rfloor}$ for all $T$
% (note that both are measures on $\cwalks_{\lfloor T \rfloor}$ in this case).
Given such a model, the corresponding grand canonical ensemble is given by
\begin{equation}
d\mu(\omega)
  =
\frac{1}{\chi(\nu)}
e^{-\nu |\omega| - H_{|\omega|}(\omega)}
d\lambda_{|\omega|}(\omega)
\end{equation}
and the grand canonical partition function, denoted $\chi(\nu)$, is known as the \emph{susceptibility}. In this setting, the fugacity $\nu$ is usually referred to as the \emph{killing rate}.
% The grand canonical partition function, denoted $\chi$, is known as the \emph{susceptibility}.
Note that
\begin{equation}
\mu(\cdot \mid \cwalks_T) = \mu_T.
\end{equation}

Let $\cwalks_T(x) \subset \cwalks_T$ denote the set of walks in $\cwalks_T$ from $0$ to $x$ and let $\cwalks(x) = \bigcup_{T \ge 0} \cwalks_T(x)$. We define the
\emph{two-point function}
\begin{equation}
G_x(\nu) = \mu(\cwalks(x)) \int_0^\infty e^{-\nu T} c_T(x) \; dT,
\end{equation}
where
\begin{equation}
c_T(x) = \int_{\cwalks_T(x)} e^{-H_T} \; d\lambda_T.
\end{equation}
Note that
\begin{equation}
\chi(\nu) = \sum_{x\in\vertices} G_x(\nu),
\end{equation}
which is consistent with the analogous relation for spin systems. Later we will discuss the relationship between the two-point function for walks and spin systems.

The \emph{critical point} $\nu_c$ for a model of walks is defined
\begin{equation}
\nu_c = \inf (\nu : \chi(\nu) < \infty).
\end{equation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Continuous-time simple random walk}

Let $\generator = -\lap$
Then $\generator$ is the generator of the $\vertices$-valued Markov process
$X = (X_t)_{t \ge 0}$ with transition probabilities
\begin{equation}
\Pr(X_t = y \mid X_0 = x) = (e^{-t \lap})_{xy},
\end{equation}
called the \emph{continuous-time simple random walk} on $\graph$.
We define the measure $\lambda_T$ on $\cwalks_T$ by
\begin{equation}
\lambda_T(d\omega) = \Pr(X_t = d\omega_t, \, t \le T \mid X_0 = 0).
\end{equation}
For the corresponding Gibbs measures (with $H_T \equiv 0$), we have
\begin{equation}
c_T(x) = (e^{-t \lap})_{0x},
  \quad
G_x = (\nu - \lap)^{-1}_{0x}
\end{equation}
for $\nu > 0$. Thus, the two-point function is the Green function for the
massive Laplacian.

\begin{example}
The discrete-time simple random walk is the Markov chain given by
$X_n = X_{\tau_n}$. Consider the discrete-time simple random walk on $\Zd$,
for which $X_n = X_0 + \sum_{i=1}^n Y_i$, where $Y_i$ are iid random variables
in $\{ e \in \Zd : |e| = 1 \}$ with $\Ex Y_i = 0$. Thus, $\Ex |X_n|^2 = n$ and
the central limit theorem implies that
$X_n / \sqrt n \Rightarrow \normal(0, 1)$. More generally, Donsker's invariance
principle states that a rescsaled version of $X$ converges to Brownian motion on $\Rd$.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Weakly self-avoiding walk with self-attraction}

Define the \emph{local time} up to time $T$ of $\omega \in \cwalks$ at
$x \in \vertices$ by
\begin{equation}
\label{e:LTx-def}
\lt^x_T(\omega) = \int_0^T \1_{\omega(S)=x} \; dS.
\end{equation}
In the discrete-time case, $\lt^x_n$ is the number of times $\omega$ visits $x$
and is bounded by $n$. In the continuous-time case, $\lt^x_T$ is almost surely
finite for the continuous-time simple random walk.

We define the \emph{intersection local time}
\begin{equation}
\label{e:ITdef}
I_T(\omega) = \sum_{x\in\vertices} (\lt^x_T)^2
  =
\int_0^T \!\! \int_0^T \1_{\omega(S_1)=\omega(S_2)} \; dS_1 dS_2
\end{equation}
and the \emph{contact self-attraction}
\begin{equation}
\label{e:CTdef}
C_T(\omega)
	=
\sum_{x \in \vertices} \sum_{y \sim x} \lt_T^x(\omega) \lt_T^y(\omega)
	=
\int_0^T ds \int_0^T dt \; \1_{\omega_s \sim \omega_t}
\end{equation}
up to time $T$.
% Recall that we have set the inverse temperature equal to $1$.
Given a parameter $\gcc > 0$, and $\gamma \in \R$, let
\begin{equation}
\label{e:Udef-neg}
U_{\gcc,\gamma}(f)
=
\gcc \sum_{x\in\vertices} f_x^2
- \frac{\gamma}{2d}
\sum_{x\in\vertices} \sum_{y \sim x} f_x f_y
\end{equation}
for $f : \vertices \to \R$.
The \emph{weakly self-avoiding walk with self-attraction} (WSAW-SA) is defined via the Hamiltonian
\begin{equation}
\label{e:V}
U_{\gcc,\gamma,T}
	= U_{\gcc,\gamma} \circ L_T
	= \gcc I_T - \frac{\gamma}{2 d} C_T.
\end{equation}
Thus,
\begin{equation}
\label{e:c}
    c_T = E_a\left(e^{-U_{\gcc,\gamma,T}}\right),
    \quad
    c_T(x) = E_0\left(e^{-U_{\gcc,\gamma,T}}\1_{X_T = x}\right)
\end{equation}
and the two-point function and susceptibility are given by
\begin{align}
\lbeq{Gsa}
G_x(\gcc,\gamma,\nu)
    &=
\int_0^\infty c_T(x) e^{-\nu T} \; dT
\end{align}
and
\begin{equation}
\label{e:suscept-def}
\chi(\gcc, \gamma, \nu)
	=
\int_0^\infty c_T e^{-\nu T} \; dT
	=
\sum_{x\in\Zd} G_x(\gcc,\gamma,\nu)
\end{equation}

In the case $\gamma = 0$, the discrete-time version of this model is known as
the \emph{Domb-Joyce model}. In continuous-time, it is the
\emph{continuous-time weakly self-avoiding walk} (WSAW).

\subsubsection{Alternative representation}

For $f : \Zd \to \R$,
\begin{equation}
\label{e:sbp}
\sum_{x\in\Zd}   f_x \Delta_{\Zd} f_x
=
-\frac{1}{2} |\nabla f|^2.
\end{equation}
It follows that
\begin{equation}
\sum_{x\in\Zd} \sum_{e\in\Ucal} f_x f_{x+e}
=
2 d \sum_{x\in\Zd} f_x^2
+ \sum_{x\in\Zd} f_x \Delta_{\Zd} f_x
=
2 d \sum_{x\in\Zd} f_x^2
- \frac{1}{2} \sum_{x\in\Zd} |\nabla f_x|^2
\end{equation}
and so we get the useful representation:
\begin{equation}
\label{e:Udef-pos}
U_{\gcc,\gamma}(f)
= (\gcc - \gamma) \sum_{x\in\Zd} f_x^2
+ \frac{\gamma}{4d} \sum_{x\in\Zd} \sum_{e\in\Ucal} |\nabla^e f_x|^2.
\end{equation}
In particular,
\begin{equation}
  \label{e:V2}
  U_{\gcc,\gamma,T} =
  (\gcc - \gamma) I_T
  + \frac{\gamma}{4d}
  |\nabla \lt_T|^2
  .
\end{equation}
% A version of \refeq{V2} can be found in \cite{HK01a}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Predicted behaviour}

\todo{State expected critical behaviour.}

\todo{
For walks, it is expected that
\begin{align}
c_T                       &\sim C_5 e^{-\nu_c T} T^{-\gammabar}, \\
\langle |X_T|^2 \rangle   &\sim C_6 T^{-\nubar}.
\end{align}
\todo{Motivate the above with an example somewhere.}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Main results}

The main result is stated below.
\todo{Discuss existence of $\nu_c$}

\begin{theorem} \label{thm:suscept}
  Let $d = 4$ and $n \ge 0$. For $L$ sufficiently large (depending on $n$),
  there exist $\gcc_* > 0$
  and a positive function $\gamma_* : (0, \gcc_*) \to \R$
  such that whenever $0 < \gcc < \gcc_*$ and $|\gamma| < \gamma_*(\gcc)$,
  there are constants $A_{\gcc,\gamma,n}$ and $B_{\gcc,\gamma,n}$ such that the following hold:

  \smallskip\noindent
  (i)
  The critical two-point function decays as
  \begin{equation}
    G_x(\gcc,\gamma,\nu_c; n)
        =
    A_{\gcc,\gamma} |x|^{-2} (1 + O((\log |x|)^{-1}))
        \quad
    \text{as $|x|\to\infty$},
  \end{equation}
  with $A_{\gcc,\gamma} = (4 \pi)^{-2} (1 + O(\gcc))$ as $\gcc \downarrow 0$.

  \smallskip\noindent
  (ii)
  The susceptibility diverges as
  \begin{equation} \label{e:chieps-asympt}
    \chi(\gcc, \gamma, \nu_c + \varepsilon; n)
      \sim B_{\gcc,\gamma,n} \varepsilon^{-1} (\log \varepsilon^{-1})^{(n+2)/(n+8)},
    \quad \varepsilon\downarrow 0
  \end{equation}
  with $B_{\gcc,\gamma,n} = ((n + 8) \gcc / 16\pi^2)^{(n+2)/(n+8)} (1 + O(\gcc))$
  as $\gcc \downarrow 0$.

  \smallskip\noindent
  (iii) For any $p >0$, if $L$ is chosen large and $\gcc_*$ small both depending on $p$,
  then the correlation length of order $p$ diverges as
  \begin{equation} \label{e:xieps-asympt}
    \xi_p(\gcc, \gamma, \nu_c + \varepsilon; n)
     \sim B_{\gcc,\gamma,n}^{1/2} {\sf c}_p \varepsilon^{-1/2} (\log \varepsilon^{-1})^{(n+2)/2(n+8)},
    \quad \varepsilon\downarrow 0
  \end{equation}
  with
  \begin{equation}
  {\sf c}_p^p = \int_{\R^4} |x|^p (-\Delta_{\R^4} + 1)^{-1}_{0x} \; dx.
  \end{equation}
\end{theorem}

The $\gamma = 0$ cases of (i) and (ii) were proved by Bauerschmidt, Brydges, and
Slade. The $n > 0$ case with $\gamma \ne 0$ is a new result in this thesis. We
will only discuss the proof of the $\gamma \ge 0$ case, which is of primary
interest. The proof of the $\gamma < 0$ case with $n = 0$ can be found in
\cite{BSW-saw-sa} and the extension to $n > 0$ is straightforward.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Spin systems and models of walks}

We have already discussed the close relationship between the simple random walk
and the Gaussian free field, which ultimately stems from the representation of
matrix powers in terms of walks and which should be somewhat familiar to anyone
who has studied Markov chains. Namely, if $M$ is a $\vertices\times\vertices$
matrix, then
\begin{equation}
M^n_{ab} = \sum_{x_1,\ldots,x_n\in\vertices} M_{ax_1} M_{x_1x_2} \ldots M_{x_nb}.
\end{equation}
When $M$ is indexed by edges (i.e.\ when $M_{xy} = 0$ for $x \not\sim y$), the
above sum can be replaced by a sum over $n$-step walks from $a$ to $b$ on $\graph$.
When the entries of $M$ are non-negative, such a sum acquires a probabilistic
interpretation as an expectation with respect to the random walk whose steps
are weighted by the entries of $M$.

This idea can be extended to obtain relationships between certain models of
interacting walks and spin systems.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{High-temperature expansion of the \texorpdfstring{$O(n)$}{O(n)} model}

The high-temperature expansion of a spin system is based on the expansion of the
Boltzmann weight $e^{\beta H}$ around $\beta = 0$.
For the $O(n)$ spin model, an uncontrolled high-temperature expansion yields
\begin{align}
Z 	&= \int d\lambda(\sigma) \prod_{xy\in\edges} e^{\beta \sigma_x \cdot \sigma_y} \\
	&\approx \int d\lambda(\sigma) \prod_{xy\in\edges} (1 + \beta \sigma_x \cdot \sigma_y) \\
	&= \sum_{E \subset \edges} \beta^{|E|} \int d\lambda(\sigma) \prod_{xy \in E} \sigma_x \cdot \sigma_y
\end{align}
By reflection-invariance of the sphere measure, the last integral above is non-zero
if and only if every vertex in the product over $E$ appears an even number of times;
thus, the sum over subsets of $\edges$ can be replaced by a sum over collections of
loops (walks from a vertex to itself) in $\graph$.

A similar expansion can be performed for the numerator in the definition of the
two-point function, yielding:
\begin{equation}
\int d\lambda(\sigma) \sigma_a \cdot \sigma_b
	\approx
\sum_{E\subset\edges} \beta^{|E|}
\int d\lambda(\sigma) \sigma_a \cdot \sigma_b
\prod_{xy\in E} \sigma_x \cdot \sigma_y.
\end{equation}
Once again, every vertex must appear twice on the right-hand side. This time,
there are additional non-zero contributions from subsets $E$ of edges containg
a path from $a$ to $b$. For instance, if $a \sim b$, there is a non-zero
contribution from $E = \{ \{ a, b \} \}$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The \texorpdfstring{$n\to0$}{n approaches 0} limit}

A more careful analysis of the high-temperature expansion of the $O(n)$ model
above will reveal the $n$-dependence of the non-zero contributions to the
partition function and two-point function. When the spins are restricted to
the sphere of radius of $\sqrt n$, it can be shown that formally setting $n = 0$
results in $Z = 1$ and the two-point function receives contributions only from
self-avoiding walks from $a$ to $b$. See \cite[Section 2.3]{MS93} for details.

Based on this idea, De Gennes predicted the critical exponents of the self-avoiding
walk by setting $n = 0$ in the predicted exponents for the $O(n)$ spin model.
This is known as the $n \to 0$ ``limit''.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Self-avoiding walk representation}
% This section based on saw-sa
\label{sec:intrep}

It is not clear how to make rigorous the $n\to0$ limit of De Gennes. Parisi and
Sourlas and, independently, McKane, discovered an alternative approach to the
predictions of De Gennes. They argued that the weakly
self-avoiding walk \todo{two-point function} could be represented as the two-point
function for a version of the $|\varphi|^4$ model involving both boson and fermion
fields. The formal appearance of $n = 0$ quantities was then explained as a
consequence of a symmetry between the bosons and fermions known as \emph{supersymmetry}.

In this section we describe an integral representation of the of WSAW-SA, which
is a special case of a result of Brydges, Imbrie, and Slade \cite{BIS09}.
We restrict out attention to the graph $\Lambda = \Lambda_N = \Zd/L^N\Zd$.
We begin by introducing the notions of bosons and fermion fields on $\Lambda$.

\subsubsection{Boson and fermion fields}
\label{sec:forms}

We fix $N$ and write $\Lambda = \Lambda_N$.
Given complex variables $\phi_x, \bar\phi_x$
(the boson field) for $x \in \Lambda$,
we define the differentials (the fermion field)
\begin{equation}
\psi_x = \frac{1}{\sqrt{2\pi i}} d\phi_x,
\quad
\bar\psi_x = \frac{1}{\sqrt{2\pi i}} d\bar\phi_x,
\end{equation}
where we fix a choice of complex square root.
The fermion fields are multiplied with each other
via the anti-commutative wedge product,
though we suppress this in our notation.

A differential form that is the
product of a function of $(\phi, \bar\phi)$
with $p$ differentials is said to have degree $p$.
A sum of forms of even degree is said to be \emph{even}.
We introduce a copy $\bar\Lambda$ of $\Lambda$
and we denote the copy of $X \subset \Lambda$ by $\bar X \subset \bar\Lambda$.
We also denote the copy of $x \in \Lambda$
by $\bar x \in \bar\Lambda$ and define $\phi_{\bar x} = \bar\phi_x$ and $\psi_{\bar x} = \bar\psi_x$.
Then any differential form $F$ can be written
\begin{equation}
\lbeq{FinNcal}
F
=
\sum_{\vec y}
F_{\vec y} (\phi, \bar\phi)
\psi^{\vec y}
\end{equation}
where the sum is over finite sequences $\vec y$ over $\Lambda\sqcup\bar\Lambda$,
and $\psi^{\vec y} = \psi_{y_1} \ldots \psi_{y_p}$ when $\vec y = (y_1, \ldots, y_p)$.
When $\vec y = \varnothing$ is the empty sequence,
$F_\varnothing$ denotes the $0$-degree (bosonic) part of $F$.

In order to apply the results of \cite{BBS-saw4-log,BBS-saw4,BSTW-clp}, we require
smoothness of the coefficients $F_{\vec y}$ of $F$.  For Theorem~\ref{thm:suscept}(i,ii),
we need these coefficients to be $C^{10}$, and for Theorem~\ref{thm:suscept}(iii) we require
a $p$-dependent number of derivatives for the analysis of $\xi_p$, as discussed in \cite{BSTW-clp}.
We let $\Ncal^\varnothing$ be the algebra of even forms with sufficiently smooth coefficients
and we let $\Ncal^\varnothing(X) \subset \Ncal^\varnothing$ be the sub-algebra of even forms only depending on fields
in $X$. Thus, for $F \in \Ncal^\varnothing(X)$, the sum in \eqref{e:FinNcal} runs over sequences $\vec y$
over $X \sqcup \bar X$.
Note that $\Ncal^\varnothing = \Ncal^\varnothing(\Lambda)$.


Now let $F = (F_j)_{j \in J}$ be a finite collection of even forms
indexed by a set $J$
and write $F_\varnothing = (F_{\varnothing,j})_{j \in J}$.
Given a $C^\infty$ function $f : \R^J \to \C$, we define
$f(F)$ by its Taylor expansion about $F_\varnothing$:
\begin{equation}
f(F) = \sum_\alpha \frac{1}{\alpha!} f^{(\alpha)}(F_\varnothing) (F - F_\varnothing)^\alpha.
\end{equation}
The summation terminates as a finite sum,
since $\psi_x^2 = \bar\psi_x^2 = 0$ due to the anti-commut\-ative product.

We define the integral
$\int F$
of a differential form $F$ in the usual way
as the Riemann integral of its top-degree part
(which may be regarded as a function
of the boson field).
In particular, given a positive-definite
$\Lambda \times \Lambda$ symmetric matrix $C$
with inverse $A = C^{-1}$,
we define the \emph{Gaussian expectation}
(or \emph{super-expectation}) of $F$ by
\begin{equation}
\lbeq{ExCF}
\Ex_C F = \int e^{-S_A} F,
\end{equation}
where
\begin{equation}
\label{e:action}
S_A = \sum_{x\in\Lambda} \Big(\phi_x (A\bar\phi)_x + \psi_x (A \bar\psi)_x\Big).
\end{equation}

Finally, for $F = f(\phi, \bar\phi) \psi^{\vec y}$,
we let
\begin{equation}
\theta F = f(\phi + \xi, \bar\phi + \bar\xi) (\psi + \eta)^{\vec y},
\end{equation}
where $\xi$ is a new boson field, $\eta = (2\pi i)^{-1/2} d\xi$ a new fermion field,
and $\bar\xi, \bar\eta$ are the corresponding conjugate fields.
We extend $\theta$ to all $F \in \Ncal^\varnothing$ by linearity
and define the convolution operator $\Ex_C\theta$ by letting
$\Ex_C\theta F \in \Ncal^\varnothing$ denote the Gaussian expectation of $\theta F$ with respect
to $(\xi, \bar\xi, \eta, \bar\eta)$, with $\phi,\phib,\psi,\psib$ held fixed.

\subsubsection{Integral representation of the two-point function}
\label{sec:Gintrep}

An integral representation formula applying to general local time functionals
is given in \cite{BEI92,BIS09}; see also \cite[Appendix~A]{ST-phi4}.
We state the result we need in the proposition below.

Let $\Delta$ denote the Laplacian on $\Lambda$,
i.e.\ $\Delta_{xy}$ is given by the right-hand side of
\eqref{e:Deltaxy} for $x, y \in \Lambda$.
We define the differential forms:
\begin{align}
\label{e:taudef}
\tau_x
	&=
\phi_x \bar\phi_x + \psi_x \bar\psi_x
	\\
\label{e:addDelta}
\tau_{\Delta,x}
	&=
\frac 12
\Big(
	\phi_{x} (- \Delta \bar{\phi})_{x} + (- \Delta \phi)_{x} \bar{\phi}_{x}
		+
	\psi_{x}  (- \Delta \bar{\psi})_{x} + (- \Delta \psi)_{x}  \bar{\psi}_{x}
\Big)
	\\
\label{e:nablatau}
|\nabla \tau_x|^2
	&=
\sum_{|e|=1} (\nabla^e \tau)_x^2.
\end{align}
Let
\begin{equation}
\label{e:Vdef2}
V_{\gcc,\gamma,\nu,N}
	=
U_{\gcc,\gamma}(\tau)
	+
\sum_{x\in\Lambda_N}
\Big(
	\nu \tau_x + \tau_{\Delta,x}
\Big)
% \sum_{x\in\Lambda_N}
% \Big(
% 	\gcc \tau_x^2 + \nu \tau_x + \tau_{\Delta,x} - \tfrac{1}{2 d} \gamma |\nabla \tau_x|^2
% \Big)
\end{equation}

\begin{prop}
Let $d > 0$ and $\gcc > 0$. For $\gamma < \gcc$ and $\nu \in \R$,
\begin{align}
\label{e:Grep-pos-bis}
G_{x,N}(\gcc, \gamma, \nu)
	&=
\int e^{-V_{\gcc,\gamma,\nu,N}} \phib_0 \phi_x.
% \int e^{-U_{\gcc,\gamma,\nu,N}} \bar\phi_a \phi_b.
\end{align}
\end{prop}

\subsubsection{Finite-volume approximation}

In order to make use of the integral representation above, we must approximate the
WSAW-SA on $\Zd$ by a model on $\Lambda_N$.

Let $X^{L^N}$ denote the simple random walk on $\Lambda_N$.
For $F_T = F_T(X)$ any one of the functions $L_T^x,I_T,C_T$
of $X$ defined in \eqref{e:LTx-def}--\eqref{e:CTdef},
we write $F_{N,T} = F_T(X^{L^N})$. For instance, with $n=L^N$,
\begin{equation}
    L^x_{N,T} = \int_0^T \1_{X^{n}_t=\;x} \; dt,
    \quad I_{N,T} = \sum_{x \in \Lambda_N}(L_{N,T}^x)^2 .
\end{equation}

As before, we identify the vertices of $\Lambda_N$ with nested subsets of $\Zd$,
centred at the origin (approximately if $L$ is even),
with $\Lambda_{N+1}$ paved by $L^d$ translates of $\Lambda_N$.
% We can thus define $\partial \Lambda_N$ to be the inner vertex boundary of $\Lambda_N$.
We denote the expectation of $X^{L^N}$ started from $a \in \Lambda_N$ by $E^{\Lambda_N}_a$
and define
\begin{align}
\label{e:cN}
c_{N,T}(x)
    &= E^{\Lambda_N}_a \left( e^{-U_{\gcc,\gamma,T}} \1_{X(T)=b} \right)
    \quad (x \in \Lambda_N), \\
c_{N,T}
    &= E^{\Lambda_N}_0 \left( e^{-U_{\gcc,\gamma,T}} \right).
\end{align}
The finite-volume two-point function and susceptibility
are defined by
\begin{align}
G_{x,N}(\gcc,\gamma,\nu)
    &=
\int_0^\infty c_{N,T}(x) e^{-\nu T} \; dT, \\
\label{e:chiNdef}
\chi_N(\gcc, \gamma, \nu)
    &=
\int_0^\infty c_{N,T} e^{-\nu T} \; dT.
\end{align}

\begin{prop}
\label{prop:finvol}
Let $d >0$, $\gcc >0$ and $\gamma < \gcc$. For all $\nu \in \R$,
\begin{equation}
\label{e:Givlc}
\lim_{N \to \infty}
G_{x,N}(\gcc,\gamma,\nu)
=
G_x(\gcc,\gamma,\nu)
\end{equation}
and
\begin{equation}
\label{e:chilim}
\lim_{N\to\infty}\chi_N(\gcc,\gamma,\nu) =   \chi(\gcc,\gamma,\nu).
\end{equation}
\end{prop}

The proof is in the appendix.