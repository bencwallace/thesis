% Parts are the largest structural units, but are optional.
%\part{Thesis}

% Chapters are the next main unit.
\chapter{Introduction}

\section{To do}
\begin{itemize}
\item
Use $\Vcal$, etc. for polynomials, $\Ucal$ for unit vectors

\item
Make $U_{\gcc,\gamma}$ notation consistent with $U_{\gcc,\nu,N}$.
I have done this by getting rid of the latter (it is hardly used
explicitly in clp)

\item
Change $\beta, g$ to $\backslash gcc$

\item
Change $L$ to $\backslash lt$

\item
Make $G_x(g, \nu; n)$ consistent with $G_{\gcc,\gamma,\nu}(a, b)$.
Maybe use $G_x(g, \gamma, \nu)$ and $G_x(g, \nu; n)$

\item
Make it so that $U$ has observables but no constant and $V$ is $U$
plus the constant. Thus, we must change $V$ in saw-sa to $U$ (the $V$
in saw-sa has no observables, but these can be added in without harm).
We must also change $U^\pm$ in saw-sa to something else

\item
Change $\chi$ and $\tilde\chi$ to $\backslash chicCov$ and $\backslash chicCovgen$
\end{itemize}


\section{Statistical mechanics}


\subsection{Hamiltonian mechanics}

Let $\Omega = U^n \times \R^{3n}$, where $U \subset \R^3$, and denote a generic element of
$\Omega$ by $(q, p)$, where $q \in U^n$ and $p \in \R^{3n}$. Then $\Omega$ is the state
space of a system of $n$ point particles $i = 1, \ldots, n$ with positions $q_i \in U$
and momenta $p_i \in \R^3$. Given a $C^1$ function $H : \Omega \to \R$, known as the
\emph{Hamiltonian},
the dynamics of such a system is determined by \emph{Hamilton's equations}
\begin{align}
\dd{q}{t} &= \nabla_q H(q(t), p(t)) \\
\dd{p}{t} &= -\nabla_p H(q(t), p(t)).
\end{align}

The value $H(q, p)$ represents the total energy of the configuration $(q, p)$.
An immediate consequence of Hamilton's equations and the chain rule is the principle
of conservation of energy:
\begin{equation}
\dd{H}{t}(q(t), p(t)) = 0.
\end{equation}
Thus, a Hamiltonian system with initial configuration $(q(0), p(0))$ and energy
$E = H(q(0), p(0))$ will evolve on the constant energy shell $S_E = H^{-1}(E)$.

We will assume that $H$ has compact level sets so that the solutions to Hamilton's
equations can be extended globally in time.


\subsection{The microcanonical ensemble}

In general, especially when $n$ is large, a Hamiltonian system is likely to be too
complicated to understand in a precise way.
The basic idea of statistical mechanics is to leverage this complexity by assuming
(or in some cases proving) that, as $t\to\infty$, such a system will settle into a
state of equilibrium in which all possible states are equiprobable.

It can be shown that the measure defined by
\begin{equation}
\mu'_E(A) = \lim_{\delta\downarrow 0} \int_{H^{-1}([E, E + \delta])} \1_A(x) \; dx
\end{equation}
exists, is supported on $S_E$, and is invariant under the Hamiltonian dynamics
\cite{Adams06}. By our assumption that $S_E$ is compact, $\mu'_E(S_E) < \infty$
and we can define the \emph{microcanonical ensemble} $\mu_E$ by
\begin{equation}
\mu_E(A) = \mu'_E(A) / \mu'_E(S_E).
\end{equation}


\subsection{The canonical ensemble}

The microcanonical ensemble may present obstacles to analysis due to the fact that
it is typically singular with respect to the Lebesgue measure on $\Omega$.
Moreover, in practice, most systems of interest are not truly isolated and may exchange
energy with
their environment. Everyday experience, however, suggests that
a physical system that is left undisturbed for a sufficiently long time will achieve
\emph{thermal equilibrium}, in which the system's
temperature is constant and equal to that of its surroundings.

This situation can be modeled as follows: call the system of interest system $A$ and
its surroundings system $B$. We assume that $B$ behaves as a \emph{thermal reservoir},
meaning that it is so large that its temperature may be assumed to be effectively
constant, even if system $A$ is at a different temperature.
It is then reasonable to assume that the total system $A \times B$
is isolated and therefore described by a microcanonical distribution on a constant energy shell.

The marginal distribution of $A$ can then be computed by the following rough argument.
Let $\Omega_1$ and $\Omega_2$ be the state spaces of systems $A$ and
$B$, respectively, and let $H_i : \Omega_i \to \R$ be their respective Hamiltonians,
where $i = 1, 2$. Then the total system $A \times B$ has state space $\Omega_1 \times \Omega_2$
and Hamiltonian $H : \Omega \to \R$ given by\footnote{We are assuming the energy due to interactions
between $A$ and $B$ is negligible.}
$H(\omega_1, \omega_2) = H_1(\omega_1) + H_2(\omega_2)$
for $\omega_i \in \Omega_i$. Suppose that $S_E$ is compact so that the microcanonical ensemble $\mu_E$
on $S_E$ is well-defined.

For any $E_2 \in \R$, let $S^2_{E_2} = H_2^{-1}(E_2)$. Then the marginal distribution $\mu^1_E$
of $\mu$ on $\Omega_1$ is given by the density
\begin{equation}
f^1_E(\omega_1)
  =
\int \frac{\1_{(\omega_1, \omega_2) \in S_E}}{|S_E|} d\omega_2
  =
\frac{|S^2_{E-H_1(\omega_1)}|}{|S_E|}
  =
\frac{e^{h^2_{E-H_1(\omega_1)}}}{|S_E|},
\end{equation}
where $|S|$ is the Lebesgue measure of a set $S$ and
\begin{equation}
h^2_{E_2} = \log |S^2_{E_2}|
\end{equation}
is the entropy of the microcanonical ensemble on $S^2_{E_2}$.

If $E_2 \mapsto h^2_{E_2}$ is $C^1$, then we have the first-order expansion
\begin{equation}
h^2_{E - H_1(\omega_1)}
  =
h^2_E - \dd{h^2_E}{E} H_1(\omega_1) + O(H_1(\omega_1)^2).
\end{equation}
Thus,
\begin{equation}
e^{-h^2_{E-H_1(\omega_1)}}
  \approx
C e^{-\beta H_1(\omega_1)},
\end{equation}
where $\beta = \dd{h^2_E}{E}$ and $C$ is a constant independent of $\omega_1$.
The assumption that system $B$ is a ``heat bath'' then amounts to saying that
$E - H_1(\omega_1)$ is such a negligible perturbation of $E$ that the first-order
approximation above accurately represents the marginal density of $\mu^1_E$.

The probability measure
\begin{equation}
\frac{1}{Z_\beta} e^{-\beta H_1(\omega_1)} d\omega_1
\end{equation}
is known as the \emph{canonical ensemble} on $\Omega_1$ at \emph{inverse temperature} $\beta > 0$.
The normalizing constant $Z_\beta$ is known as the \emph{(canonical) partition function}.


\subsection{Gibbs measures}

Given a measure space $(\Omega, d\lambda)$ (not necessarily of point particles) and measurable
Hamiltonian $H : \Omega \to \R$ for which $e^{-H}$ is integrable with respect to $d\lambda$,
we define the \emph{Gibbs measure} at inverse temperature $\beta > 0$
on $\Omega$ to be the probability measure of the form
\begin{equation}
\frac{1}{Z} e^{-\beta H(\omega)} d\omega.
\end{equation}

There are various justifications for studying Gibbs measures.
One is the \emph{principle of maximum entropy}, which states roughly that the least
biased choice of probability distributions from a given class of distributions is the
one with the maximum entropy. It can be shown using the method of Lagrange multipliers
that the canonical ensemble maximizes the
entropy over all distributions $\mu$ on $\Omega$ satisfying the average energy constraint
\begin{equation}
\int_{\Omega} H(\omega) \; d\mu(\omega) = E.
\end{equation}
The constant $\beta$ then arises as a Lagrange multiplier.

Another, purely mathematical, reason for studying measures of this form is the Hammersley-Clifford
theorem, which states that any Markov random field on a graph has a representation as a Gibbs
measure whose Hamiltonian is a sum of ``local'' interactions.

Lastly, there is the variational principle, which states that the free energy associated to
a pair $(H, \mu)$, where $H$ is a Hamiltonian and $\mu$ is a probability measure is minimized
when $\mu$ is the Gibbs measure associated to $H$.


\subsection{Grand canonical ensemble}

Consider a physical system that is free to exchange particles with its environment
and let $\Omega_T$ be the space of configurations with $T$
particles and let $H_T : \Omega_T \to \R$ be the Hamiltonian on $\Omega_T$
for $T\in\interval\subset\R$ (we allow $T$ to take non-integer values for
additional generality).
The state space for the full system is then given by $\Omega = \bigsqcup_{T \in \interval} \Omega_T$,
where $\sqcup$ denotes the disjoint union. Let $|\omega|$ be the unique value of $T$
such that $\omega \in \Omega_T$.
We define $H : \Omega \to \R$ by $H(\omega) = H_{|\omega|}(\omega)$.

By an argument similar to the derivation of the canonical ensemble (either by marginalizing
the microcanonical ensemble or by maximum entropy) we are led to define the \emph{grand
canonical ensemble} with Hamiltonian $H$ and \emph{fugacity} (or \emph{activity}) $\nu \in \R$ by
\begin{equation}
\frac{1}{Z_{\beta,\nu}} e^{-\beta (H(\omega) - \nu |\omega|)}.
\end{equation}
Since the $\nu |\omega|$ term can be absorbed into the Hamiltonian,
the grand canonical ensemble is itself a Gibbs measure and we will only loosely
distinguish between the canonical and grand canonical ensembles. 


\section{Lattice models}

Let $\graph = (\vertices, \edges)$ be a graph.
% Let $J$ be a $\vertices \times \vertices$
% matrix with $J_{xx} = 0$ and $J_{xy} \ge 0$ for all $x, y \in \vertices$ and suppose
% that $J$ has summable rows: $\sum_{y\in\vertices} J_{xy} < \infty$. Let $D$ be
% the diagonal matrix with entries $D_{xx} = \sum_{y\in\vertices} J_{xy}$, and let $A = D - J$.

% \todo{The $Q$ matrix will be $Q = -A$, the matrix $J$ will be the (ferromagnetic) Ising interaction,
% and $A$ will be the interaction for the $|\varphi|^4$ model.
% E.g.\ $A = -\Delta + m^2$ has positive diagonal entries. Recall that
% $\Delta_{xy} = \1_{x \sim y} - 2 d \1_{x=y}$.}


\subsection{Models of walks}

In the following, $\interval_T$ will denote one of the following choices (for all $T \ge 0$):
\begin{equation}
\interval_T
  =
\begin{cases}
\{ 0, \ldots, \lfloor T \rfloor \} \\
[0, T]
\end{cases}.
\end{equation}
These two choices will be referred to, respectively, as the \emph{discrete-} and
\emph{continuous-time} cases.
Fix a designated vertex $0 \in \vertices$ in $\graph$ and
let $\Wcal_T$ denote the set of
right-continuous paths $\omega : \interval_T \to \vertices$ with $\omega(0) = 0$.
We will refer to elements of $\Wcal := \bigcup_{T \geq 0} \Wcal_T$ as \emph{walks}.
A model of walks is determined by a choice of finite measure $d\mu_T$ on
$\Wcal_T$ for each $T$.

In the discrete-time case, we will assume that
$\mu_T = \mu_{\lfloor T \rfloor}$ for all $T$ (both are measures on
$\Wcal_{\lfloor T \rfloor}$ in this case). Thus, it suffices to study consider only
the measures $\mu_n$ ($n \in \Z_+$) in this case.

Given such a model $d\mu_T$, we define
\begin{equation}
c_T = \int_{\Wcal_T} d\mu_T.
\end{equation}
Given a parameter $\nu \in \R$ (called the \emph{killing rate}),
there is a natural measure $\mu$ on $\Wcal$ defined by
\begin{equation}
\int f \; d\mu
  =
\int_0^\infty dT \; e^{-\nu T} \int_{\Wcal_T} d\mu_T f.
\end{equation}
The corresponding normalizing constant is given by
\begin{equation}
\chi(\nu) = \int_0^\infty dT \; e^{-\nu T} c_T
\end{equation}
and is known as the \emph{susceptibility}. In the discrete-time case, this becomes
\begin{equation}
\mu(f)
  =
\frac{1 - e^{-\nu}}{\nu} \sum_{n=0}^\infty z^n \int_{\Wcal_n} d\mu_n(\omega) \; f(\omega).
\end{equation}
with
\begin{equation}
\chi(\nu) = \frac{1 - e^{-\nu}}{\nu} \sum_{n=0}^\infty c_n z^n,
\end{equation}
where $z = e^{-\nu}$.

\todo{Since we are not translation-invariant yet, should replace $x$ by $(a, b)$.}
Let $\Wcal_T(x) \subset \Wcal_T$ denote the collection of walks $\omega \in \Wcal_T$
with $\omega(T) = x$. The conditional measure $\mu^{(x)}_T = \mu_T(\cdot \mid \Wcal_T(x))$
is given by
\begin{equation}
\mu^{(x)}_T(d\omega) = \frac{\mu_T(d\omega) \1_{\Wcal_T(x)}(d\omega)}{c_T(x)},
\end{equation}
where
\begin{equation}
c_T(x) = \mu_T(\Wcal_T(x)).
\end{equation}
Let $\Wcal(x) = \bigcup_{T \ge 0} \Wcal_T(x)$. Then
\begin{equation}
\mu^{(x)}(d\omega) = \frac{\mu(d\omega) \1_{\Wcal(x)}(d\omega)}{G_x},
\end{equation}
where
\begin{equation}
G_x = \mu(\Wcal(x)) = \int_0^\infty dT \; e^{-\nu T} c_T(x).
\end{equation}
In discrete time, we have
\begin{align}
G_x = \frac{1 - e^{-\nu}}{\nu} \sum_{n=0}^\infty c_n(x) z^n.
\end{align}

Many models of walks are determined by letting $\mu_T$ be the canonical Gibbs measure
associated to a Hamiltonian $H_T : \Wcal_T \to \R$ and a base measure $d\lambda$. That is,
\begin{equation}
d\mu_T(\omega) = \frac{1}{Z_T} e^{-H_T(\omega)} d\lambda_T(\omega).
\end{equation}
In this caes, $\mu$ is the corresponding grand canonical ensemble (with killing rate playing
the role of fugacity) and $c_T$ and $\chi$
are the canonical and grand canonical partition functions, respectively.

% In what follows, we let $Q$ be a $\vertices \times \vertices$ matrix with $Q_{xy} = 0$
% whenever $\{ x, y \} \notin \edges$.


\subsubsection{Random walk}

Let $J$ be a $\vertices \times \vertices$
matrix with $J_{xx} = 0$ and $J_{xy} \ge 0$ for all $x, y \in \vertices$ and suppose
that $J$ has summable rows: $\sum_{y\in\vertices} J_{xy} < \infty$. Let $D$ be
the diagonal matrix with entries $D_{xx} = \sum_{y\in\vertices} J_{xy}$
and let $Q = D - J$.

Then $Q$ is the generator of a $V$-valued Markov process $(X_t)_{t \ge 0}$:
the holding time of $X$ at $x$ is exponentially distributed with rate $-Q_{xx}$
and the transition probability from $x$ to $y \ne x$ is
$-Q_{xy} / Q_{xx} = J_{xy} / D_{xx}$.
We call $X$ the \emph{continuous-time random walk} with generator $Q$.

If $P$ is any stochastic matrix, then $P$ is the transition matrix for a Markov chain
$(\hat X_n)_{n\in\Z_+}$, called the \emph{discrete-time random walk} with transition matrix $P$.
In particular, the random walk $\hat X_n$ with transition matrix given by
$P_{xy} = -Q_{xy} / Q_{xx}$ if $x \ne y$ and $P_{xx} = 0$ is called the \emph{skeleton
walk} associated with the process $X_t$.

In both cases, the \emph{simple random walk} is the random walk with $Q = -\Delta$,
where
\begin{equation}
\Delta_{xy} = \1_{x \sim y} - 2 d \1_{x=y}.
\end{equation}
\todo{Define killed SRW (or more general substochastic processes).}

For $v \in \vertices$, let $E_v$ denote the expectation
with respect to either the process $X$ or $\hat X$ conditioned so that $X_0 = v$.

\begin{example}[The Green function]
Let $P$ be a $\vertices \times \vertices$ stochastic matrix and suppose that the Neumann series
\begin{equation}
\sum_{n=0}^\infty P^n
\end{equation}
converges in the operator norm
\begin{equation}
\|P\| = \sup_{f \in \R^V} \frac{|P f|}{|f|},
\end{equation}
where $|f| = \sum_{x\in V} f_x^2$. Then $1 - P$ is invertible with inverse
\begin{equation}
(1 - P)^{-1} = \sum_{n=0}^\infty P^n.
\end{equation}
By writing $P^n_{xy} = E_x \1_{X_n=y}$, we see that the $xy$ entry of the
above matrix is the expected number of visits to $y$ made by a random walk
started at $x$. Thus, $1 - P$ is invertible if and only if the random walk
with transition matrix $P$ is transient. \todo{(Does this really follow?)}

Let $z = 2 d / (2 d + m^2)$, and $P = \frac{1}{2 d} J$,
where $-\Delta = D - J$ with $J$ the off-diagonal part of $-\Delta$. Then
\begin{equation}
-\Delta + m^2 = \frac{2 d}{z} (1 - z P).
\end{equation}
This is invertible whenever $m^2 > 0$ since $|z| < 1$ in this case.

When $m^2 = 0$ ($z = 1$), we see that the massless Green function $(-\Delta)^{-1}$
exists if and only if the simple random walk is transient (in particular, it exists on
$\Zd$ if and only if $d > 2$).
\end{example}

\subsubsection{Self-avoiding walk}

The \emph{self-avoiding walk} is given by the microcanonical ensemble on the
collection of self-intersecting paths starting at $0$ of length $n$.

\subsubsection{Variants of the self-avoiding walk}

The \emph{local time} of $\omega \in \Wcal_T$ at $x \in \Zd$ is defined by
\begin{equation}
\lt^x_T(\omega) = \int_0^T \1_{\omega(S)=x} \; dS.
\end{equation}
In the discrete-time case, $\lt^x_n$ is the number of times $\omega$ visits $x$
and is bounded by $n$. In the continuous-time case, $\lt^x_T$ is almost surely
finite for paths distributed as continuous-time simple random walks.

For $\omega \in \Wcal_T$, we define the \emph{intersection local time}
\begin{equation}
\label{e:ITdef}
I_T(\omega) = \sum_{x\in\Zd} (\lt^x_T)^2 = \int_0^T \int_0^T \1_{\omega(S_1)=\omega(S_2)} \; dS_1 dS_2
\end{equation}
and \emph{contact self-attraction} by
\begin{equation}
\label{e:CTdef}
C_T(\omega) =
  \sum_{x \in \Z^d}\sum_{e\in\Ucal} \lt_T^x(\omega) \lt_T^{x+e}(\omega)
  = \int_0^T ds \int_0^T dt \; \1_{\omega_{s} \sim \omega_{t}}.
\end{equation}
% Recall that we have set the inverse temperature equal to $1$.
Given a parameter $\gcc > 0$,
and $\gamma \in \R$, we define
\begin{equation}
\label{e:Udef-neg}
U_{\gcc,\gamma}(f)
=
\gcc \sum_{x\in\Zd} f_x^2
- \frac{\gamma}{2d}
\sum_{x\in\Zd} \sum_{e\in\Ucal} f_x f_{x+e}
\end{equation}
for $f : \Zd \to \R$.
The Hamiltonian is given by
\begin{equation}
H_T(\omega) = U_{\gcc,\gamma}(L_T(\omega)).
\end{equation}
We denote the canonical partition function by
\begin{equation}
c_T = c_T(\gcc, \gamma) = E_0 \left( e^{-\gcc I(T) + \gamma C(T)} \right),
\end{equation}
where $0 \in \vertices$ is fixed,
and the susceptibility by
\begin{equation}
\chi(\gcc, \gamma, \nu) = \int_0^\infty c_T e^{-\nu T} \; dT.
\end{equation}

In the case $\gamma = 0$, the discrete-time version of this model is known as
the \emph{Domb-Joyce model}. In continuous-time, it is the \emph{continuous-time
weakly self-avoiding walk}, which we will abbreviate as WSAW.


\subsection{Spin systems}

Assume for now that $\graph$ is a finite graph.

Let $S \subset \R^n$. A \emph{spin system} on $\graph$ with spin in $S$ is given
by a probability measure $\mu$ on $\Omega = S^V$. Such a measure is often given by the
Gibbs measure
\begin{equation}
\frac{1}{Z} e^{-H(\varphi)} d\varphi,
\end{equation}
where $d\varphi = \prod_{x\in\vertices} d\varphi_x$ is the Lebesgue measure on
$\Omega$. A spin system of the above form is said to be \emph{ferromagnetic} when
the Gibbs measure can be written as
\begin{equation}
\frac{1}{Z} e^{-\tilde H(\varphi)} \prod_{x\in\Lambda} \mu(d\varphi_x)
\end{equation}
for some measure $\mu$ on $S$, with
\begin{equation}
\tilde H(\varphi) = -\sum_{x, y \in \vertices} J_{xy} \varphi_x \cdot \varphi_y
\end{equation}
and $J_{xy} \ge 0$ for all $x, y$.

Given a configuration $\varphi \in \Omega$
of spins, we will denote the $i$-th component of $\varphi_x \in S$ by $\varphi^i_x$.
We also define the inner product
\begin{equation}
\varphi \cdot \tilde\varphi = \sum_{i=1}^n \sum_{x\in\vertices} \varphi^i_x \tilde\varphi^i_x.
\end{equation}
We also let a $V \times V$ matrix $M$ act on $\varphi$ via
\begin{equation}
(M\varphi)^i_x = \sum_{y\in\vertices} M_{xy} \varphi^i_x.
\end{equation}

For any spin system, we define the \emph{two-point function}
\begin{equation}
G_x(\mu) = \int d\mu(\varphi) \; \varphi_0 \cdot \varphi_x
\end{equation}
and the \emph{susceptibility}
\begin{equation}
\chi(\mu) = \sum_{x\in\vertices} G_x(\mu).
\end{equation}


\subsubsection{Gaussian fields}

Suppose that $C$ is a positive-definite symmetric matrix with inverse $A = C^{-1}$.
Then the Gibbs measure induced by the Hamiltonian
\begin{equation}
H(\varphi) = \frac{1}{2} \varphi \cdot A \varphi
\end{equation}
is a Gaussian measure, known as the discrete Gaussian field with covariance $C$.

In particular, when $C = (-\Delta + m^2)^{-1}$ with $m^2 \ge 0$, we get the \emph{discrete Gaussian
free field} (DGFF), which is an example of a ferromagnetic spin system. The DGFF is said to be
\emph{massive} with \emph{mass} $m^2$ when $m^2 > 0$, and is said to be \emph{massless} when $m^2 = 0$.


\subsubsection{The $|\varphi|^4$ spin model}

The $|\varphi|^4$ spin model is given a quartic perturbation to the Gaussian free field.
Precisely, the Hamiltonian has the form
\begin{equation}
H(\varphi)
  =
\sum_{x\in\vertices}
\left(
  \frac{1}{4} g |\varphi_x|^4
    +
  \frac{1}{2} \nu |\varphi_x|^2
    +
  \frac{1}{2} \varphi_x \cdot (C \varphi)_x
\right).
\end{equation}
Due to the presence of the quartic term, $C$ can be any symmetric
matrix\footnote{Positive-definiteness is required for the Gaussian measure to be
integrable. There is no loss of generality in assuming symmetry of $C$.}.
An important special case corresponds to the choice $C = -\Delta$, for which
the $|\varphi|^4$ model is ferromagnetic.


\subsubsection{The $O(n)$ spin model}

Consider the $|\varphi|^4$ model with interaction matrix $C$ and suppose that $C$ has
constant diagonal part with $C_{xx} \equiv c$. Let $J = C - c$ denote the off-diagonal
part of $C$. Then the $|\varphi|^4$ Hamiltonian can be written as
\begin{equation}
\sum_{x\in\vertices}
\left(
  \frac{1}{4} g |\varphi_x|^4
    +
  \frac{1}{2} (\nu + c) |\varphi_x|^2
\right)
  +
\frac{1}{2} \varphi \cdot J \varphi
\end{equation}

If we take the limit $g\to\infty$ with $\nu = -(c + g / 2)$, the
$|\varphi|^4$ spin model converges
weakly to the $O(n)$ spin model, given by the Hamiltonian
\begin{equation}
H(\varphi) = \frac{1}{2} \varphi \cdot J \varphi
\end{equation}
on the state space $S = S^{n-1} \subset \R^n$ the $(n-1)$-sphere.
The case $n = 1$ is the well-known \emph{Ising model}. When $n = 2$, we get the \emph{XY model}
and when $n = 3$, the \emph{classical Heisenberg model}.


\subsubsection{Infinite-volume Gibbs measures}

\todo{Does DLR work for general spins? See Friedli-Velenik and Georgii}

The examples above do not generalize directly to the case of infinite graph due to the fact
that the Hamiltonian is no longer absolutely summable. This obstacle was overcome in the work
of Dobrushin, Lanford, and Ruelle.

For every finite subset $A \subset \vertices$, let $\Phi_A : \Omega \to \R$ be a function that
depends only on the values of the spins in $A$. Then we can define the Hamiltonian on a finite
subset $\Lambda \subset \vertices$ by
\begin{equation}
H^\Phi_\Lambda(\varphi) = \sum \Phi_A(\varphi),
\end{equation}
where the sum is over all finite subset $A \subset \vertices$ that intersect $\Lambda$.
For simplicity, suppose that the space of spins $S$ is either a discrete set equipped with the
counting measure or is equipped with the Lebesgue measure. Let us also assume that the Hamiltonians
$H^\Phi_\Lambda$ are bounded below. Then the  Gibbs measures corresponding to $H^\Phi_\Lambda$ are
all well-defined. Then a measure $\mu$ on $\Omega$ is said to be a Gibbs measure if for $\mu$-almost
every choice of boundary condition $\tilde\varphi$, the conditional distribution
$\mu(\cdot \mid \varphi_{\Lambda^c} = \tilde\varphi_{\Lambda^c})$ is given by the finite-volume Gibbs
measure
\begin{equation}
\mu^\Phi_\Lambda(\varphi \mid \tilde\varphi)
  :=
\frac{1}{Z^\Phi_\Lambda(\tilde\varphi)}
e^{-H^\Phi_\Lambda(\varphi_\Lambda \tilde\varphi_{\Lambda^c})}
d\varphi_\Lambda,
\end{equation}
where $\varphi_\Lambda\tilde\varphi_{\Lambda^c}$ is the concatenation of
$\varphi_\Lambda = (\varphi_x)_{x\in\Lambda}$ and $\tilde\varphi_{\Lambda^c}$
and where $d\varphi_\Lambda$ is the product measure on $S^\Lambda$.
We denote the collection of all such Gibbs measures by $\Gibbs(\Phi)$.

Let $\Lambda_N$ be a sequence of finite subsets of $\vertices$ such that $\Lambda_N \uparrow \vertices$
and let $\varphi^{(N)}$ be a sequence of spin configurations in $\Omega$. It can be verified
that, if the sequence of measure $\mu_N = \mu^\Phi_{\Lambda_N}(\cdot \mid \varphi^{(N)})$ converges weakly
to a measure $\mu$, then $\mu$ is a Gibbs measure. In this case, we can study the measure $\mu$
by studying \emph{observables}, which are bounded continuous functions $f : \Omega \to \R$. It suffices
to study the limiting properties of $\mu_N(f)$.

\begin{example}[Periodic boundary conditions]
Let $\graph = \Zd$ and suppose we are given a translation-invariant potential $\Phi$.
That is, $\Phi_A = \Phi_{A + i}$ for any $i \in \Zd$.
Suppose, moreover, that $\Phi$ is of finite range, i.e.\ $\Phi_A = 0$ whenever
$|A| > R$ for some $R$. Let $\Lambda_N \subset \Zd$ be a sequence of finite boxes
with $|\Lambda_N| > R$ for each $N$.

Given a configuration $\varphi \in \Omega$, let $\varphi^N \in \Omega$
be the periodic extension of the restriction of $\varphi$ to $\Lambda_N$.
We define a potential $\Phi^N$ by
\begin{equation}
\Phi^N_A(\varphi) = \phi_A(\varphi^N) \1_{A \subset \Lambda_N}.
\end{equation}
The Gibbs measure on $\Lambda_N$ with \emph{periodic boundary conditions} is defined by
\begin{equation}
\mu_N(d\varphi) = \frac{1}{Z_N} \exp\left(-H^{\Phi^N}(\varphi)\right) d\varphi,
\end{equation}
where $H^{\Phi^N}$ is the Hamiltonian on $\Lambda_N$ associated to the potential $\Phi_N$.
It is shown in \cite[Example 4.20]{Georgii11} that, if $\mu_N$ converges weakly to a
measure $\mu$, then $\mu \in \Gibbs(\Phi)$.
\end{example}

\todo{Two-point function and
susceptibility. Discuss first-order and continuous phase transitions.}


\section{Critical behaviour}

Let $\Gcal_\beta$ denote the set of all Gibbs measures for some potential at inverse temperature
$\beta$. A \emph{phase transition} is said to occur at inverse temperature $\beta$ if
$|\Gcal_\beta| > 1$. Many systems possess a unique \emph{critical point} $\beta_c$, such that
\begin{equation}
|\Gcal_\beta|
\begin{cases}
=1,  & \beta < \beta_c \\
> 1, & \beta > \beta_c
\end{cases}.
\end{equation}
Moreover, such systems tend to exhibit \emph{critical behaviour} when $\beta = \beta_c$:
roughly speaking, this means that a number of observables scale according to a power
law (sometimes with logarithmic corrections) at or near $\beta_c$.

The presence of critical behaviour is most notably signalled by the divergence of the
\emph{correlation length}; this is defined for any model (of walks or spins) with two-point
function $G_x(\mu)$ by
\begin{equation}
\xi(\mu) = \limsup_{k\to\infty} \frac{-k}{\log G_{ke}(\mu)}, \quad |e| = 1.
\end{equation}
\todo{Note: this is for the Euclidean lattice}
A related quantity is the \emph{correlation length of order $p$}, defined by
\begin{equation}
\xi_p(\mu) = \left(\frac{\sum_{x\in\Zd} |x|^p G_x(\mu)}{\chi(\mu)}\right)^{1/p}
\end{equation}


\subsection{The DGFF}

The two-point function is just the massive Green function $(-\Delta + m^2)^{-1}$
which, on $\Zd$, has the well-known Ornstein-Uhlenbeck decay \todo{(show this;
use random walks?)}. Write $-\Delta = D - J$ with $-J$ the off-diagonal part of
$-\Delta$. Let $P = \frac{1}{2 d} J$ and let $z = 2 d / (2 d + m^2)$. Then
\begin{equation}
(-\Delta + m^2)^{-1}
  =
\frac{z}{2 d} (1 - z P)^{-1}
  =
\frac{z}{2 d} \sum_{n=0}^\infty z^n P^n
\end{equation}
and it follows that
\begin{equation}
\chi
  =
\sum_{x\in\vertices} (-\Delta + m^2)^{-1}_{0x}
  =
\sum_{x\in\vertices} \sum_{n=0}^\infty z^n P^n_{0x}
  =
\sum_{n=0}^\infty z^n
  =
(1 - z)^{-1}.
\end{equation}
Thus, there is a critical point at $m^2 = 0$ ($z = 1$).

\todo{See candidacy report or preliminary version of it.}


\subsection{Universality}

Critical behaviour should, roughly speaking, only depend on ``tail properties''
(global geometry, range of interaction, and symmetries).


\section{Relations between models}


\subsection{The SRW and DGFF}

\todo{See candidacy report or preliminary version of it. See also misc notes}

For the discrete-time simple random walk, the canonical partition function $c_n$,
which is the number of such walks, is just $(2 d)^n$.


\subsection{The Kac-Siegert representation}

\todo{See notes on this}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagebreak

\section{Collected definitions}

Before defining the models, we establish some notation.
Let $L > 1$ be an integer (which we will need to fix large).
Consider the sequence $\Lambda=\Lambda_N = \Z^d/(L^N\Z^d)$ of
discrete $d$-dimensional tori of side lengths $L^N$,
with $N \to \infty$ corresponding to the infinite volume limit $\Lambda_N \uparrow \Z^d$.
We only consider $d=4$, but we sometimes write $d$ instead of $4$
to emphasise the role of dimension.
Let $\Ucal$ denote the collection of unit vectors in $\Zd$. % added
% For any of the $2d$ unit vectors $e \in \Z^d$,
For any $e \in \Ucal$, % added
we define the discrete gradient of a function $f:\Lambda_N \to \R$
by $\nabla^e f_x = f_{x + e} - f_x$, and
the discrete Laplacian by
\begin{equation}
\label{e:DeltaLambda}
\Delta = -\frac{1}{2}\sum_{e\in\Z^d:|e| = 1}\nabla^{-e} \nabla^{e}.
\end{equation}
The gradient and Laplacian operators act component-wise on vector-valued functions.
We also use the
% discrete Laplacian $\Delta_{\Zd}$ on $\Zd$, and the
continuous Laplacian $\Delta_{\Rd}$ on $\Rd$.

\subsection{The \texorpdfstring{\phifour}{phi4} model}
% From clp

\commentbw{Might actually be easier to study a perturbation of
the $|\varphi|^4$ model analogous to the WSAW-SA. However, do
we know the limits exist? Do we need to know this, or does the
method take care of it?}

Given $n \ge 1$,
a \emph{spin field} is a function $\varphi : \Lambda_N \to \R^n$.
We write this function as $x \mapsto \varphi_x =(\varphi_x^1,\ldots,\varphi_x^n)$.

On $\R^n$, we use the Euclidean inner product $v \cdot w = \sum_{i=1}^n v^i w^i$,
the Euclidean norm $|v|^2 = v\cdot v$,
and write $|v|^4 = (v\cdot v)^2$.
Given $g>0$, $\nu \in \R$, we define
% a function $U_{g,\nu,N}$ of the field by
% \begin{equation} \label{e:Vdef1}
%   U_{g,\nu,N}(\varphi)
%   = \sum_{x\in\Lambda}
%   \Big(\tfrac{1}{4} g |\varphi_x|^4 + \half \nu |\varphi_x|^2
%   + \half \varphi_x\cdot (-\Delta \varphi)_x  \Big)
%   .
% \end{equation}
the $|\varphi|^4$ measure on $(\R^n)^{\Lambda_N}$ by
\begin{equation}
\frac{d\varphi}{Z_{g,\nu,N}} \exp\left(-\sum_{x\in\Lambda_N}
  \Big(\tfrac{1}{4} g |\varphi_x|^4 + \half \nu |\varphi_x|^2
    + \half \varphi_x\cdot (-\Delta \varphi)_x 
  \Big)\right),
\end{equation}
where $d\varphi$ is the product Lebesgue measure on $(\R^n)^{\Lambda_N}$
and $Z_{g,\nu,N}$ is a normalisation constant (the \emph{partition function})
chosen so that $\langle 1 \rangle_{g,\nu,N} = 1$. We denote the expectation
of a random variable $F:(\R^n)^{\Lambda_N} \to \R$ with respect to this measure
by $\langle F \rangle_{g,\nu,N}$.
% \begin{equation}
%   \label{e:phi4-expectation-def}
%   \langle F \rangle_{g,\nu,N}
%   = \frac{1}{Z_{g,\nu,N}} \int F(\varphi) e^{-U_{g,\nu,N}(\varphi)} d\varphi,
% \end{equation}
% where $d\varphi$ is the Lebesgue measure on $(\R^n)^{\Lambda}$.

Given a lattice point $x$,
we define the finite and infinite volume \emph{two-point functions}
(whenever the infinite volume limit exists):
\begin{equation}\label{e:two-point-function-phi4}
G_{x, N}(g,\nu; n) =
\frac{1}{n} \pair{\varphi_0 \cdot \varphi_x}_{g,\nu, N},
\quad
G_x(g,\nu; n) = \lim_{N \to \infty} G_{x, N}(g,\nu; n).
\end{equation}
In the above limit, we identify a point $x \in \Zd$ with $x \in \Lambda_N$
for large $N$, by embedding the vertices of $\Lambda_N$ as an approximately
centred cube in $\Z^d$ (say as $[-\frac12 L^N+1,\frac12 L^N]^d \cap \Z^d$ if $L^N$ is even
and as $[-\frac12 (L^N-1), \frac12 (L^N-1)]^d \cap \Z^d$ if $L^N$ is odd).
\commentbw{This embedding is repeated elsewhere}

The \emph{susceptibility} is defined by
\begin{equation}
\label{e:susceptibility-def}
\chi(g, \nu; n)
= \lim_{N\to\infty} \sum_{x\in\Lambda_N} G_{x,N} (g,\nu; n).
\end{equation}
Given a unit vector $e\in \Zd$,
the \emph{correlation length} $\xi$ is defined by
\begin{equation}\label{e:xidef}
\xi (g,\nu; n) = \limsup_{k \to \infty} \frac{k}{\log G_{ke}(g, \nu; n)}.
\end{equation}
It provides a characteristic length scale for the model.
We study a related quantity,
the \emph{correlation length of order} $\clo >0$,
defined in terms of the infinite volume two-point function and susceptibility by
\begin{equation}
\label{e:clp}
\xi_{\clo} (g, \nu; n)
=
    \left[\frac{\sum_{x \in \Z^4} |x|^\clo G_{x}(g, \nu; n)}
    {\chi(g, \nu; n)}\right]^\frac{1}{\clo}
\hspace{-8pt}.
\end{equation}


\subsection{The weakly self-avoiding walk with self-attraction}
% From saw-sa

For $d>0$, let $X$ denote the continuous-time simple random walk on $\Zd$.
That is, $X$ is the stochastic process
with right-continuous sample paths that takes its steps at the times
of the events of a rate-$2d$ Poisson process.  A step is independent both
of the Poisson process and of all other steps, and is taken uniformly
at random to one of the $2d$ nearest neighbours of the current
position.
The field of \emph{local times} $\lt_T = (\lt_T^x)_{x\in \Z^d}$
of  $X$, up to time $T \ge 0$,
is defined by
\begin{equation}
\label{e:LTx-def}
  \lt_T^x = \int_0^T \1_{X_t = x} \; dt
  .
\end{equation}
The \emph{self-intersection local time} and \emph{self-contact local time}
of $X$ up to time $T$ are the random variables defined, respectively, by
\begin{align}
\label{e:ITdef}
  I_T &=
  \sum_{x \in \Z^d} (\lt_T^x)^2
  = \int_0^T ds \int_0^T dt \; \1_{X_{s}=X_{t}}
  ,\\
\lbeq{CTdef}
  C_T
  &=
  \sum_{x \in \Z^d}\sum_{e\in\Ucal} \lt_T^x\lt_T^{x+e}
  = \int_0^T ds \int_0^T dt \; \1_{X_{s} \sim X_{t}}
  ,
\end{align}
where
% $\Ucal$ is the set of unit vectors in $\Zd$ and
$y\sim x$ indicates that $x$ and $y$ are nearest neighbours.

Given $\gcc > 0$ and $\gamma \in \R$,
we define
\begin{equation}
\label{e:Udef-neg}
U_{\gcc,\gamma}(f)
=
\gcc \sum_{x\in\Zd} f_x^2
- \frac{\gamma}{2d}
\sum_{x\in\Zd} \sum_{e\in\Ucal} f_x f_{x+e}
\end{equation}
for $f:\Zd\to \R$ with $f_x = 0$
for all but finitely many $x$.
% For $\gcc > 0, \gamma \in \R$,
The potential that associates an energy to $X$ in terms of its
field of local times is given by
\begin{equation}
  \label{e:V}
  U_{\gcc,\gamma,T}
  =
  U_{\gcc,\gamma}(\lt_T)
  =
  \gcc I_T
  - \frac{\gamma}{2d}
  C_T
  .
\end{equation}
The energy $U_{\gcc,\gamma,T}$ increases with the self-intersection local time,
corresponding to weak self-avoidance.  For $\gamma >0$, the energy decreases
when the self-contact local time increases, corresponding to a contact self-attraction.
For $\gamma<0$, the contact term is repulsive.  We are primarily interested in
the case of positive $\gamma$, but our results hold also for small negative $\gamma$.

Figure~\ref{fig:polymer-contact} shows a sample path $X$
and indicates one self-intersection and four self-contacts.
Although $I_T$ also receives contributions from the
time the walk spends at each vertex, and $C_T$ receives a contribution from each step,
these contributions have the same distribution for all walks taking the same number
of steps.  The depicted intersections and contacts are the meaningful ones.

\begin{figure}[ht]
 \centering\input{polymer-contact.pspdftex}
 \caption{Polymer with one self-intersection and four self-contacts shown.}
 \label{fig:polymer-contact}
\end{figure}

Let $a,b \in \Zd$, and
let $E_a$ denote the expectation for the
process $X$ started at $X(0)=a$.
We define
\begin{equation}
\label{e:c}
    c_T = E_a\left(e^{-U_{\gcc,\gamma,T}}\right),
    \quad
    c_T(a,b) = E_a\left(e^{-U_{\gcc,\gamma,T}}\1_{X_T = b}\right).
\end{equation}
By translation-invariance, $c_T$ does not depend on $a$.
For $\nu \in \R$, the \emph{two-point function} is defined by
\begin{align}
\lbeq{Gsa}
    G_x(\gcc,\gamma,\nu) &=
    \int_0^\infty c_T(0, x) e^{-\nu T} \; dT,
\end{align}
and the \emph{susceptibility} is defined by
\begin{equation}
\label{e:suscept-def}
    \chi(\gcc, \gamma, \nu)
    = \int_0^\infty c_T e^{-\nu T} \; dT
    = \sum_{x\in\Zd} G_x(\gcc,\gamma,\nu)
    .
\end{equation}
For $p>0$, we define the \emph{correlation length of order $p$} by
\begin{equation}
\lbeq{xip-def}
    \xi_p(\gcc,\gamma,\nu) = \left(\frac{1}{\chi(\gcc, \gamma, \nu)}
    \sum_{x\in\Zd} |x|^p G_{\gcc,\gamma,\nu}(0, x)
    \right)^{1/p}.
\end{equation}
In \eqref{e:Gsa}--\eqref{e:xip-def},
self-intersections are suppressed by the factor
$\exp[-\gcc I_T]$, whereas nearest-neighbour
contacts are encouraged by the factor
$\exp[\frac{\gamma}{2d}C_T]$ when $\gamma > 0$.


\subsection{The critical point}

The right-hand sides of \eqref{e:Gsa}--\eqref{e:suscept-def} % \eqref{e:xip-def}
are positive or $+\infty$,
and % $G_{\gcc,\gamma,\nu}(a,b)$ and $ \chi(\gcc, \gamma, \nu)$ are
monotone decreasing in $\nu$ by definition.
We define the \emph{critical point}
\begin{equation}
\label{e:nuc-def}
\nu_c(\gcc, \gamma) = \inf \{ \nu \in \R : \chi(\gcc, \gamma, \nu) < \infty \} .
\end{equation}
For $\gamma=0$, an elementary argument
shows that $\nu_c(\gcc,0) > -\infty$ for all dimensions, and furthermore
that $\nu_c(\gcc, 0) \in [ -2  \gcc(-\Delta_{\Zd}^{-1})_{0,0}, 0]$ for dimensions $d>2$;
see \cite[Lemma~\ref{log-lem:csub}]{BBS-saw4-log}.
Here, $\Delta_{\Zd}$ is the Laplacian on $\Zd$, i.e., the $\Zd \times \Zd$
matrix with entries
\begin{equation}
\label{e:Deltaxy}
(\Delta_{\Zd})_{x, y} = \1_{x\sim y} - 2 d \1_{x=y}.
\end{equation}
% An equivalent definition is as follows:
% given a unit vector $e \in \Zd$, the discrete gradient is
% defined by $\nabla^e f_x = f_{x+e}-f_x$, and the Laplacian is $\Delta_{\Zd}
% f_{x} = \sum_{e \in \Ucal} \nabla^e f_x =
% -\frac{1}{2}\sum_{e \in \Ucal}\nabla^{-e} \nabla^{e} f_x$.

To estimate the critical point when $\gamma \neq 0$,
we also define
\begin{align} \label{e:nabladef}
    |\nabla f_x|^2 &= \sum_{e\in\Ucal}
    |\nabla^e f_x|^2,
    \quad
    |\nabla f|^2 = \sum_{x\in\Zd} |\nabla f_x|^2.
\end{align}
From the definition, we see that
\begin{equation}
\label{e:sbp}
\sum_{x\in\Zd}   f_x \Delta_{\Zd} f_x
=
-\frac{1}{2} |\nabla f|^2.
\end{equation}
It follows that
\begin{equation}
\sum_{x\in\Zd} \sum_{e\in\Ucal} f_x f_{x+e}
=
2 d \sum_{x\in\Zd} f_x^2
+ \sum_{x\in\Zd} f_x \Delta_{\Zd} f_x
=
2 d \sum_{x\in\Zd} f_x^2
- \frac{1}{2} \sum_{x\in\Zd} |\nabla f_x|^2
\end{equation}
and so we get the useful representation:
\begin{equation}
\label{e:Udef-pos}
U_{\gcc,\gamma}(f)
= (\gcc - \gamma) \sum_{x\in\Zd} f_x^2
+ \frac{\gamma}{4d} \sum_{x\in\Zd} \sum_{e\in\Ucal} |\nabla^e f_x|^2.
\end{equation}
In particular,
\begin{equation}
  \label{e:V2}
  U_{\gcc,\gamma,T} =
  (\gcc - \gamma) I_T
  + \frac{\gamma}{4d}
  |\nabla \lt_T|^2
  .
\end{equation}
A version of \refeq{V2} can be found in \cite{HK01a}.

\begin{lemma}
\label{lem:nuc}
Let $d >0$.
Let $\gcc>0$ and $|\gamma| < \gcc$.
If $\gamma \ge 0$ then $\nu_c(\gcc, \gamma) \in [\nu_c(\gcc, 0),\nu_c(\gcc-\gamma, 0)]$.
If $\gamma < 0$ then $\nu_c(\gcc,\gamma) \in [\nu_c(\gcc-\gamma,0),\nu_c(\gcc,0)]$.
\end{lemma}

\begin{proof}
Suppose first that $\gamma \in [0,\gcc)$.
It follows from \refeq{V} and \refeq{V2} that
\begin{equation}
    U_{\gcc-\gamma,0,T} \le U_{\gcc,\gamma,T} \le  U_{\gcc,0,T},
\end{equation}
which implies the desired estimates for $\nu_c(\gcc,\gamma)$.

On the other hand,
if $\gamma \in (-\gcc, 0)$ then the inequalities are reversed and now
\begin{equation}
    U_{\gcc,0,T} \le U_{\gcc,\gamma,T} \le  U_{\gcc-\gamma,0,T},
\end{equation}
which again implies the desired result.
\end{proof}


\section{Main results}

\begin{theorem}\label{thm:mr}
Let $d=4$, $n \geq 0$ and $p>0$.
For $L$ sufficiently large (depending on $\clo,n$), and for
$g >0$ sufficiently small (depending on $\clo,n$),
as $\varepsilon \downarrow 0$,
\begin{equation}
\lbeq{xipasy}
\xi_\clo(g, \nu_c  + \varepsilon;n)
\sim {\sf c}_p \tilde A_{g,n}^{\frac12}  \varepsilon^{-\frac{1}{2}} (\log \varepsilon^{-1})^{\frac{1}{2}\frac{n+2}{n+8}}
.
\end{equation}
\end{theorem}

\begin{theorem} \label{thm:suscept}
  Let $d = 4$.
  % For any $\gamma_* > 0$ there exists $\gcc_* > 0$ such that when
  % $0<\gcc < \gcc_*$ %$0 < \gcc - \gamma < g_*$
  % and $0 \le |\gamma| < \gamma_* \gcc^3$,
  There exists $\gcc_* > 0$
  and a positive function $\gamma_* : (0, \gcc_*) \to \R$
  such that whenever $0 < \gcc < \gcc_*$ and $|\gamma| < \gamma_*(\gcc)$,
  % amplitudes $A,B,C>0$ (depending on $\gcc,\gamma$)
  there are constants $A_{\gcc,\gamma}$ and $B_{\gcc,\gamma}$ such that the following hold:

  \smallskip\noindent
  (i)
  % There is a constant $A_\gcc = (2\pi)^{-2} (1 + O(\gcc))$ such that
%  decays exponentially for all $\nu > \nu_c$
%  \chgs{{\bf we should prove this to be sure we did not use monotonicity that is
%  now lost}} and
  The critical two-point function decays as
  \begin{equation}
    G_{\gcc,\gamma,\nu_c}(0, x)
        =
    A_{\gcc,\gamma} |x|^{-2} \left(1 + O\left(\frac{1}{\log |x|}\right)\right)
        \quad
    \text{as $|x|\to\infty$},
  \end{equation}
  with $A_{\gcc,\gamma} = \frac{1}{4 \pi^2} (1 + O(\gcc))$ as $\gcc \downarrow 0$.

  \smallskip\noindent
  (ii)
  % There is a constant $B_\gcc = ({\sf b} \gcc)^{1/4} (1 + O(\gcc))$ such that,
  % as $\varepsilon = \nu - \nu_c \downarrow 0$,
  The susceptibility diverges as
  \begin{equation} \label{e:chieps-asympt}
    \chi(\gcc, \gamma, \nu_c + \varepsilon)
    \sim B_{\gcc,\gamma} \varepsilon^{-1} (\log \varepsilon^{-1})^{1/4},
    \quad \varepsilon\downarrow 0,
  \end{equation}
  with $B_{\gcc,\gamma} = (\frac{\gcc}{4 \pi^2})^{1/4} (1 + O(\gcc))$ as $\gcc \downarrow 0$.

  \smallskip\noindent
  (iii) For any $p >0$,
  % there is a constant $C = ???$ such that,
  if $\gcc_*$ is chosen small depending on $p$, then
  % as $\varepsilon = \nu - \nu_c \downarrow 0$, the
  the correlation length of order $p$ diverges as
  \begin{equation} \label{e:xieps-asympt}
    \xi_p(\gcc, \gamma, \nu_c + \varepsilon)
     \sim B_{\gcc,\gamma} {\sf c}_p \varepsilon^{-1/2} (\log \varepsilon^{-1})^{1/8},
     \quad \varepsilon\downarrow 0.
     % (1 + O(\gcc)),
  \end{equation}
\end{theorem}