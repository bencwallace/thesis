% Parts are the largest structural units, but are optional.
%\part{Thesis}

% Chapters are the next main unit.
\chapter{Introduction}

\section{To do}
\begin{itemize}
\item
Use $\Vcal$, etc. for polynomials, $\Ucal$ for unit vectors

\item
Make $U_{\gcc,\gamma}$ notation consistent with $U_{\gcc,\nu,N}$.
I have done this by getting rid of the latter (it is hardly used
explicitly in clp)

\item
Change $\beta, g$ to $\backslash gcc$

\item
Change $L$ to $\backslash lt$

\item
Make $G_x(g, \nu; n)$ consistent with $G_{\gcc,\gamma,\nu}(a, b)$.
Maybe use $G_x(g, \gamma, \nu)$ and $G_x(g, \nu; n)$

\item
Make it so that $U$ has observables but no constant and $V$ is $U$
plus the constant. Thus, we must change $V$ in saw-sa to $U$ (the $V$
in saw-sa has no observables, but these can be added in without harm).
We must also change $U^\pm$ in saw-sa to something else

\item
Change $\chi$ and $\tilde\chi$ to $\backslash chicCov$ and $\backslash chicCovgen$
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Statistical mechanics}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Microcanonical ensemble}

A physical system may be determined by a choice of \emph{state space} $\Omega$ and a function
$H : \Omega \to \R$, called the \emph{Hamiltonian}. The value $H(\omega)$ represents the
total energy of the system in state $\omega\in\Omega$.

\begin{example}
Let $\Omega = U^n \times \R^{3n}$, where $U \subset \R^3$, and denote a generic element of
$\Omega$ by $(q, p)$, where $q \in U^n$ and $p \in \R^{3n}$. Then $\Omega$ is the state
space of a system of $n$ point particles $i = 1, \ldots, n$ with positions $q_i \in U$
and momenta $p_i \in \R^3$. Given a $C^1$ Hamiltonian $H : \Omega \to \R$,
the dynamics of such a system is determined by \emph{Hamilton's equations}
\begin{align}
\dd{q}{t} &= \nabla_q H(q(t), p(t)) \\
\dd{p}{t} &= -\nabla_p H(q(t), p(t)).
\end{align}
An immediate consequence of Hamilton's equations and the chain rule is the principle
of conservation of energy:
\begin{equation}
\dd{H}{t}(q(t), p(t)) = 0.
\end{equation}
Thus, a Hamiltonian system with initial configuration $(q(0), p(0))$ and energy
$E = H(q(0), p(0))$ will evolve on the constant energy shell $S_E = H^{-1}(E)$.

Let us assume that $H$ has compact level sets so that the solutions to Hamilton's
equations can be extended globally in time. In general, especially when $n$ is large,
a Hamiltonian system is likely to be too complicated to understand in a precise way.
The basic idea of statistical mechanics is to leverage this complexity by assuming
(or in some cases proving) that, as $t\to\infty$, such a system will settle into a
state of equilibrium in which all possible states are ``equiprobable''.
% One can make sense of this notion via the measure defined by
% \begin{equation}
% \mu'_E(A) = \lim_{\delta\downarrow 0} \int_{H^{-1}([E, E + \delta])} \1_A(x) \; dx.
% \end{equation}
% This measure is well-defined, is supported on $S_E$, and is invariant under the Hamiltonian
% dynamics \cite{Adams06}. Since $S_E$ is compact, $\mu'_E(S_E) < \infty$
% we can define the probability measure
% \begin{equation}
% \mu_E(A) = \mu'_E(A) / \mu'_E(S_E).
% \end{equation}
\end{example}

Although one can make sense of the notion of an equiprobable probability distribution
on $S_E$ in the above example, it is simpler (and more relevant to this thesis) to
consider the case when $S_E$ is finite. In this case, we define the
\emph{microcanonical distribution} on $S_E = H^{-1}(E)$ to be the usual uniform
measure on the (finite) set $S_E$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Canonical ensemble}

In practice, most systems of interest are not truly isolated and may exchange
energy with
their environment. Everyday experience, however, suggests that
a physical system that is left undisturbed for a sufficiently long time will achieve
\emph{thermal equilibrium}, in which the system's
temperature is constant and equal to that of its surroundings.

This situation can be modeled as follows: call the system of interest system $A$ and
its surroundings system $B$. We assume that $B$ behaves as a \emph{thermal reservoir},
meaning that it is so large that its temperature may be assumed to be effectively
constant, even if system $A$ is at a different temperature.
It is then reasonable to assume that the total system $A \times B$
is isolated and therefore described by a microcanonical distribution on a constant energy shell.

\begin{example}
Let $\Omega_1$ and $\Omega_2$ be the state spaces of systems $A$ and
$B$, respectively, and let $H_i : \Omega_i \to \R$ be their respective Hamiltonians,
where $i = 1, 2$. We assume that $|S^i_E| < \infty$ for $i = 1, 2$ and for any $E$.
The total system $A \times B$ has state space $\Omega_1 \times \Omega_2$
and Hamiltonian $H : \Omega \to \R$ given by\footnote{We are assuming the energy due to interactions
between $A$ and $B$ is negligible.}
$H(\omega) = H_1(\omega_1) + H_2(\omega_2)$
for $\omega = (\omega_1, \omega_2) \in \Omega$.
% Suppose that $S_E$ is compact so that the microcanonical ensemble $\mu_E$ on $S_E$ is well-defined.

For any $E_2 \in \R$, let $S^2_{E_2} = H_2^{-1}(E_2)$. Then the marginal distribution $\mu^1_E$
of $\mu$ on $\Omega_1$ is given by
\begin{equation}
\mu^1_E(\omega_1)
  =
\sum_{\omega_2:\omega\in S_E} \mu_E(\omega)
  =
\frac{\# S^2_{E-H_1(\omega_1)}}{\# S_E}
  \propto
e^{h^2_{E-H_1(\omega_1)}},
\end{equation}
where
\begin{equation}
h^2_{E_2} = \log |S^2_{E_2}|
\end{equation}
is the \emph{entropy} of the microcanonical ensemble on $S^2_{E_2}$.

If $E_2 \mapsto h^2_{E_2}$ is $C^1$, then we have the first-order expansion
\begin{equation}
h^2_{E - H_1(\omega_1)}
  =
h^2_E - \dd{h^2_E}{E} H_1(\omega_1) + O(H_1(\omega_1)^2).
\end{equation}
Thus,
\begin{equation}
e^{-h^2_{E-H_1(\omega_1)}}
  \approx
C e^{-\beta H_1(\omega_1)},
\end{equation}
where $\beta = \dd{h^2_E}{E}$ and $C$ is a constant independent of $\omega_1$.
The assumption that system $B$ is a ``heat bath'' then amounts to saying that
$E - H_1(\omega_1)$ is such a negligible perturbation of $E$ that the first-order
approximation above accurately represents the marginal density of $\mu^1_E$.

% The probability measure
% \begin{equation}
% \frac{1}{Z_\beta} e^{-\beta H_1(\omega_1)} d\omega_1
% \end{equation}
% is known as the \emph{canonical ensemble} on $\Omega_1$ at \emph{inverse temperature} $\beta > 0$.
% The normalizing constant $Z_\beta$ is known as the \emph{(canonical) partition function}.
\end{example}

Given a measure space $(\Omega, d\lambda)$ (not necessarily of point particles) and measurable
Hamiltonian $H : \Omega \to \R$ for which $e^{-H}$ is integrable with respect to $d\lambda$,
we define the \emph{canonical distribution} or \emph{Gibbs measure} at inverse temperature $\beta > 0$
on $\Omega$ to be the probability measure of the form
\begin{equation}
\frac{1}{Z_\beta} e^{-\beta H} d\lambda.
\end{equation}
The normalizing constant $Z_\beta$ is known as the \emph{canonical partition function}.

There are a number of reasons for studying measures of this form.
One is the \emph{principle of maximum entropy}, which states roughly that the least
biased choice of probability distributions from a given class of distributions is the
one with the maximum entropy. It can be shown using the method of Lagrange multipliers
that the canonical ensemble maximizes the
entropy over all distributions $\mu$ on $\Omega$ satisfying the average energy constraint
\begin{equation}
\int_{\Omega} H(\omega) \; d\mu(\omega) = E.
\end{equation}
The constant $\beta$ then arises as a Lagrange multiplier.

Another, purely mathematical, reason for studying measures of this form is the Hammersley-Clifford
theorem, which states that any Markov random field on a graph has a representation as a Gibbs
measure whose Hamiltonian is a sum of ``local'' interactions.

\todo{Lastly, there is the variational principle, which states that the free energy associated to
a pair $(H, \mu)$, where $H$ is a Hamiltonian and $\mu$ is a probability measure is minimized
when $\mu$ is the Gibbs measure associated to $H$.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Grand canonical ensemble}

Consider a physical system that is free to exchange particles with its environment
and let $\Omega_T$ be the space of configurations with $T$
particles and let $H_T : \Omega_T \to \R$ be the Hamiltonian on $\Omega_T$
for $T\in\interval\subset\R$ (we allow $T$ to take non-integer values for
additional generality).
The state space for the full system is then given by $\Omega = \bigsqcup_{T \in \interval} \Omega_T$,
where $\sqcup$ denotes the disjoint union.
For $\omega\in\Omega$, let $|\omega|$ be the unique value of $T$
such that $\omega \in \Omega_T$.
We define $H : \Omega \to \R$ by $H(\omega) = H_{|\omega|}(\omega)$.

By an argument similar to the derivation of the canonical ensemble (either by marginalizing
the microcanonical ensemble or by maximum entropy) we are led to define the \emph{grand
canonical ensemble} with Hamiltonian $H$ and \emph{fugacity} (or \emph{activity}) $\nu \in \R$ by
\begin{equation}
\frac{1}{Z_{\beta,\nu}} e^{-\beta (H(\omega) - \nu |\omega|)}.
\end{equation}
The normalizing constant $Z_{\beta,\nu}$ is known as the \emph{grand canonical partition function}.
Since the $\nu |\omega|$ term can be absorbed into the Hamiltonian,
the grand canonical ensemble is itself a Gibbs measure and we will only loosely
distinguish between the canonical and grand canonical ensembles. 


\section{Lattice models}

% Let $\graph = (\vertices, \edges)$ be a graph with vertices
% $\vertices$ and (undirected) edges $\edges$.

Let $\vertices$ be a countable set. An $n$-component \emph{field} on $\vertices$
is an element $\varphi$ of $(\R^n)^\vertices$.
We denote the components of a field $\varphi$
by $\varphi^i_x \in \R$ for $x \in \vertices$ and $i = 1, \ldots, n$.
The Euclidean inner product on fields is defined by
\begin{equation}
\varphi\cdot\tilde\varphi
  =
\sum_{x\in\vertices} \varphi_x \cdot \tilde\varphi_y
  =
\sum_{i=1}^n \sum_{x\in\vertices} \varphi^i_x \tilde\varphi^i_x
\end{equation}
and the Euclidean norm is
\begin{equation}
|\varphi|^2 = \varphi \cdot \varphi.
\end{equation}
Given any $\vertices\times\vertices$ matrix $M$, we define the field $M \varphi$ by
\begin{equation}
(M \varphi)_x = \sum_{y\in\vertices} M_{xy} \varphi_y
\end{equation}
when the sum is well-defined.

Let $\jay$ be a symmetric $\vertices\times\vertices$ matrix satisfying
\begin{equation}
0 < d_x = \sum_{y\in\vertices} J_{xy} < \infty,
  \quad
J_{xy} \ge 0,
  \quad
J_{xx} = 0
\end{equation}
for all $x, y$. Then we can define the diagonal matrix $\diag$ with entries
\begin{equation}
\diag_{xx} = d_x.
\end{equation}
Moreover, if $\edges = \{ \{ x, y \} : J_{xy} \ne 0 \}$, then
$\graph = (\vertices, \edges, \jay)$ is a weighted connected undirected graph.
We write $x \sim y$ if $\{ x, y \} \in \edges$.

The \emph{graph Laplacian} on $\graph$ is defined by
\begin{equation}
\lap = \diag - \jay.
\end{equation}
We also define the \emph{massive Laplacian} with squared \emph{mass} $m^2 > 0$
by
\begin{equation}
m^2 + \lap.
\end{equation}
Note that
\begin{equation}
\varphi \cdot \lap \varphi
  =
\frac{1}{2} \sum_{x,y\in\vertices} J_{xy} |\varphi_x - \varphi_y|^2
  \ge
0,
\end{equation}
so $\lap$ is positive-semidefinite.

If $m^2 > 0$, then $m^2 + \lap$ is positive-definite, hence invertible with inverse
\begin{equation}
(m^2 + \lap)^{-1} = (m^2 + D)^{-1} \sum_{n=0}^\infty Z^n P^n,
\end{equation}
where
\begin{align}
Z = (m^2 + D)^{-1} D,
  \quad
P = D^{-1} J.
\end{align}
Let $z_x$ denote the diagonal elements of $Z$.
The \emph{Green function} for $m^2 + \lap$ is the kernel of $(m^2 + \lap)^{-1}$, which we define by
\begin{equation}
C(x, y)
  =
(m^2 + d_x)^{-1} \sum_{n=0}^\infty z_x^n P^n_{xy}
\end{equation}
whenever this series converges.

An important case is when $\jay$ has $\{0, 1 \}$-valued entries. In this case, $d_x$ is the
\emph{degree} of $x$ in $\graph$ and we denote the matrix $\lap$ by $-\Delta$, which has
entries
\begin{equation}
-\Delta_{xy} = d_x \1_{x=y} - \1_{x \sim y}.
\end{equation}

% Let $\jay$ be a $\vertices \times \vertices$
% matrix with $J_{xx} = 0$ and $J_{xy} \ge 0$ for all $x, y \in \vertices$ and suppose
% that $\jay$ has summable rows: $\sum_{y\in\vertices} J_{xy} < \infty$. Let $\diag$ be
% the diagonal matrix with entries $D_{xx} = \sum_{y\in\vertices} J_{xy}$, and let $A = \diag - \jay$.

% \todo{The $Q$ matrix will be $Q = -A$, the matrix $\jay$ will be the (ferromagnetic) Ising interaction,
% and $A$ will be the interaction for the $|\varphi|^4$ model.
% E.g.\ $A = -\Delta + m^2$ has positive diagonal entries. Recall that
% $\Delta_{xy} = \1_{x \sim y} - 2 d \1_{x=y}$.}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Models of walks}

In the following, $\interval_T$ will denote one of the following choices (for all $T \ge 0$):
\begin{equation}
\interval_T
  =
\begin{cases}
\{ 0, \ldots, \lfloor T \rfloor \} \\
[0, T]
\end{cases}.
\end{equation}
These two choices will be referred to, respectively, as the \emph{discrete-} and
\emph{continuous-time} cases.
\todo{Unless the graph is transitive, the following depends on $0$.}
Fix a designated vertex $0 \in \vertices$ and
let $\Wcal_T$ denote the set of
right-continuous paths $\omega : \interval_T \to \vertices$ with $\omega(0) = 0$.
We will refer to elements of $\Wcal := \bigcup_{T \geq 0} \Wcal_T$ as \emph{walks}.
A model of walks is determined by a choice of finite measure $d\mu_T$ on
$\Wcal_T$ for each $T$.
In the discrete-time case, we will assume that
$\mu_T = \mu_{\lfloor T \rfloor}$ for all $T$ (both are measures on
$\Wcal_{\lfloor T \rfloor}$ in this case).

Given a model of walks $d\mu_T$, we define the normalizing constant
\begin{equation}
c_T = \int_{\Wcal_T} d\mu_T.
\end{equation}
Given a parameter $\nu \in \R$ (called the \emph{killing rate}),
there is a natural measure $\mu$ on $\Wcal$ defined by
\begin{equation}
\int f \; d\mu
  =
\int_0^\infty dT \; e^{-\nu T} \int_{\Wcal_T} d\mu_T f
\end{equation}
for any continuous function $f$ on $\Wcal$ with compact support.
\todo{When is $\mu$ well-defined?}
The corresponding normalizing constant is denoted
\begin{equation}
\chi(\nu) = \int_0^\infty dT \; e^{-\nu T} c_T
\end{equation}
and is known as the \emph{susceptibility}. In the discrete-time case,
we let $z = e^{-\nu}$ and write
\begin{equation}
\mu(f)
  =
\frac{1 - e^{-\nu}}{\nu} \sum_{n=0}^\infty z^n \int_{\Wcal_n} d\mu_n(\omega) \; f(\omega).
\end{equation}
with
\begin{equation}
\chi(\nu) = \frac{1 - e^{-\nu}}{\nu} \sum_{n=0}^\infty c_n z^n.
\end{equation}

For $a, b \in \vertices$, let $\Wcal_T(a, b) \subset \Wcal_T$ denote the collection of walks
$\omega \in \Wcal_T$ with $\omega_0 = a$ and $\omega_T = x$.
The conditional measure $\mu^{(ab)}_T = \mu_T(\cdot \mid \Wcal_T(a, b))$
is given by
\begin{equation}
\mu^{(ab)}_T(d\omega) = \frac{\mu_T(d\omega) \1_{\Wcal_T(a, b)}(\omega)}{c_T(a, b)},
\end{equation}
where
\begin{equation}
c_T(a, b) = \mu_T(\Wcal_T(a, b)).
\end{equation}
Let $\Wcal(a, b) = \bigcup_{T \ge 0} \Wcal_T(a, b)$. Then
\begin{equation}
\mu^{(ab)}(d\omega) = \frac{\mu(d\omega) \1_{\Wcal(a, b)}(\omega)}{G_x},
\end{equation}
where the \emph{two-point function}
\begin{equation}
G_{ab} = \mu(\Wcal(a, b)) = \int_0^\infty dT \; e^{-\nu T} c_T(a, b).
\end{equation}
In discrete time, we have
\begin{align}
G_{ab} = \frac{1 - e^{-\nu}}{\nu} \sum_{n=0}^\infty c_n(a, b) z^n.
\end{align}

Many models of walks are determined by letting $\mu_T$ be the canonical Gibbs measure
associated to a Hamiltonian $H_T : \Wcal_T \to \R$ and a base measure $d\lambda_T$ on $\Wcal_T$.
That is,
\begin{equation}
d\mu_T(\omega) = \frac{1}{Z_T} e^{-H_T(\omega)} d\lambda_T(\omega).
\end{equation}
In this caes, $\mu$ is the corresponding grand canonical ensemble (with killing rate playing
the role of fugacity) and $c_T$ and $\chi$
are the canonical and grand canonical partition functions, respectively.

% In what follows, we let $Q$ be a $\vertices \times \vertices$ matrix with $Q_{xy} = 0$
% whenever $\{ x, y \} \notin \edges$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Random walk}

Let $Q$ be the $\vertices\cup\{\partial\}\times\vertices\cup\{\partial\}$ matrix with
\begin{equation}
Q_{xy}
  =
\begin{cases}
J_{xy},       & x \ne y, \partial, y \in \vertices \\
m^2,          & x \ne \partial, y = \partial \\
-(m^2 + d_x), & x = y \in \vertices \\
0,            & x = \partial
\end{cases}.
\end{equation}
Let $X_t$ be the Markov process with generator $Q$.
That is, $X$ takes jumps from $x$ at rate
\begin{equation}
-Q_{xx}
  =
\begin{cases}
m^2 + d_x,    & x = y \in \vertices \\
0,            & x = y = \partial
\end{cases}
\end{equation}
and jumps from $x$ to $y$ with probability (with $0/0 = 1$)
\begin{equation}
\hat P_{xy}
  =
-Q_{xy} / Q_{xx}
  =
\begin{cases}
z_x P_{xy},             & x \ne \partial, y \in \vertices \\
\frac{m^2}{m^2 + d_x},  & x \ne \partial, y = \partial \\
\1_{y=\partial},        & x = \partial
\end{cases}.
\end{equation}
We call $X_t$ the \emph{continuous-time random walk} on $\graph$.
In continuous time, we let
\begin{equation}
\lambda_T(d\omega) = P_0(d\omega \mid \tau_\partial = T),
\end{equation}
where $\tau_\partial = \inf(t : X_T = \partial)$.

The \emph{discrete-time random walk} on $\graph$ is the Markov chain
$\hat X_n$ defined by
\begin{equation}
\hat X_n = X_{\tau_n},
\end{equation}
where $\tau_n$ is the $n$-th jump time of $X$. The transition matrix of
$\hat X$ is given by $\hat P$.

For $v \in \vertices$, let $P_v$ and $E_v$ denote the probability and expectation
with respect to either the process $X$ or $\hat X$ conditioned so that $X_0 = v$.
We have
\begin{equation}
c_T(x, y) = P_x (X_T = y) = (e^{t Q})_{xy}.
\end{equation}

% If $P$ is any substochastic matrix, then $P$ is the transition matrix for a Markov chain
% on $V \cup \{\partial\}$ with transition probability from $x$ to $y \ne x$ given by $P_{xy}$
% if $y \ne x$ and $P_{x\partial} := 1 - \sum_{y\in\vertices} P_{xy}$ otherwise.
% The process
% $(\hat X_n)_{n\in\Z_+}$ is called the \emph{killed discrete-time random walk} with transition matrix $P$.
% \todo{What is the killing rate?}
% In particular, the random walk $\hat X_n$ with transition matrix given by $\hat P$ above
% is called the \emph{skeleton walk} associated with $X_t$.

\begin{example}
We have
\begin{equation}
\int_0^\infty dT \; \1_{X_T=y}
  =
\sum_{n=0}^\infty \int_{\tau_n}^{\tau_{n+1}} dT \; \1_{\hat X_n=y}
  =
\sum_{n=0}^\infty (\tau_{n+1} - \tau_n) \1_{\hat X_n=y}.
\end{equation}
If $\hat X_n = y$, then $\tau_{n+1} - \tau_n$ is a Poisson random variable with rate $d_y$,
so taking the expectation of the above yields
\begin{equation}
G_{xy} = d_y \sum_{n=0}^\infty c_n(x, y).
\end{equation}


We have
\begin{equation}
G_{xy} = \sum_{n=0}^\infty c_n(x, y) \int_{\tau_n}^{\tau_{n+1}} dT \; e^{-\nu T}
\end{equation}

\begin{equation}
C(x, y) = (m^2 + d_x)^{-1} E_x \left(\sum_{n=0}^\infty \1_{X_n=y} \right)
\end{equation}
so the sum converges if and only if the expected number of visits to $y$
made a walk with transition $\hat P$ started at $x$ is finite. Thus, $C$ is
well-defined if and only if the walk is transient.
In particular, it is well-defined for $m^2 > 0$. When $\graph = \Zd$, it is
well-defined for $m^2 = 0$ if and only if $d > 2$.
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Self-avoiding walk}

A \emph{self-avoiding walk} of length $n$ on $\graph$ is a discrete walk $\omega\in\Wcal_n$
that has no self intersections, i.e.\ $\omega_x = \omega_y$ if and only if $x = y$.
We equip the collection of all self-avoiding walks of length $n$ with the uniform measure $\mu_n$.

These measures do not form a consistent family due to the possibility of ``traps''.
That is, the equality
\begin{equation}
\mu_{|\omega|}(\omega) = \sum_{\tilde\omega \supset \omega} \mu_{|\tilde\omega|}(\tilde\omega)
\end{equation}
does not hold for all $\omega\in\Wcal$ (the sum here is over all self-avoiding walks extending
$\omega$).
% \begin{wrapfigure}{R}{0.4\textwidth}
% \vspace{-0.5cm}
% \begin{center}
%   \includegraphics[width=0.3\textwidth]{figures/trapped}
%   \caption{A trapped self-avoiding walk}
%   \label{fig:trap}
% \end{center}
% \vspace{-0.5cm}
% \end{wrapfigure}
For instance, consider the self-avoiding walk $\omega\in\Wcal_7$ on $\Zd$ in
Figure~\ref{fig:trap}.
This walk has positive probability under $\mu_7$ but,
since there are no self-avoiding walks extending $\omega$, the sum on the right-hand side
above is $0$.

As a result, the methods of stochastic processes cannot be directly used to study the self-avoiding
walk. The existence of traps also contributes to the combinatorial difficulty of studying
self-avoiding walk; for instance, it is not clear how to express $c_{n+1}$ (the number of
$(n+1)$-step self-avoiding walks) in terms of $c_n$.

% \begin{figure}[!htb]
% \centering
% \caption{A trapped self-avoiding walk}
% \includegraphics{figures/trapped}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Weakly self-avoiding walk with self-attraction}

Define the \emph{local time} up to time $T$ of $\omega \in \Wcal$ at $x \in \Zd$ by
\begin{equation}
\lt^x_T(\omega) = \int_0^T \1_{\omega(S)=x} \; dS.
\end{equation}
In the discrete-time case, $\lt^x_n$ is the number of times $\omega$ visits $x$
and is bounded by $n$. In the continuous-time case, $\lt^x_T$ is almost surely
finite for the continuous-time simple random walk.

We define the \emph{intersection local time}
\begin{equation}
\label{e:ITdef}
I_T(\omega) = \sum_{x\in\vertices} (\lt^x_T)^2
  =
\int_0^T \!\! \int_0^T \1_{\omega(S_1)=\omega(S_2)} \; dS_1 dS_2
\end{equation}
and the \emph{contact self-attraction}
\begin{equation}
\label{e:CTdef}
C_T(\omega) =
  \sum_{x \in \vertices} \sum_{y \sim x} \lt_T^x(\omega) \lt_T^y(\omega)
  = \int_0^T ds \int_0^T dt \; \1_{\omega_{s} \sim \omega_{t}}
\end{equation}
up to time $T$.
% Recall that we have set the inverse temperature equal to $1$.
Given a parameter $\gcc > 0$,
and $\gamma \in \R$, we define
\begin{equation}
\label{e:Udef-neg}
U_{\gcc,\gamma}(f)
=
\gcc \sum_{x\in\vertices} f_x^2
- \frac{\gamma}{2d}
\sum_{x\in\vertices} \sum_{y \sim x} f_x f_y
\end{equation}
for $f : \vertices \to \R$.
The \emph{weakly self-avoiding walk with self-attraction} (WSAW-SA) is defined via
the Hamiltonian
\begin{equation}
H_T(\omega) = U_{\gcc,\gamma}(L_T(\omega)).
\end{equation}
We denote the canonical partition function by
\begin{equation}
c_T = c_T(\gcc, \gamma) = E_0 \left( e^{-\gcc I(T) + \gamma C(T)} \right),
\end{equation}
where $0 \in \vertices$ is fixed, and the susceptibility by
\begin{equation}
\chi(\gcc, \gamma, \nu) = \int_0^\infty c_T e^{-\nu T} \; dT.
\end{equation}

In the case $\gamma = 0$, the discrete-time version of this model is known as
the \emph{Domb-Joyce model}. In continuous-time, it is the \emph{continuous-time
weakly self-avoiding walk} (WSAW).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Spin systems}

Assume for now that $\graph$ is a finite graph.

Let $S \subset \R^n$. A \emph{spin system} on $\graph$ with spins in $S$ is given
by a probability measure $\mu$ on $\Omega = S^V$. Such a measure is often given by a
Gibbs measure
\begin{equation}
\frac{1}{Z} e^{-H(\varphi)} d\varphi,
\end{equation}
where $d\varphi = \prod_{x\in\vertices} d\varphi_x$ is the Lebesgue measure on
$\Omega$. A spin system is said to be \emph{ferromagnetic} when the measure can
be written as
\begin{equation}
\frac{1}{Z} e^{-\tilde H(\varphi)} \prod_{x\in\Lambda} \mu(d\varphi_x)
\end{equation}
for some measure $\mu$ on $S$, with
\begin{equation}
\tilde H(\varphi) = -\sum_{x, y \in \vertices} J_{xy} \varphi_x \cdot \varphi_y
\end{equation}
and $J_{xy} \ge 0$ for all $x, y$.

%%%%% MOVE EARLIER %%%%%%%%%%%%%%%%
% Given a configuration $\varphi \in \Omega$
% of spins, we will denote the $i$-th component of $\varphi_x \in S$ by $\varphi^i_x$.
% We define the inner product
% \begin{equation}
% \varphi \cdot \tilde\varphi = \sum_{i=1}^n \sum_{x\in\vertices} \varphi^i_x \tilde\varphi^i_x
% \end{equation}
% and we let a $V \times V$ matrix $M$ act on $\varphi$ via
% \begin{equation}
% (M\varphi)_x = \sum_{y\in\vertices} M_{xy} \varphi_x.
% \end{equation}

We define the \emph{two-point function} (when it exists)
\begin{equation}
G_x(\mu) = \frac{1}{n} \int d\mu(\varphi) \; \varphi_0 \cdot \varphi_x
\end{equation}
and the \emph{susceptibility}
\begin{equation}
\chi(\mu) = \sum_{x\in\vertices} G_x(\mu).
\end{equation}
Note that this definition of the susceptibility is consistent with the corresponding
definition for walks.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Gaussian fields}

Let $C$ be a positive-definite symmetric $\vertices\times\vertices$ matrix.
Then $C$ is invertible and the Gibbs measure induced by the Hamiltonian
\begin{equation}
H(\varphi) = \frac{1}{2} \varphi \cdot C^{-1} \varphi
\end{equation}
is a Gaussian measure, known as the discrete Gaussian field with covariance $C$.
The two-point function is equal to the covariance.
In particular, when $C = A^{-1} = (m^2 + \diag - \jay)^{-1}$ with $m^2 > 0$, we get the
\emph{discrete massive Gaussian free field} (DGFF), which is an example of a ferromagnetic
spin system.
% The DGFF is said to be
% \emph{massive} with \emph{mass} $m^2$ when $m^2 > 0$, and is said to be \emph{massless} when $m^2 = 0$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{The $|\varphi|^4$ spin model}

The $|\varphi|^4$ spin model is given by a quartic perturbation to the Gaussian free field.
Precisely, the Hamiltonian has the form
\begin{equation}
H(\varphi)
  =
\sum_{x\in\vertices}
\left(
  \frac{1}{4} g |\varphi_x|^4
    +
  \frac{1}{2} \nu |\varphi_x|^2
    +
  \frac{1}{2} \varphi_x \cdot (A \varphi)_x
\right)
\end{equation}
for $g > 0$, $\nu\in\R$. This is a ferromagnetic spin system.

Here, $m^2$ need not be strictly positive (this was required for the DGFF for reasons of
integrability). In fact, an important special case for us will be $A = -\Delta$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{The $O(n)$ spin model}

Consider the $|\varphi|^4$ model as above. Suppose that the $A$ are constant:
there exists $d_0$ such that $d_x = d_0$ for all $x$.
Then the $|\varphi|^4$ Hamiltonian can be written as
\begin{equation}
\sum_{x\in\vertices}
\left(
  \frac{1}{4} g |\varphi_x|^4
    +
  \frac{1}{2} (\nu + d_0) |\varphi_x|^2
\right)
  -
\frac{1}{2} \varphi \cdot \jay \varphi
\end{equation}

If we take the limit $g\to\infty$ with $\nu = -(d_0 + g / 2)$, the
$|\varphi|^4$ spin model converges
weakly to the $O(n)$ spin model, given by the Hamiltonian
\begin{equation}
H(\varphi) = -\frac{1}{2} \varphi \cdot \jay \varphi
\end{equation}
on the state space $S = S^{n-1} \subset \R^n$ the $(n-1)$-sphere.
This again is a ferromagnetic spin system.
The case $n = 1$ is the celebrated \emph{Ising model}. When $n = 2, 3$,
we get the \emph{XY model} and the \emph{classical Heisenberg model}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection{Infinite-volume Gibbs measures}

The examples above do not generalize directly to an infinite graph as
the Hamiltonian is no longer well-defined in that case. This obstacle was overcome in the work
of Dobrushin, Lanford, and Ruelle. We briefly sketch their ideas in this section.

For every finite subset $A \subset \vertices$, let $\Phi_A : \Omega \to \R$ be a function that
depends only on the values of the spins in $A$. The collection $\Phi = (\Phi_A)_{A\subset\vertices}$
is known as a \emph{potential}. The Hamiltonian induced by $\Phi$ on a finite
subset $\Lambda \subset \vertices$ is defined by
\begin{equation}
H^\Phi_\Lambda(\varphi) = \sum \Phi_A(\varphi),
\end{equation}
where the sum is over all finite subset $A \subset \vertices$ that intersect $\Lambda$.
For simplicity, suppose that the space of spins $S$ is either a discrete set equipped with the
counting measure or is equipped with the Lebesgue measure. Let us also assume that the Hamiltonians
$H^\Phi_\Lambda$ are bounded below. Thus, the  Gibbs measures corresponding to $H^\Phi_\Lambda$ are
all well-defined.

For $\Lambda \subset \vertices$ and $\varphi \in \Omega$, let $\varphi_\Lambda \in S^\Lambda$
denote the restriction of $\varphi$ to $\Lambda$.
A measure $\mu$ on $\Omega$ is said to be a \emph{Gibbs measure} for the potential $\Phi$
if for $\mu$-almost
every choice of boundary condition $\tilde\varphi$, the conditional distribution
$\mu(d\varphi \mid \varphi_{\Lambda^c} = \tilde\varphi_{\Lambda^c})$ is given by the finite-volume Gibbs
measure
\begin{equation}
\mu^\Phi_\Lambda(\varphi \mid \tilde\varphi)
  :=
\frac{1}{Z^\Phi_\Lambda(\tilde\varphi)}
e^{-H^\Phi_\Lambda(\varphi_\Lambda \tilde\varphi_{\Lambda^c})}
d\varphi_\Lambda,
\end{equation}
where $\varphi_\Lambda\tilde\varphi_{\Lambda^c} \in \Omega$ is the concatenation of
$\varphi_\Lambda$ and $\tilde\varphi_{\Lambda^c}$
and where $d\varphi_\Lambda$ is the Lebesgue measure on $S^\Lambda$.
We denote the collection of all such Gibbs measures by $\gibbs(\Phi)$.

It is straightforward to verify that any finite-volume Gibbs measure is a Gibbs measure
in the above sense. A common procedure for constructing other elements of $\gibbs(\Phi)$
is to take an \emph{infinite-volume limit}.

To do so, let $\Lambda_N$ be a sequence of finite subsets of $\vertices$ such that
$\Lambda_N \uparrow \vertices$
and let $\varphi^{(N)}$ be a sequence of spin configurations in $\Omega$. It can be verified
that, if the sequence of measures $\mu_N = \mu^\Phi_{\Lambda_N}(\cdot \mid \varphi^{(N)})$ converges weakly
to a measure $\mu$, then $\mu\in\gibbs(\Phi)$. Any measure $\mu$ constructed in this way
can be recovered from the limiting expectations $\lim_{N\to\infty} \mu_N(f)$ of sufficiently
many \emph{observables}, which are bounded continuous functions $f : \Omega \to \R$.
% It suffices to study the limiting properties of $\mu_N(f)$.

\begin{example}[Periodic boundary conditions]
Let $\graph = \Zd$ and suppose we are given a translation-invariant potential $\Phi$.
That is, $\Phi_A = \Phi_{A + i}$ for any $i \in \Zd$.
Suppose, moreover, that $\Phi$ is of finite range, i.e.\ $\Phi_A = 0$ whenever
$|A| > R$ for some $R$. Let $\Lambda_N \subset \Zd$ be a sequence of finite boxes
with $|\Lambda_N| > R$ for each $N$.

Given a configuration $\varphi \in \Omega$, let $\varphi^N \in \Omega$
be the periodic extension of the restriction of $\varphi_{\Lambda_N}$.
We define a potential $\Phi^N$ by
\begin{equation}
\Phi^N_A(\varphi) = \Phi_A(\varphi^N) \1_{A \subset \Lambda_N}.
\end{equation}
The Gibbs measure $\mu_N$ on $\Lambda_N$ with \emph{periodic boundary conditions}
with potential $\Phi$ is defined to be the Gibbs measure on $\Lambda_N$ with
potential $\Phi^N$ (and any choice of boundary conditions).
% \begin{equation}
% \mu_N(d\varphi) = \frac{1}{Z_N} \exp\left(-H^{\Phi^N}(\varphi)\right) d\varphi,
% \end{equation}
% where $H^{\Phi^N}$ is the Hamiltonian on $\Lambda_N$ associated to the potential $\Phi_N$.
It is shown in \cite[Example 4.20]{Georgii11} that, if $\mu_N$ converges weakly to a
measure $\mu$, then $\mu \in \gibbs(\Phi)$.
\end{example}

\begin{example}
Let $\graph = \Zd$ and let $\Lambda_N = \Zd/L^N\Zd$ for $L > 1$.
Let $G_{N,x}$ denote the two-point function of a spin system on $\Lambda_N$.
We define the two-point function on $\Zd$ by the limit
\begin{equation}
G_x = \lim_{N\to\infty} G_{x,N}.
\end{equation}
By the previous example, if the limit $\mu$ of the $\mu_N$ exists, then
\begin{equation}
G_x = \frac{1}{n} \int d\mu(\varphi) \varphi_0 \cdot \varphi_x.
\end{equation}
\end{example}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Phase transitions and critical behaviour}

\todo{This description of critical behaviour is too narrow and does not apply to walks}

In this section, we let $\graph = \Zd$.

Let $\gibbs_\beta$ denote the set of all Gibbs measures for some potential at inverse temperature
$\beta$. A \emph{phase transition} is said to occur at inverse temperature $\beta$ if
$|\gibbs_\beta| > 1$. Many systems possess a unique \emph{critical point} $\beta_c$, such that
\begin{equation}
|\gibbs_\beta|
\begin{cases}
=1,  & \beta < \beta_c \\
> 1, & \beta > \beta_c
\end{cases}
\end{equation}
and it is usually expected that $|\gibbs_{\beta_c}| = 1$.
Moreover, such systems tend to exhibit \emph{critical behaviour} when $\beta = \beta_c$:
roughly speaking, this means that a number of observables scale according to a power
law (sometimes with logarithmic corrections) at or near $\beta_c$, whereas these same
observables exhibit exponential decay away from $\beta_c$.

A strong indicator of critical behaviour is the divergence of the
\emph{correlation length}, defined for any model (of walks or spins) with two-point
function $G_x(\mu)$ by
\begin{equation}
\xi(\mu) = \limsup_{k\to\infty} \frac{-k}{\log G_{ke}(\mu)},
\end{equation}
where $e \in \Zd$ is a unit vector.
In other words, the correlation length is the exponential rate of decay of the
two-point function.
A related quantity is the \emph{correlation length of order $p$}, defined by
\begin{equation}
\xi_p(\mu) = \left(\frac{\sum_{x\in\Zd} |x|^p G_x(\mu)}{\chi(\mu)}\right)^{1/p}.
\end{equation}
\todo{Heuristic relation bewteen $\xi$ and $\xi_p$.}

It is expected that
\begin{align}
G_x       &\sim C_1 |x|^{-(d - 2 + \eta)}, \\
\chi(\nu) &\sim C_2 (\nu - \nu_c)^{-\gamma}, \\
\xi       &\sim C_3 (\nu - \nu_c)^{-\nubar}, \\
\xi_p     &\sim C_4 (\nu - \nu_c)^{-\nubar}
\end{align}
possibly with logarithmic corrections.
For walks, it is expected that
\begin{align}
c_T                       &\sim C_5 e^{-\nu_c T} T^{-\gamma}, \\
\langle |X_T|^2 \rangle   &\sim C_6 T^{-\nubar}.
\end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The DGFF}

The two-point function is just the massive Green function $(-\Delta + m^2)^{-1}$
which, on $\Zd$, has the well-known Ornstein-Uhlenbeck decay \todo{(show this;
use random walks?)}.
Moreover,
\begin{equation}
\chi
  =
\sum_{x\in\vertices} (-\Delta + m^2)^{-1}_{0x}
  =
\sum_{x\in\vertices} \sum_{n=0}^\infty z^n P^n_{0x}
  =
\sum_{n=0}^\infty z^n
  =
(1 - z)^{-1}.
\end{equation}
Thus, there is a critical point at $m^2 = 0$ ($z = 1$).

\todo{See candidacy report or preliminary version of it.}

\todo{For the Green function, see Theorem 1.5.4 in Lawler--Intersections of Random Walks}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Universality}

Critical behaviour should, roughly speaking, only depend on ``tail properties''
(global geometry, range of interaction, and symmetries).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Relations between models}

There are a number of close relationships between models of walks and ferromagnetic spin
systems given by a Gibbs measure.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The SRW and DGFF}

\todo{See candidacy report or preliminary version of it. See also misc notes}

For the discrete-time simple random walk, the canonical partition function $c_n$,
which is the number of such walks, is just $(2 d)^n$.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{The Kac-Siegert representation}

\todo{See notes on this}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagebreak

\section{Collected definitions}

Before defining the models, we establish some notation.
Let $L > 1$ be an integer (which we will need to fix large).
Consider the sequence $\Lambda=\Lambda_N = \Z^d/(L^N\Z^d)$ of
discrete $d$-dimensional tori of side lengths $L^N$,
with $N \to \infty$ corresponding to the infinite volume limit $\Lambda_N \uparrow \Z^d$.
We only consider $d=4$, but we sometimes write $d$ instead of $4$
to emphasise the role of dimension.
Let $\Ucal$ denote the collection of unit vectors in $\Zd$. % added
% For any of the $2d$ unit vectors $e \in \Z^d$,
For any $e \in \Ucal$, % added
we define the discrete gradient of a function $f:\Lambda_N \to \R$
by $\nabla^e f_x = f_{x + e} - f_x$, and
the discrete Laplacian by
\begin{equation}
\label{e:DeltaLambda}
\Delta = -\frac{1}{2}\sum_{e\in\Z^d:|e| = 1}\nabla^{-e} \nabla^{e}.
\end{equation}
The gradient and Laplacian operators act component-wise on vector-valued functions.
We also use the
% discrete Laplacian $\Delta_{\Zd}$ on $\Zd$, and the
continuous Laplacian $\Delta_{\Rd}$ on $\Rd$.

\subsection{The \texorpdfstring{\phifour}{phi4} model}
% From clp

\commentbw{Might actually be easier to study a perturbation of
the $|\varphi|^4$ model analogous to the WSAW-SA. However, do
we know the limits exist? Do we need to know this, or does the
method take care of it?}

Given $n \ge 1$,
a \emph{spin field} is a function $\varphi : \Lambda_N \to \R^n$.
We write this function as $x \mapsto \varphi_x =(\varphi_x^1,\ldots,\varphi_x^n)$.

On $\R^n$, we use the Euclidean inner product $v \cdot w = \sum_{i=1}^n v^i w^i$,
the Euclidean norm $|v|^2 = v\cdot v$,
and write $|v|^4 = (v\cdot v)^2$.
Given $g>0$, $\nu \in \R$, we define
% a function $U_{g,\nu,N}$ of the field by
% \begin{equation} \label{e:Vdef1}
%   U_{g,\nu,N}(\varphi)
%   = \sum_{x\in\Lambda}
%   \Big(\tfrac{1}{4} g |\varphi_x|^4 + \half \nu |\varphi_x|^2
%   + \half \varphi_x\cdot (-\Delta \varphi)_x  \Big)
%   .
% \end{equation}
the $|\varphi|^4$ measure on $(\R^n)^{\Lambda_N}$ by
\begin{equation}
\frac{d\varphi}{Z_{g,\nu,N}} \exp\left(-\sum_{x\in\Lambda_N}
  \Big(\tfrac{1}{4} g |\varphi_x|^4 + \half \nu |\varphi_x|^2
    + \half \varphi_x\cdot (-\Delta \varphi)_x 
  \Big)\right),
\end{equation}
where $d\varphi$ is the product Lebesgue measure on $(\R^n)^{\Lambda_N}$
and $Z_{g,\nu,N}$ is a normalisation constant (the \emph{partition function})
chosen so that $\langle 1 \rangle_{g,\nu,N} = 1$. We denote the expectation
of a random variable $F:(\R^n)^{\Lambda_N} \to \R$ with respect to this measure
by $\langle F \rangle_{g,\nu,N}$.
% \begin{equation}
%   \label{e:phi4-expectation-def}
%   \langle F \rangle_{g,\nu,N}
%   = \frac{1}{Z_{g,\nu,N}} \int F(\varphi) e^{-U_{g,\nu,N}(\varphi)} d\varphi,
% \end{equation}
% where $d\varphi$ is the Lebesgue measure on $(\R^n)^{\Lambda}$.

Given a lattice point $x$,
we define the finite and infinite volume \emph{two-point functions}
(whenever the infinite volume limit exists):
\begin{equation}\label{e:two-point-function-phi4}
G_{x, N}(g,\nu; n) =
\frac{1}{n} \pair{\varphi_0 \cdot \varphi_x}_{g,\nu, N},
\quad
G_x(g,\nu; n) = \lim_{N \to \infty} G_{x, N}(g,\nu; n).
\end{equation}
In the above limit, we identify a point $x \in \Zd$ with $x \in \Lambda_N$
for large $N$, by embedding the vertices of $\Lambda_N$ as an approximately
centred cube in $\Z^d$ (say as $[-\frac12 L^N+1,\frac12 L^N]^d \cap \Z^d$ if $L^N$ is even
and as $[-\frac12 (L^N-1), \frac12 (L^N-1)]^d \cap \Z^d$ if $L^N$ is odd).
\commentbw{This embedding is repeated elsewhere}

The \emph{susceptibility} is defined by
\begin{equation}
\label{e:susceptibility-def}
\chi(g, \nu; n)
= \lim_{N\to\infty} \sum_{x\in\Lambda_N} G_{x,N} (g,\nu; n).
\end{equation}
Given a unit vector $e\in \Zd$,
the \emph{correlation length} $\xi$ is defined by
\begin{equation}\label{e:xidef}
\xi (g,\nu; n) = \limsup_{k \to \infty} \frac{k}{\log G_{ke}(g, \nu; n)}.
\end{equation}
It provides a characteristic length scale for the model.
We study a related quantity,
the \emph{correlation length of order} $\clo >0$,
defined in terms of the infinite volume two-point function and susceptibility by
\begin{equation}
\label{e:clp}
\xi_{\clo} (g, \nu; n)
=
    \left[\frac{\sum_{x \in \Z^4} |x|^\clo G_{x}(g, \nu; n)}
    {\chi(g, \nu; n)}\right]^\frac{1}{\clo}
\hspace{-8pt}.
\end{equation}


\subsection{The weakly self-avoiding walk with self-attraction}
% From saw-sa

For $d>0$, let $X$ denote the continuous-time simple random walk on $\Zd$.
That is, $X$ is the stochastic process
with right-continuous sample paths that takes its steps at the times
of the events of a rate-$2d$ Poisson process.  A step is independent both
of the Poisson process and of all other steps, and is taken uniformly
at random to one of the $2d$ nearest neighbours of the current
position.
The field of \emph{local times} $\lt_T = (\lt_T^x)_{x\in \Z^d}$
of  $X$, up to time $T \ge 0$,
is defined by
\begin{equation}
\label{e:LTx-def}
  \lt_T^x = \int_0^T \1_{X_t = x} \; dt
  .
\end{equation}
The \emph{self-intersection local time} and \emph{self-contact local time}
of $X$ up to time $T$ are the random variables defined, respectively, by
\begin{align}
\label{e:ITdef}
  I_T &=
  \sum_{x \in \Z^d} (\lt_T^x)^2
  = \int_0^T ds \int_0^T dt \; \1_{X_{s}=X_{t}}
  ,\\
\lbeq{CTdef}
  C_T
  &=
  \sum_{x \in \Z^d}\sum_{e\in\Ucal} \lt_T^x\lt_T^{x+e}
  = \int_0^T ds \int_0^T dt \; \1_{X_{s} \sim X_{t}}
  ,
\end{align}
where
% $\Ucal$ is the set of unit vectors in $\Zd$ and
$y\sim x$ indicates that $x$ and $y$ are nearest neighbours.

Given $\gcc > 0$ and $\gamma \in \R$,
we define
\begin{equation}
\label{e:Udef-neg}
U_{\gcc,\gamma}(f)
=
\gcc \sum_{x\in\Zd} f_x^2
- \frac{\gamma}{2d}
\sum_{x\in\Zd} \sum_{e\in\Ucal} f_x f_{x+e}
\end{equation}
for $f:\Zd\to \R$ with $f_x = 0$
for all but finitely many $x$.
% For $\gcc > 0, \gamma \in \R$,
The potential that associates an energy to $X$ in terms of its
field of local times is given by
\begin{equation}
  \label{e:V}
  U_{\gcc,\gamma,T}
  =
  U_{\gcc,\gamma}(\lt_T)
  =
  \gcc I_T
  - \frac{\gamma}{2d}
  C_T
  .
\end{equation}
The energy $U_{\gcc,\gamma,T}$ increases with the self-intersection local time,
corresponding to weak self-avoidance.  For $\gamma >0$, the energy decreases
when the self-contact local time increases, corresponding to a contact self-attraction.
For $\gamma<0$, the contact term is repulsive.  We are primarily interested in
the case of positive $\gamma$, but our results hold also for small negative $\gamma$.

Figure~\ref{fig:polymer-contact} shows a sample path $X$
and indicates one self-intersection and four self-contacts.
Although $I_T$ also receives contributions from the
time the walk spends at each vertex, and $C_T$ receives a contribution from each step,
these contributions have the same distribution for all walks taking the same number
of steps.  The depicted intersections and contacts are the meaningful ones.

% \begin{figure}[ht]
%  \centering\input{polymer-contact.pspdftex}
%  \caption{Polymer with one self-intersection and four self-contacts shown.}
%  \label{fig:polymer-contact}
% \end{figure}

Let $a,b \in \Zd$, and
let $E_a$ denote the expectation for the
process $X$ started at $X(0)=a$.
We define
\begin{equation}
\label{e:c}
    c_T = E_a\left(e^{-U_{\gcc,\gamma,T}}\right),
    \quad
    c_T(a,b) = E_a\left(e^{-U_{\gcc,\gamma,T}}\1_{X_T = b}\right).
\end{equation}
By translation-invariance, $c_T$ does not depend on $a$.
For $\nu \in \R$, the \emph{two-point function} is defined by
\begin{align}
\lbeq{Gsa}
    G_x(\gcc,\gamma,\nu) &=
    \int_0^\infty c_T(0, x) e^{-\nu T} \; dT,
\end{align}
and the \emph{susceptibility} is defined by
\begin{equation}
\label{e:suscept-def}
    \chi(\gcc, \gamma, \nu)
    = \int_0^\infty c_T e^{-\nu T} \; dT
    = \sum_{x\in\Zd} G_x(\gcc,\gamma,\nu)
    .
\end{equation}
For $p>0$, we define the \emph{correlation length of order $p$} by
\begin{equation}
\lbeq{xip-def}
    \xi_p(\gcc,\gamma,\nu) = \left(\frac{1}{\chi(\gcc, \gamma, \nu)}
    \sum_{x\in\Zd} |x|^p G_{\gcc,\gamma,\nu}(0, x)
    \right)^{1/p}.
\end{equation}
In \eqref{e:Gsa}--\eqref{e:xip-def},
self-intersections are suppressed by the factor
$\exp[-\gcc I_T]$, whereas nearest-neighbour
contacts are encouraged by the factor
$\exp[\frac{\gamma}{2d}C_T]$ when $\gamma > 0$.


\subsection{The critical point}

The right-hand sides of \eqref{e:Gsa}--\eqref{e:suscept-def} % \eqref{e:xip-def}
are positive or $+\infty$,
and % $G_{\gcc,\gamma,\nu}(a,b)$ and $ \chi(\gcc, \gamma, \nu)$ are
monotone decreasing in $\nu$ by definition.
We define the \emph{critical point}
\begin{equation}
\label{e:nuc-def}
\nu_c(\gcc, \gamma) = \inf \{ \nu \in \R : \chi(\gcc, \gamma, \nu) < \infty \} .
\end{equation}
For $\gamma=0$, an elementary argument
shows that $\nu_c(\gcc,0) > -\infty$ for all dimensions, and furthermore
that $\nu_c(\gcc, 0) \in [ -2  \gcc(-\Delta_{\Zd}^{-1})_{0,0}, 0]$ for dimensions $d>2$;
see \cite[Lemma~\ref{log-lem:csub}]{BBS-saw4-log}.
Here, $\Delta_{\Zd}$ is the Laplacian on $\Zd$, i.e., the $\Zd \times \Zd$
matrix with entries
\begin{equation}
\label{e:Deltaxy}
(\Delta_{\Zd})_{x, y} = \1_{x\sim y} - 2 d \1_{x=y}.
\end{equation}
% An equivalent definition is as follows:
% given a unit vector $e \in \Zd$, the discrete gradient is
% defined by $\nabla^e f_x = f_{x+e}-f_x$, and the Laplacian is $\Delta_{\Zd}
% f_{x} = \sum_{e \in \Ucal} \nabla^e f_x =
% -\frac{1}{2}\sum_{e \in \Ucal}\nabla^{-e} \nabla^{e} f_x$.

To estimate the critical point when $\gamma \neq 0$,
we also define
\begin{align} \label{e:nabladef}
    |\nabla f_x|^2 &= \sum_{e\in\Ucal}
    |\nabla^e f_x|^2,
    \quad
    |\nabla f|^2 = \sum_{x\in\Zd} |\nabla f_x|^2.
\end{align}
From the definition, we see that
\begin{equation}
\label{e:sbp}
\sum_{x\in\Zd}   f_x \Delta_{\Zd} f_x
=
-\frac{1}{2} |\nabla f|^2.
\end{equation}
It follows that
\begin{equation}
\sum_{x\in\Zd} \sum_{e\in\Ucal} f_x f_{x+e}
=
2 d \sum_{x\in\Zd} f_x^2
+ \sum_{x\in\Zd} f_x \Delta_{\Zd} f_x
=
2 d \sum_{x\in\Zd} f_x^2
- \frac{1}{2} \sum_{x\in\Zd} |\nabla f_x|^2
\end{equation}
and so we get the useful representation:
\begin{equation}
\label{e:Udef-pos}
U_{\gcc,\gamma}(f)
= (\gcc - \gamma) \sum_{x\in\Zd} f_x^2
+ \frac{\gamma}{4d} \sum_{x\in\Zd} \sum_{e\in\Ucal} |\nabla^e f_x|^2.
\end{equation}
In particular,
\begin{equation}
  \label{e:V2}
  U_{\gcc,\gamma,T} =
  (\gcc - \gamma) I_T
  + \frac{\gamma}{4d}
  |\nabla \lt_T|^2
  .
\end{equation}
A version of \refeq{V2} can be found in \cite{HK01a}.

\begin{lemma}
\label{lem:nuc}
Let $d >0$.
Let $\gcc>0$ and $|\gamma| < \gcc$.
If $\gamma \ge 0$ then $\nu_c(\gcc, \gamma) \in [\nu_c(\gcc, 0),\nu_c(\gcc-\gamma, 0)]$.
If $\gamma < 0$ then $\nu_c(\gcc,\gamma) \in [\nu_c(\gcc-\gamma,0),\nu_c(\gcc,0)]$.
\end{lemma}

\begin{proof}
Suppose first that $\gamma \in [0,\gcc)$.
It follows from \refeq{V} and \refeq{V2} that
\begin{equation}
    U_{\gcc-\gamma,0,T} \le U_{\gcc,\gamma,T} \le  U_{\gcc,0,T},
\end{equation}
which implies the desired estimates for $\nu_c(\gcc,\gamma)$.

On the other hand,
if $\gamma \in (-\gcc, 0)$ then the inequalities are reversed and now
\begin{equation}
    U_{\gcc,0,T} \le U_{\gcc,\gamma,T} \le  U_{\gcc-\gamma,0,T},
\end{equation}
which again implies the desired result.
\end{proof}


\section{Main results}

\begin{theorem}\label{thm:mr}
Let $d=4$, $n \geq 0$ and $p>0$.
For $L$ sufficiently large (depending on $\clo,n$), and for
$g >0$ sufficiently small (depending on $\clo,n$),
as $\varepsilon \downarrow 0$,
\begin{equation}
\lbeq{xipasy}
\xi_\clo(g, \nu_c  + \varepsilon;n)
\sim {\sf c}_p \tilde A_{g,n}^{\frac12}  \varepsilon^{-\frac{1}{2}} (\log \varepsilon^{-1})^{\frac{1}{2}\frac{n+2}{n+8}}
.
\end{equation}
\end{theorem}

\begin{theorem} \label{thm:suscept}
  Let $d = 4$.
  % For any $\gamma_* > 0$ there exists $\gcc_* > 0$ such that when
  % $0<\gcc < \gcc_*$ %$0 < \gcc - \gamma < g_*$
  % and $0 \le |\gamma| < \gamma_* \gcc^3$,
  There exists $\gcc_* > 0$
  and a positive function $\gamma_* : (0, \gcc_*) \to \R$
  such that whenever $0 < \gcc < \gcc_*$ and $|\gamma| < \gamma_*(\gcc)$,
  % amplitudes $A,B,C>0$ (depending on $\gcc,\gamma$)
  there are constants $A_{\gcc,\gamma}$ and $B_{\gcc,\gamma}$ such that the following hold:

  \smallskip\noindent
  (i)
  % There is a constant $A_\gcc = (2\pi)^{-2} (1 + O(\gcc))$ such that
%  decays exponentially for all $\nu > \nu_c$
%  \chgs{{\bf we should prove this to be sure we did not use monotonicity that is
%  now lost}} and
  The critical two-point function decays as
  \begin{equation}
    G_{\gcc,\gamma,\nu_c}(0, x)
        =
    A_{\gcc,\gamma} |x|^{-2} \left(1 + O\left(\frac{1}{\log |x|}\right)\right)
        \quad
    \text{as $|x|\to\infty$},
  \end{equation}
  with $A_{\gcc,\gamma} = \frac{1}{4 \pi^2} (1 + O(\gcc))$ as $\gcc \downarrow 0$.

  \smallskip\noindent
  (ii)
  % There is a constant $B_\gcc = ({\sf b} \gcc)^{1/4} (1 + O(\gcc))$ such that,
  % as $\varepsilon = \nu - \nu_c \downarrow 0$,
  The susceptibility diverges as
  \begin{equation} \label{e:chieps-asympt}
    \chi(\gcc, \gamma, \nu_c + \varepsilon)
    \sim B_{\gcc,\gamma} \varepsilon^{-1} (\log \varepsilon^{-1})^{1/4},
    \quad \varepsilon\downarrow 0,
  \end{equation}
  with $B_{\gcc,\gamma} = (\frac{\gcc}{4 \pi^2})^{1/4} (1 + O(\gcc))$ as $\gcc \downarrow 0$.

  \smallskip\noindent
  (iii) For any $p >0$,
  % there is a constant $C = ???$ such that,
  if $\gcc_*$ is chosen small depending on $p$, then
  % as $\varepsilon = \nu - \nu_c \downarrow 0$, the
  the correlation length of order $p$ diverges as
  \begin{equation} \label{e:xieps-asympt}
    \xi_p(\gcc, \gamma, \nu_c + \varepsilon)
     \sim B_{\gcc,\gamma} {\sf c}_p \varepsilon^{-1/2} (\log \varepsilon^{-1})^{1/8},
     \quad \varepsilon\downarrow 0.
     % (1 + O(\gcc)),
  \end{equation}
\end{theorem}